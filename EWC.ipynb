{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from catinous.CatsinomModelGramCache import CatsinomModelGramCache\n",
    "import catinous.CatsinomModelGramCache as catsmodel\n",
    "from catinous import utils as utils\n",
    "from catinous.CatsinomDataset import CatsinomDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import pytorch_lightning as pl\n",
    "import sklearn \n",
    "from sklearn.metrics import confusion_matrix, auc, roc_curve\n",
    "import torch\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from py_jotools import mut, slurm\n",
    "import numpy as np\n",
    "import gc\n",
    "import hashlib\n",
    "import dill\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor([[ 0.0072,  0.0071, -0.0101,  ...,  0.0065,  0.0051,  0.0175],\n",
    "#         [-0.0102,  0.0059,  0.0228,  ..., -0.0115,  0.0006, -0.0125],\n",
    "#         [ 0.0167, -0.0050,  0.0069,  ..., -0.0075, -0.0214,  0.0203],\n",
    "#         ...,\n",
    "#         [-0.0205,  0.0164, -0.0105,  ..., -0.0155,  0.0018, -0.0116],\n",
    "#         [-0.0189,  0.0157,  0.0153,  ..., -0.0129, -0.0067, -0.0168],\n",
    "#         [-0.0019,  0.0022, -0.0098,  ...,  0.0199,  0.0004,  0.0170]],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read: /project/catinous/trained_models/batch_lr_base_train_1_2d20289ac9.pt\n"
     ]
    }
   ],
   "source": [
    "hparams={'continous':False,\n",
    "         'datasetfile': 'catsinom_lr_dataset.csv',\n",
    "         'noncontinous_train_splits': ['base_train'],\n",
    "         'noncontinous_steps': 3000}\n",
    "blubb, logs, df_cache, basemodel_lr = catsmodel.trained_model(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0072,  0.0071, -0.0101,  ...,  0.0065,  0.0051,  0.0175],\n",
       "        [-0.0102,  0.0059,  0.0228,  ..., -0.0115,  0.0006, -0.0125],\n",
       "        [ 0.0167, -0.0050,  0.0069,  ..., -0.0075, -0.0214,  0.0203],\n",
       "        ...,\n",
       "        [-0.0205,  0.0164, -0.0105,  ..., -0.0155,  0.0018, -0.0116],\n",
       "        [-0.0189,  0.0157,  0.0153,  ..., -0.0129, -0.0067, -0.0168],\n",
       "        [-0.0019,  0.0022, -0.0098,  ...,  0.0199,  0.0004,  0.0170]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blubb.model.fc[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams={'continous': True,\n",
    "         'use_cache': False,\n",
    "         'datasetfile': 'catsinom_combined_dataset.csv',\n",
    "         'base_model': basemodel_lr,\n",
    "         'EWC': False,\n",
    "         'EWC_dataset': 'catsinom_lr_dataset.csv',\n",
    "         'EWC_lambda': 10000000000000,\n",
    "         'val_check_interval': 100}\n",
    "# model, logs, df_cache, basemodel_lr = catsmodel.trained_model(hparams, show_progress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(CatsinomDataset(model.hparams.root_dir,\n",
    "                                    'catsinom_combined_dataset.csv',\n",
    "                                    split='val'),\n",
    "                    batch_size=4, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,img,res = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_the_eval(model):\n",
    "    dl = DataLoader(CatsinomDataset(model.hparams.root_dir,\n",
    "                                    'catsinom_combined_dataset.csv',\n",
    "                                    split='val'),\n",
    "                    batch_size=4, num_workers=2)\n",
    "    \n",
    "    val_acc_lr_l = []\n",
    "    val_acc_hr_l = []\n",
    "    model.freeze()\n",
    "    with torch.no_grad():\n",
    "        for x, y, img, res in dl:\n",
    "\n",
    "            y_hat = model.forward(x.float().cuda())\n",
    "            y_sig = torch.sigmoid(y_hat)\n",
    "            y_sig = (y_sig > torch.Tensor([0.5]).cuda()).long()\n",
    "\n",
    "            if res[0] == 'lr':\n",
    "                val_acc_lr_l.extend((y[:,None].cuda()==y_sig).detach().cpu().numpy())\n",
    "            else:\n",
    "                val_acc_hr_l.extend((y[:,None].cuda()==y_sig).detach().cpu().numpy())\n",
    "\n",
    "    print('HR: %f' % (np.asarray(val_acc_hr_l).sum()/len(val_acc_hr_l)))\n",
    "    print('LR: %f' % (np.asarray(val_acc_lr_l).sum()/len(val_acc_lr_l)))                         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.565321\n",
      "LR: 0.913158\n"
     ]
    }
   ],
   "source": [
    "do_the_eval(blubb.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "# from catinous.CatsinomDataset import CatsinomDataset\n",
    "# dl = DataLoader(CatsinomDataset(model.hparams.root_dir,\n",
    "#                                               model.hparams.datasetfile,\n",
    "#                                               iterations=100,\n",
    "#                                               batch_size=8,\n",
    "#                                               split=model.hparams.noncontinous_train_splits),\n",
    "#                               batch_size=8, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatsinomModelGramCache(hparams=hparams, device=torch.device('cuda'))\n",
    "\n",
    "# model.unfreeze()\n",
    "# model.cuda()\n",
    "# cm = utils.EWC(model.model, dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCEWithLogitsLoss()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.888361\n",
      "LR: 0.528947\n"
     ]
    }
   ],
   "source": [
    "do_the_eval(model.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.565321\n",
      "LR: 0.913158\n"
     ]
    }
   ],
   "source": [
    "do_the_eval(blubb.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:GPU available: True, used: True\n",
      "INFO:root:VISIBLE GPUS: 0\n",
      "INFO:root:\n",
      "    | Name                        | Type              | Params\n",
      "--------------------------------------------------------------\n",
      "0   | model                       | ResNet            | 24 M  \n",
      "1   | model.conv1                 | Conv2d            | 9 K   \n",
      "2   | model.bn1                   | BatchNorm2d       | 128   \n",
      "3   | model.relu                  | ReLU              | 0     \n",
      "4   | model.maxpool               | MaxPool2d         | 0     \n",
      "5   | model.layer1                | Sequential        | 215 K \n",
      "6   | model.layer1.0              | Bottleneck        | 75 K  \n",
      "7   | model.layer1.0.conv1        | Conv2d            | 4 K   \n",
      "8   | model.layer1.0.bn1          | BatchNorm2d       | 128   \n",
      "9   | model.layer1.0.conv2        | Conv2d            | 36 K  \n",
      "10  | model.layer1.0.bn2          | BatchNorm2d       | 128   \n",
      "11  | model.layer1.0.conv3        | Conv2d            | 16 K  \n",
      "12  | model.layer1.0.bn3          | BatchNorm2d       | 512   \n",
      "13  | model.layer1.0.relu         | ReLU              | 0     \n",
      "14  | model.layer1.0.downsample   | Sequential        | 16 K  \n",
      "15  | model.layer1.0.downsample.0 | Conv2d            | 16 K  \n",
      "16  | model.layer1.0.downsample.1 | BatchNorm2d       | 512   \n",
      "17  | model.layer1.1              | Bottleneck        | 70 K  \n",
      "18  | model.layer1.1.conv1        | Conv2d            | 16 K  \n",
      "19  | model.layer1.1.bn1          | BatchNorm2d       | 128   \n",
      "20  | model.layer1.1.conv2        | Conv2d            | 36 K  \n",
      "21  | model.layer1.1.bn2          | BatchNorm2d       | 128   \n",
      "22  | model.layer1.1.conv3        | Conv2d            | 16 K  \n",
      "23  | model.layer1.1.bn3          | BatchNorm2d       | 512   \n",
      "24  | model.layer1.1.relu         | ReLU              | 0     \n",
      "25  | model.layer1.2              | Bottleneck        | 70 K  \n",
      "26  | model.layer1.2.conv1        | Conv2d            | 16 K  \n",
      "27  | model.layer1.2.bn1          | BatchNorm2d       | 128   \n",
      "28  | model.layer1.2.conv2        | Conv2d            | 36 K  \n",
      "29  | model.layer1.2.bn2          | BatchNorm2d       | 128   \n",
      "30  | model.layer1.2.conv3        | Conv2d            | 16 K  \n",
      "31  | model.layer1.2.bn3          | BatchNorm2d       | 512   \n",
      "32  | model.layer1.2.relu         | ReLU              | 0     \n",
      "33  | model.layer2                | Sequential        | 1 M   \n",
      "34  | model.layer2.0              | Bottleneck        | 379 K \n",
      "35  | model.layer2.0.conv1        | Conv2d            | 32 K  \n",
      "36  | model.layer2.0.bn1          | BatchNorm2d       | 256   \n",
      "37  | model.layer2.0.conv2        | Conv2d            | 147 K \n",
      "38  | model.layer2.0.bn2          | BatchNorm2d       | 256   \n",
      "39  | model.layer2.0.conv3        | Conv2d            | 65 K  \n",
      "40  | model.layer2.0.bn3          | BatchNorm2d       | 1 K   \n",
      "41  | model.layer2.0.relu         | ReLU              | 0     \n",
      "42  | model.layer2.0.downsample   | Sequential        | 132 K \n",
      "43  | model.layer2.0.downsample.0 | Conv2d            | 131 K \n",
      "44  | model.layer2.0.downsample.1 | BatchNorm2d       | 1 K   \n",
      "45  | model.layer2.1              | Bottleneck        | 280 K \n",
      "46  | model.layer2.1.conv1        | Conv2d            | 65 K  \n",
      "47  | model.layer2.1.bn1          | BatchNorm2d       | 256   \n",
      "48  | model.layer2.1.conv2        | Conv2d            | 147 K \n",
      "49  | model.layer2.1.bn2          | BatchNorm2d       | 256   \n",
      "50  | model.layer2.1.conv3        | Conv2d            | 65 K  \n",
      "51  | model.layer2.1.bn3          | BatchNorm2d       | 1 K   \n",
      "52  | model.layer2.1.relu         | ReLU              | 0     \n",
      "53  | model.layer2.2              | Bottleneck        | 280 K \n",
      "54  | model.layer2.2.conv1        | Conv2d            | 65 K  \n",
      "55  | model.layer2.2.bn1          | BatchNorm2d       | 256   \n",
      "56  | model.layer2.2.conv2        | Conv2d            | 147 K \n",
      "57  | model.layer2.2.bn2          | BatchNorm2d       | 256   \n",
      "58  | model.layer2.2.conv3        | Conv2d            | 65 K  \n",
      "59  | model.layer2.2.bn3          | BatchNorm2d       | 1 K   \n",
      "60  | model.layer2.2.relu         | ReLU              | 0     \n",
      "61  | model.layer2.3              | Bottleneck        | 280 K \n",
      "62  | model.layer2.3.conv1        | Conv2d            | 65 K  \n",
      "63  | model.layer2.3.bn1          | BatchNorm2d       | 256   \n",
      "64  | model.layer2.3.conv2        | Conv2d            | 147 K \n",
      "65  | model.layer2.3.bn2          | BatchNorm2d       | 256   \n",
      "66  | model.layer2.3.conv3        | Conv2d            | 65 K  \n",
      "67  | model.layer2.3.bn3          | BatchNorm2d       | 1 K   \n",
      "68  | model.layer2.3.relu         | ReLU              | 0     \n",
      "69  | model.layer3                | Sequential        | 7 M   \n",
      "70  | model.layer3.0              | Bottleneck        | 1 M   \n",
      "71  | model.layer3.0.conv1        | Conv2d            | 131 K \n",
      "72  | model.layer3.0.bn1          | BatchNorm2d       | 512   \n",
      "73  | model.layer3.0.conv2        | Conv2d            | 589 K \n",
      "74  | model.layer3.0.bn2          | BatchNorm2d       | 512   \n",
      "75  | model.layer3.0.conv3        | Conv2d            | 262 K \n",
      "76  | model.layer3.0.bn3          | BatchNorm2d       | 2 K   \n",
      "77  | model.layer3.0.relu         | ReLU              | 0     \n",
      "78  | model.layer3.0.downsample   | Sequential        | 526 K \n",
      "79  | model.layer3.0.downsample.0 | Conv2d            | 524 K \n",
      "80  | model.layer3.0.downsample.1 | BatchNorm2d       | 2 K   \n",
      "81  | model.layer3.1              | Bottleneck        | 1 M   \n",
      "82  | model.layer3.1.conv1        | Conv2d            | 262 K \n",
      "83  | model.layer3.1.bn1          | BatchNorm2d       | 512   \n",
      "84  | model.layer3.1.conv2        | Conv2d            | 589 K \n",
      "85  | model.layer3.1.bn2          | BatchNorm2d       | 512   \n",
      "86  | model.layer3.1.conv3        | Conv2d            | 262 K \n",
      "87  | model.layer3.1.bn3          | BatchNorm2d       | 2 K   \n",
      "88  | model.layer3.1.relu         | ReLU              | 0     \n",
      "89  | model.layer3.2              | Bottleneck        | 1 M   \n",
      "90  | model.layer3.2.conv1        | Conv2d            | 262 K \n",
      "91  | model.layer3.2.bn1          | BatchNorm2d       | 512   \n",
      "92  | model.layer3.2.conv2        | Conv2d            | 589 K \n",
      "93  | model.layer3.2.bn2          | BatchNorm2d       | 512   \n",
      "94  | model.layer3.2.conv3        | Conv2d            | 262 K \n",
      "95  | model.layer3.2.bn3          | BatchNorm2d       | 2 K   \n",
      "96  | model.layer3.2.relu         | ReLU              | 0     \n",
      "97  | model.layer3.3              | Bottleneck        | 1 M   \n",
      "98  | model.layer3.3.conv1        | Conv2d            | 262 K \n",
      "99  | model.layer3.3.bn1          | BatchNorm2d       | 512   \n",
      "100 | model.layer3.3.conv2        | Conv2d            | 589 K \n",
      "101 | model.layer3.3.bn2          | BatchNorm2d       | 512   \n",
      "102 | model.layer3.3.conv3        | Conv2d            | 262 K \n",
      "103 | model.layer3.3.bn3          | BatchNorm2d       | 2 K   \n",
      "104 | model.layer3.3.relu         | ReLU              | 0     \n",
      "105 | model.layer3.4              | Bottleneck        | 1 M   \n",
      "106 | model.layer3.4.conv1        | Conv2d            | 262 K \n",
      "107 | model.layer3.4.bn1          | BatchNorm2d       | 512   \n",
      "108 | model.layer3.4.conv2        | Conv2d            | 589 K \n",
      "109 | model.layer3.4.bn2          | BatchNorm2d       | 512   \n",
      "110 | model.layer3.4.conv3        | Conv2d            | 262 K \n",
      "111 | model.layer3.4.bn3          | BatchNorm2d       | 2 K   \n",
      "112 | model.layer3.4.relu         | ReLU              | 0     \n",
      "113 | model.layer3.5              | Bottleneck        | 1 M   \n",
      "114 | model.layer3.5.conv1        | Conv2d            | 262 K \n",
      "115 | model.layer3.5.bn1          | BatchNorm2d       | 512   \n",
      "116 | model.layer3.5.conv2        | Conv2d            | 589 K \n",
      "117 | model.layer3.5.bn2          | BatchNorm2d       | 512   \n",
      "118 | model.layer3.5.conv3        | Conv2d            | 262 K \n",
      "119 | model.layer3.5.bn3          | BatchNorm2d       | 2 K   \n",
      "120 | model.layer3.5.relu         | ReLU              | 0     \n",
      "121 | model.layer4                | Sequential        | 14 M  \n",
      "122 | model.layer4.0              | Bottleneck        | 6 M   \n",
      "123 | model.layer4.0.conv1        | Conv2d            | 524 K \n",
      "124 | model.layer4.0.bn1          | BatchNorm2d       | 1 K   \n",
      "125 | model.layer4.0.conv2        | Conv2d            | 2 M   \n",
      "126 | model.layer4.0.bn2          | BatchNorm2d       | 1 K   \n",
      "127 | model.layer4.0.conv3        | Conv2d            | 1 M   \n",
      "128 | model.layer4.0.bn3          | BatchNorm2d       | 4 K   \n",
      "129 | model.layer4.0.relu         | ReLU              | 0     \n",
      "130 | model.layer4.0.downsample   | Sequential        | 2 M   \n",
      "131 | model.layer4.0.downsample.0 | Conv2d            | 2 M   \n",
      "132 | model.layer4.0.downsample.1 | BatchNorm2d       | 4 K   \n",
      "133 | model.layer4.1              | Bottleneck        | 4 M   \n",
      "134 | model.layer4.1.conv1        | Conv2d            | 1 M   \n",
      "135 | model.layer4.1.bn1          | BatchNorm2d       | 1 K   \n",
      "136 | model.layer4.1.conv2        | Conv2d            | 2 M   \n",
      "137 | model.layer4.1.bn2          | BatchNorm2d       | 1 K   \n",
      "138 | model.layer4.1.conv3        | Conv2d            | 1 M   \n",
      "139 | model.layer4.1.bn3          | BatchNorm2d       | 4 K   \n",
      "140 | model.layer4.1.relu         | ReLU              | 0     \n",
      "141 | model.layer4.2              | Bottleneck        | 4 M   \n",
      "142 | model.layer4.2.conv1        | Conv2d            | 1 M   \n",
      "143 | model.layer4.2.bn1          | BatchNorm2d       | 1 K   \n",
      "144 | model.layer4.2.conv2        | Conv2d            | 2 M   \n",
      "145 | model.layer4.2.bn2          | BatchNorm2d       | 1 K   \n",
      "146 | model.layer4.2.conv3        | Conv2d            | 1 M   \n",
      "147 | model.layer4.2.bn3          | BatchNorm2d       | 4 K   \n",
      "148 | model.layer4.2.relu         | ReLU              | 0     \n",
      "149 | model.avgpool               | AdaptiveAvgPool2d | 0     \n",
      "150 | model.fc                    | Sequential        | 1 M   \n",
      "151 | model.fc.0                  | Linear            | 1 M   \n",
      "152 | model.fc.1                  | BatchNorm1d       | 1 K   \n",
      "153 | model.fc.2                  | Linear            | 513   \n",
      "154 | loss                        | BCEWithLogitsLoss | 0     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc45ea366fc4d9f9cefdc46297e255e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validation sanity check', layout=Layout(flex='2'), max=5, sty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19b3fe543f3b4c3f994671359f28c289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', layout=Layout(flex='2'), max=1), HTML(value='')), layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac5ab318067411eb607c9edb8e24f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validating', layout=Layout(flex='2'), max=201, style=Progress…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e13df2913ca4b87bc23e7808a56ba73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validating', layout=Layout(flex='2'), max=201, style=Progress…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87fdefe3e1d445779df3f4fc02e9194d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validating', layout=Layout(flex='2'), max=201, style=Progress…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1b98de8d8261>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpllogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_check_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_check_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_gpu_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0;31m# ON CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/trainer/distrib_parts.py\u001b[0m in \u001b[0;36msingle_gpu_train\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pretrain_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdp_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_pretrain_routine\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0;31m# CORE TRAINING LOOP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0;31m# summarize profile results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# RUN TNG EPOCH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;31m# -----------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0;31m# update LR schedulers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;31m# fast_dev_run always forces val checking after train batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_dev_run\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mshould_check_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_early_stop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/trainer/evaluation_loop.py\u001b[0m in \u001b[0;36mrun_evaluation\u001b[0;34m(self, test)\u001b[0m\n\u001b[1;32m    303\u001b[0m                                      \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                                      \u001b[0mmax_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                                      test)\n\u001b[0m\u001b[1;32m    306\u001b[0m         _, prog_bar_metrics, log_metrics, callback_metrics, _ = self.process_output(\n\u001b[1;32m    307\u001b[0m             eval_results)\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/trainer/evaluation_loop.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, model, dataloaders, max_batches, test)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0mdl_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logger = utils.pllogger(model.hparams)\n",
    "trainer = Trainer(gpus=1, max_epochs=1, early_stop_callback=False, logger=logger, val_check_interval=model.hparams.val_check_interval, show_progress_bar=True, checkpoint_callback=False)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2392, device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blubb.model.bn1.weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for n,p in model.model.named_parameters():\n",
    "#     print(n)\n",
    "    print(torch.sum(blubb.model.state_dict()[n] - p) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(blubb.model.state_dict()[n] - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 7, 7])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2392, device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.bn1.weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0072,  0.0071, -0.0101,  ...,  0.0065,  0.0051,  0.0175],\n",
       "        [-0.0102,  0.0059,  0.0228,  ..., -0.0115,  0.0006, -0.0125],\n",
       "        [ 0.0167, -0.0050,  0.0069,  ..., -0.0075, -0.0214,  0.0203],\n",
       "        ...,\n",
       "        [-0.0205,  0.0164, -0.0105,  ..., -0.0155,  0.0018, -0.0116],\n",
       "        [-0.0189,  0.0157,  0.0153,  ..., -0.0129, -0.0067, -0.0168],\n",
       "        [-0.0019,  0.0022, -0.0098,  ...,  0.0199,  0.0004,  0.0170]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.fc[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0072,  0.0071, -0.0101,  ...,  0.0065,  0.0051,  0.0175],\n",
       "        [-0.0102,  0.0059,  0.0228,  ..., -0.0115,  0.0006, -0.0125],\n",
       "        [ 0.0167, -0.0050,  0.0069,  ..., -0.0075, -0.0214,  0.0203],\n",
       "        ...,\n",
       "        [-0.0205,  0.0164, -0.0105,  ..., -0.0155,  0.0018, -0.0116],\n",
       "        [-0.0189,  0.0157,  0.0153,  ..., -0.0129, -0.0067, -0.0168],\n",
       "        [-0.0019,  0.0022, -0.0098,  ...,  0.0199,  0.0004,  0.0170]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blubb.model.fc[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.3084],\n",
       "        [-6.4678],\n",
       "        [-5.9596],\n",
       "        [-6.4614]], device='cuda:0')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.forward(x.float().cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0184],\n",
       "        [-3.5679],\n",
       "        [-2.5764],\n",
       "        [-3.3453]], device='cuda:0')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blubb.model.forward(x.float().cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(blubb.state_dict(),'/tmp/weird1.pth')\n",
    "torch.save(model.state_dict(),'/tmp/weird2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.conv1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.bn1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.bn1.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.bn1.running_mean\n",
      "tensor(0.0337, device='cuda:0')\n",
      "model.bn1.running_var\n",
      "tensor(-2.8077, device='cuda:0')\n",
      "model.bn1.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer1.0.conv1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer1.0.bn1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer1.0.bn1.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer1.0.bn1.running_mean\n",
      "tensor(2.1207, device='cuda:0')\n",
      "model.layer1.0.bn1.running_var\n",
      "tensor(-0.0685, device='cuda:0')\n",
      "model.layer1.0.bn1.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer1.0.conv2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer1.0.bn2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer1.0.bn2.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer1.0.bn2.running_mean\n",
      "tensor(-0.2326, device='cuda:0')\n",
      "model.layer1.0.bn2.running_var\n",
      "tensor(0.0015, device='cuda:0')\n",
      "model.layer1.0.bn2.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer1.0.conv3.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer1.0.bn3.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer1.0.bn3.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer1.0.bn3.running_mean\n",
      "tensor(0.0046, device='cuda:0')\n",
      "model.layer1.0.bn3.running_var\n",
      "tensor(0.1031, device='cuda:0')\n",
      "model.layer1.0.bn3.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer1.0.downsample.0.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer1.0.downsample.1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer1.0.downsample.1.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer1.0.downsample.1.running_mean\n",
      "tensor(4.5762, device='cuda:0')\n",
      "model.layer1.0.downsample.1.running_var\n",
      "tensor(0.0193, device='cuda:0')\n",
      "model.layer1.0.downsample.1.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer1.1.conv1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer1.1.bn1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer1.1.bn1.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer1.1.bn1.running_mean\n",
      "tensor(-0.3341, device='cuda:0')\n",
      "model.layer1.1.bn1.running_var\n",
      "tensor(-0.3575, device='cuda:0')\n",
      "model.layer1.1.bn1.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer1.1.conv2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer1.1.bn2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer1.1.bn2.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer1.1.bn2.running_mean\n",
      "tensor(-0.1387, device='cuda:0')\n",
      "model.layer1.1.bn2.running_var\n",
      "tensor(-0.1286, device='cuda:0')\n",
      "model.layer1.1.bn2.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer1.1.conv3.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer1.1.bn3.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer1.1.bn3.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer1.1.bn3.running_mean\n",
      "tensor(-0.0016, device='cuda:0')\n",
      "model.layer1.1.bn3.running_var\n",
      "tensor(-0.0277, device='cuda:0')\n",
      "model.layer1.1.bn3.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer1.2.conv1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer1.2.bn1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer1.2.bn1.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer1.2.bn1.running_mean\n",
      "tensor(-0.1274, device='cuda:0')\n",
      "model.layer1.2.bn1.running_var\n",
      "tensor(-0.2608, device='cuda:0')\n",
      "model.layer1.2.bn1.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer1.2.conv2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer1.2.bn2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer1.2.bn2.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer1.2.bn2.running_mean\n",
      "tensor(0.0709, device='cuda:0')\n",
      "model.layer1.2.bn2.running_var\n",
      "tensor(-0.0966, device='cuda:0')\n",
      "model.layer1.2.bn2.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer1.2.conv3.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer1.2.bn3.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer1.2.bn3.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer1.2.bn3.running_mean\n",
      "tensor(0.1429, device='cuda:0')\n",
      "model.layer1.2.bn3.running_var\n",
      "tensor(0.0148, device='cuda:0')\n",
      "model.layer1.2.bn3.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer2.0.conv1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.0.bn1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.0.bn1.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.0.bn1.running_mean\n",
      "tensor(0.4039, device='cuda:0')\n",
      "model.layer2.0.bn1.running_var\n",
      "tensor(-0.7194, device='cuda:0')\n",
      "model.layer2.0.bn1.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer2.0.conv2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.0.bn2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.0.bn2.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.0.bn2.running_mean\n",
      "tensor(0.1910, device='cuda:0')\n",
      "model.layer2.0.bn2.running_var\n",
      "tensor(0.1570, device='cuda:0')\n",
      "model.layer2.0.bn2.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer2.0.conv3.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.0.bn3.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.0.bn3.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.0.bn3.running_mean\n",
      "tensor(0.0252, device='cuda:0')\n",
      "model.layer2.0.bn3.running_var\n",
      "tensor(0.0150, device='cuda:0')\n",
      "model.layer2.0.bn3.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer2.0.downsample.0.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.0.downsample.1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.0.downsample.1.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.0.downsample.1.running_mean\n",
      "tensor(0.4476, device='cuda:0')\n",
      "model.layer2.0.downsample.1.running_var\n",
      "tensor(-0.8781, device='cuda:0')\n",
      "model.layer2.0.downsample.1.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer2.1.conv1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.1.bn1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.1.bn1.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.1.bn1.running_mean\n",
      "tensor(0.0204, device='cuda:0')\n",
      "model.layer2.1.bn1.running_var\n",
      "tensor(0.1695, device='cuda:0')\n",
      "model.layer2.1.bn1.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer2.1.conv2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.1.bn2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.1.bn2.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.1.bn2.running_mean\n",
      "tensor(0.0008, device='cuda:0')\n",
      "model.layer2.1.bn2.running_var\n",
      "tensor(0.0163, device='cuda:0')\n",
      "model.layer2.1.bn2.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer2.1.conv3.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.1.bn3.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.1.bn3.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.1.bn3.running_mean\n",
      "tensor(0.0101, device='cuda:0')\n",
      "model.layer2.1.bn3.running_var\n",
      "tensor(-0.0126, device='cuda:0')\n",
      "model.layer2.1.bn3.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer2.2.conv1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.2.bn1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.2.bn1.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.2.bn1.running_mean\n",
      "tensor(-0.0146, device='cuda:0')\n",
      "model.layer2.2.bn1.running_var\n",
      "tensor(-0.0411, device='cuda:0')\n",
      "model.layer2.2.bn1.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer2.2.conv2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.2.bn2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.2.bn2.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.2.bn2.running_mean\n",
      "tensor(0.0629, device='cuda:0')\n",
      "model.layer2.2.bn2.running_var\n",
      "tensor(0.1623, device='cuda:0')\n",
      "model.layer2.2.bn2.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer2.2.conv3.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.2.bn3.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.2.bn3.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.2.bn3.running_mean\n",
      "tensor(-0.0113, device='cuda:0')\n",
      "model.layer2.2.bn3.running_var\n",
      "tensor(-0.0127, device='cuda:0')\n",
      "model.layer2.2.bn3.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer2.3.conv1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.3.bn1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.3.bn1.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.3.bn1.running_mean\n",
      "tensor(-0.0533, device='cuda:0')\n",
      "model.layer2.3.bn1.running_var\n",
      "tensor(0.1176, device='cuda:0')\n",
      "model.layer2.3.bn1.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer2.3.conv2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.3.bn2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.3.bn2.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.3.bn2.running_mean\n",
      "tensor(0.0308, device='cuda:0')\n",
      "model.layer2.3.bn2.running_var\n",
      "tensor(0.0436, device='cuda:0')\n",
      "model.layer2.3.bn2.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer2.3.conv3.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.3.bn3.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.3.bn3.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer2.3.bn3.running_mean\n",
      "tensor(0.0545, device='cuda:0')\n",
      "model.layer2.3.bn3.running_var\n",
      "tensor(-0.0044, device='cuda:0')\n",
      "model.layer2.3.bn3.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer3.0.conv1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.0.bn1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.0.bn1.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.0.bn1.running_mean\n",
      "tensor(-0.2345, device='cuda:0')\n",
      "model.layer3.0.bn1.running_var\n",
      "tensor(0.0091, device='cuda:0')\n",
      "model.layer3.0.bn1.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer3.0.conv2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.0.bn2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.0.bn2.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.0.bn2.running_mean\n",
      "tensor(0.1161, device='cuda:0')\n",
      "model.layer3.0.bn2.running_var\n",
      "tensor(0.7615, device='cuda:0')\n",
      "model.layer3.0.bn2.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer3.0.conv3.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.0.bn3.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.0.bn3.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.0.bn3.running_mean\n",
      "tensor(-0.0745, device='cuda:0')\n",
      "model.layer3.0.bn3.running_var\n",
      "tensor(-0.0257, device='cuda:0')\n",
      "model.layer3.0.bn3.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer3.0.downsample.0.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.0.downsample.1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.0.downsample.1.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.0.downsample.1.running_mean\n",
      "tensor(-0.2798, device='cuda:0')\n",
      "model.layer3.0.downsample.1.running_var\n",
      "tensor(0.2353, device='cuda:0')\n",
      "model.layer3.0.downsample.1.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer3.1.conv1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.1.bn1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.1.bn1.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.1.bn1.running_mean\n",
      "tensor(-0.0051, device='cuda:0')\n",
      "model.layer3.1.bn1.running_var\n",
      "tensor(0.0810, device='cuda:0')\n",
      "model.layer3.1.bn1.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer3.1.conv2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.1.bn2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.1.bn2.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.1.bn2.running_mean\n",
      "tensor(0.0721, device='cuda:0')\n",
      "model.layer3.1.bn2.running_var\n",
      "tensor(0.2666, device='cuda:0')\n",
      "model.layer3.1.bn2.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer3.1.conv3.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.1.bn3.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.1.bn3.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.1.bn3.running_mean\n",
      "tensor(-0.1140, device='cuda:0')\n",
      "model.layer3.1.bn3.running_var\n",
      "tensor(-0.1644, device='cuda:0')\n",
      "model.layer3.1.bn3.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer3.2.conv1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.2.bn1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.2.bn1.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.2.bn1.running_mean\n",
      "tensor(-0.2518, device='cuda:0')\n",
      "model.layer3.2.bn1.running_var\n",
      "tensor(0.2216, device='cuda:0')\n",
      "model.layer3.2.bn1.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer3.2.conv2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.2.bn2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.2.bn2.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.2.bn2.running_mean\n",
      "tensor(-0.1910, device='cuda:0')\n",
      "model.layer3.2.bn2.running_var\n",
      "tensor(0.1357, device='cuda:0')\n",
      "model.layer3.2.bn2.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer3.2.conv3.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.2.bn3.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.2.bn3.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.2.bn3.running_mean\n",
      "tensor(-0.0031, device='cuda:0')\n",
      "model.layer3.2.bn3.running_var\n",
      "tensor(-0.0057, device='cuda:0')\n",
      "model.layer3.2.bn3.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer3.3.conv1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.3.bn1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.3.bn1.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.3.bn1.running_mean\n",
      "tensor(-0.2781, device='cuda:0')\n",
      "model.layer3.3.bn1.running_var\n",
      "tensor(0.2369, device='cuda:0')\n",
      "model.layer3.3.bn1.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer3.3.conv2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.3.bn2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.3.bn2.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.3.bn2.running_mean\n",
      "tensor(-0.1161, device='cuda:0')\n",
      "model.layer3.3.bn2.running_var\n",
      "tensor(0.0735, device='cuda:0')\n",
      "model.layer3.3.bn2.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer3.3.conv3.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.3.bn3.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.3.bn3.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.3.bn3.running_mean\n",
      "tensor(-0.0176, device='cuda:0')\n",
      "model.layer3.3.bn3.running_var\n",
      "tensor(-0.0109, device='cuda:0')\n",
      "model.layer3.3.bn3.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer3.4.conv1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.4.bn1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.4.bn1.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.4.bn1.running_mean\n",
      "tensor(-0.3424, device='cuda:0')\n",
      "model.layer3.4.bn1.running_var\n",
      "tensor(0.2504, device='cuda:0')\n",
      "model.layer3.4.bn1.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer3.4.conv2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.4.bn2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.4.bn2.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.4.bn2.running_mean\n",
      "tensor(-0.0333, device='cuda:0')\n",
      "model.layer3.4.bn2.running_var\n",
      "tensor(0.1338, device='cuda:0')\n",
      "model.layer3.4.bn2.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer3.4.conv3.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.4.bn3.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.4.bn3.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.4.bn3.running_mean\n",
      "tensor(0.2336, device='cuda:0')\n",
      "model.layer3.4.bn3.running_var\n",
      "tensor(0.0154, device='cuda:0')\n",
      "model.layer3.4.bn3.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer3.5.conv1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.5.bn1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.5.bn1.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.5.bn1.running_mean\n",
      "tensor(-0.1491, device='cuda:0')\n",
      "model.layer3.5.bn1.running_var\n",
      "tensor(0.1747, device='cuda:0')\n",
      "model.layer3.5.bn1.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer3.5.conv2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.5.bn2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.5.bn2.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.5.bn2.running_mean\n",
      "tensor(-0.0371, device='cuda:0')\n",
      "model.layer3.5.bn2.running_var\n",
      "tensor(0.0351, device='cuda:0')\n",
      "model.layer3.5.bn2.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer3.5.conv3.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.5.bn3.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.5.bn3.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer3.5.bn3.running_mean\n",
      "tensor(-0.3201, device='cuda:0')\n",
      "model.layer3.5.bn3.running_var\n",
      "tensor(-0.1749, device='cuda:0')\n",
      "model.layer3.5.bn3.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer4.0.conv1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer4.0.bn1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer4.0.bn1.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer4.0.bn1.running_mean\n",
      "tensor(-1.0190, device='cuda:0')\n",
      "model.layer4.0.bn1.running_var\n",
      "tensor(0.5156, device='cuda:0')\n",
      "model.layer4.0.bn1.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer4.0.conv2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer4.0.bn2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer4.0.bn2.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer4.0.bn2.running_mean\n",
      "tensor(-0.4610, device='cuda:0')\n",
      "model.layer4.0.bn2.running_var\n",
      "tensor(1.1304, device='cuda:0')\n",
      "model.layer4.0.bn2.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer4.0.conv3.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer4.0.bn3.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer4.0.bn3.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer4.0.bn3.running_mean\n",
      "tensor(0.2255, device='cuda:0')\n",
      "model.layer4.0.bn3.running_var\n",
      "tensor(0.2077, device='cuda:0')\n",
      "model.layer4.0.bn3.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer4.0.downsample.0.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer4.0.downsample.1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer4.0.downsample.1.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer4.0.downsample.1.running_mean\n",
      "tensor(-0.9441, device='cuda:0')\n",
      "model.layer4.0.downsample.1.running_var\n",
      "tensor(0.2872, device='cuda:0')\n",
      "model.layer4.0.downsample.1.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer4.1.conv1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer4.1.bn1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer4.1.bn1.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer4.1.bn1.running_mean\n",
      "tensor(-0.2758, device='cuda:0')\n",
      "model.layer4.1.bn1.running_var\n",
      "tensor(4.8916, device='cuda:0')\n",
      "model.layer4.1.bn1.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer4.1.conv2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer4.1.bn2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer4.1.bn2.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer4.1.bn2.running_mean\n",
      "tensor(-0.2575, device='cuda:0')\n",
      "model.layer4.1.bn2.running_var\n",
      "tensor(0.6873, device='cuda:0')\n",
      "model.layer4.1.bn2.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer4.1.conv3.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer4.1.bn3.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer4.1.bn3.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer4.1.bn3.running_mean\n",
      "tensor(-0.1955, device='cuda:0')\n",
      "model.layer4.1.bn3.running_var\n",
      "tensor(-0.0748, device='cuda:0')\n",
      "model.layer4.1.bn3.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer4.2.conv1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer4.2.bn1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer4.2.bn1.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer4.2.bn1.running_mean\n",
      "tensor(-4.0918, device='cuda:0')\n",
      "model.layer4.2.bn1.running_var\n",
      "tensor(-0.1387, device='cuda:0')\n",
      "model.layer4.2.bn1.num_batches_tracked\n",
      "tensor(-302, device='cuda:0')\n",
      "model.layer4.2.conv2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer4.2.bn2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer4.2.bn2.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer4.2.bn2.running_mean\n",
      "tensor(-1.9048, device='cuda:0')\n",
      "model.layer4.2.bn2.running_var\n",
      "tensor(-2.7223, device='cuda:0')\n",
      "model.layer4.2.bn2.num_batches_tracked\n",
      "tensor(-301, device='cuda:0')\n",
      "model.layer4.2.conv3.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer4.2.bn3.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer4.2.bn3.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.layer4.2.bn3.running_mean\n",
      "tensor(-0.2281, device='cuda:0')\n",
      "model.layer4.2.bn3.running_var\n",
      "tensor(-0.5363, device='cuda:0')\n",
      "model.layer4.2.bn3.num_batches_tracked\n",
      "tensor(-301, device='cuda:0')\n",
      "model.fc.0.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.fc.0.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.fc.1.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.fc.1.bias\n",
      "tensor(0., device='cuda:0')\n",
      "model.fc.1.running_mean\n",
      "tensor(0.0229, device='cuda:0')\n",
      "model.fc.1.running_var\n",
      "tensor(27.8224, device='cuda:0')\n",
      "model.fc.1.num_batches_tracked\n",
      "tensor(-301, device='cuda:0')\n",
      "model.fc.2.weight\n",
      "tensor(0., device='cuda:0')\n",
      "model.fc.2.bias\n",
      "tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.freeze()\n",
    "blubb.freeze()\n",
    "for key in model.state_dict().keys():\n",
    "    print(key)\n",
    "    print(torch.sum(blubb.state_dict()[key] - model.state_dict()[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.888361\n",
      "LR: 0.528947\n"
     ]
    }
   ],
   "source": [
    "do_the_eval(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR: 0.565321\n",
      "LR: 0.913158\n"
     ]
    }
   ],
   "source": [
    "do_the_eval(blubb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n",
      "('lr', 'lr', 'lr', 'lr')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-295b85615982>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for p in model.val_dataloader()[0]:\n",
    "    if p[3][0] == 'lr':\n",
    "        print(p[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ewcloss: 0.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.penalty(model)*100000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       " \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34mr\"\"\"This loss combines a `Sigmoid` layer and the `BCELoss` in one single\u001b[0m\n",
       "\u001b[0;34m    class. This version is more numerically stable than using a plain `Sigmoid`\u001b[0m\n",
       "\u001b[0;34m    followed by a `BCELoss` as, by combining the operations into one layer,\u001b[0m\n",
       "\u001b[0;34m    we take advantage of the log-sum-exp trick for numerical stability.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    The unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    .. math::\u001b[0m\n",
       "\u001b[0;34m        \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\u001b[0m\n",
       "\u001b[0;34m        l_n = - w_n \\left[ y_n \\cdot \\log \\sigma(x_n)\u001b[0m\n",
       "\u001b[0;34m        + (1 - y_n) \\cdot \\log (1 - \\sigma(x_n)) \\right],\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    where :math:`N` is the batch size. If :attr:`reduction` is not ``'none'``\u001b[0m\n",
       "\u001b[0;34m    (default ``'mean'``), then\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    .. math::\u001b[0m\n",
       "\u001b[0;34m        \\ell(x, y) = \\begin{cases}\u001b[0m\n",
       "\u001b[0;34m            \\operatorname{mean}(L), & \\text{if reduction} = \\text{'mean';}\\\\\u001b[0m\n",
       "\u001b[0;34m            \\operatorname{sum}(L),  & \\text{if reduction} = \\text{'sum'.}\u001b[0m\n",
       "\u001b[0;34m        \\end{cases}\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    This is used for measuring the error of a reconstruction in for example\u001b[0m\n",
       "\u001b[0;34m    an auto-encoder. Note that the targets `t[i]` should be numbers\u001b[0m\n",
       "\u001b[0;34m    between 0 and 1.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    It's possible to trade off recall and precision by adding weights to positive examples.\u001b[0m\n",
       "\u001b[0;34m    In the case of multi-label classification the loss can be described as:\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    .. math::\u001b[0m\n",
       "\u001b[0;34m        \\ell_c(x, y) = L_c = \\{l_{1,c},\\dots,l_{N,c}\\}^\\top, \\quad\u001b[0m\n",
       "\u001b[0;34m        l_{n,c} = - w_{n,c} \\left[ p_c y_{n,c} \\cdot \\log \\sigma(x_{n,c})\u001b[0m\n",
       "\u001b[0;34m        + (1 - y_{n,c}) \\cdot \\log (1 - \\sigma(x_{n,c})) \\right],\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    where :math:`c` is the class number (:math:`c > 1` for multi-label binary classification,\u001b[0m\n",
       "\u001b[0;34m    :math:`c = 1` for single-label binary classification),\u001b[0m\n",
       "\u001b[0;34m    :math:`n` is the number of the sample in the batch and\u001b[0m\n",
       "\u001b[0;34m    :math:`p_c` is the weight of the positive answer for the class :math:`c`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    :math:`p_c > 1` increases the recall, :math:`p_c < 1` increases the precision.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    For example, if a dataset contains 100 positive and 300 negative examples of a single class,\u001b[0m\n",
       "\u001b[0;34m    then `pos_weight` for the class should be equal to :math:`\\frac{300}{100}=3`.\u001b[0m\n",
       "\u001b[0;34m    The loss would act as if the dataset contains :math:`3\\times 100=300` positive examples.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Examples::\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        >>> target = torch.ones([10, 64], dtype=torch.float32)  # 64 classes, batch size = 10\u001b[0m\n",
       "\u001b[0;34m        >>> output = torch.full([10, 64], 0.999)  # A prediction (logit)\u001b[0m\n",
       "\u001b[0;34m        >>> pos_weight = torch.ones([64])  # All weights are equal to 1\u001b[0m\n",
       "\u001b[0;34m        >>> criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\u001b[0m\n",
       "\u001b[0;34m        >>> criterion(output, target)  # -log(sigmoid(0.999))\u001b[0m\n",
       "\u001b[0;34m        tensor(0.3135)\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Args:\u001b[0m\n",
       "\u001b[0;34m        weight (Tensor, optional): a manual rescaling weight given to the loss\u001b[0m\n",
       "\u001b[0;34m            of each batch element. If given, has to be a Tensor of size `nbatch`.\u001b[0m\n",
       "\u001b[0;34m        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\u001b[0m\n",
       "\u001b[0;34m            the losses are averaged over each loss element in the batch. Note that for\u001b[0m\n",
       "\u001b[0;34m            some losses, there are multiple elements per sample. If the field :attr:`size_average`\u001b[0m\n",
       "\u001b[0;34m            is set to ``False``, the losses are instead summed for each minibatch. Ignored\u001b[0m\n",
       "\u001b[0;34m            when reduce is ``False``. Default: ``True``\u001b[0m\n",
       "\u001b[0;34m        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\u001b[0m\n",
       "\u001b[0;34m            losses are averaged or summed over observations for each minibatch depending\u001b[0m\n",
       "\u001b[0;34m            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\u001b[0m\n",
       "\u001b[0;34m            batch element instead and ignores :attr:`size_average`. Default: ``True``\u001b[0m\n",
       "\u001b[0;34m        reduction (string, optional): Specifies the reduction to apply to the output:\u001b[0m\n",
       "\u001b[0;34m            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\u001b[0m\n",
       "\u001b[0;34m            ``'mean'``: the sum of the output will be divided by the number of\u001b[0m\n",
       "\u001b[0;34m            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\u001b[0m\n",
       "\u001b[0;34m            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\u001b[0m\n",
       "\u001b[0;34m            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\u001b[0m\n",
       "\u001b[0;34m        pos_weight (Tensor, optional): a weight of positive examples.\u001b[0m\n",
       "\u001b[0;34m                Must be a vector with length equal to the number of classes.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Shape:\u001b[0m\n",
       "\u001b[0;34m        - Input: :math:`(N, *)` where :math:`*` means, any number of additional dimensions\u001b[0m\n",
       "\u001b[0;34m        - Target: :math:`(N, *)`, same shape as the input\u001b[0m\n",
       "\u001b[0;34m        - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(N, *)`, same\u001b[0m\n",
       "\u001b[0;34m          shape as input.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m     Examples::\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        >>> loss = nn.BCEWithLogitsLoss()\u001b[0m\n",
       "\u001b[0;34m        >>> input = torch.randn(3, requires_grad=True)\u001b[0m\n",
       "\u001b[0;34m        >>> target = torch.empty(3).random_(2)\u001b[0m\n",
       "\u001b[0;34m        >>> output = loss(input, target)\u001b[0m\n",
       "\u001b[0;34m        >>> output.backward()\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0m__constants__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pos_weight'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reduction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pos_weight'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                                  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                                  \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                                  \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/candid/lib/python3.6/site-packages/torch/nn/modules/loss.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?? nn.functional.bce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.penalty(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "blubb = {'a': 1, 'b': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blubb.pop('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b': 2}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blubb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].float().cuda()[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0.0000, 0.0077, 0.0098,  ..., 0.0098, 0.0211, 0.0197],\n",
      "          [0.0028, 0.0014, 0.0077,  ..., 0.0105, 0.0176, 0.0162],\n",
      "          [0.0267, 0.0147, 0.0035,  ..., 0.0133, 0.0197, 0.0239],\n",
      "          ...,\n",
      "          [0.0183, 0.0246, 0.0204,  ..., 0.2725, 0.1791, 0.1025],\n",
      "          [0.0091, 0.0056, 0.0028,  ..., 0.0878, 0.0618, 0.0337],\n",
      "          [0.0154, 0.0077, 0.0063,  ..., 0.0288, 0.0302, 0.0232]],\n",
      "\n",
      "         [[0.0000, 0.0077, 0.0098,  ..., 0.0098, 0.0211, 0.0197],\n",
      "          [0.0028, 0.0014, 0.0077,  ..., 0.0105, 0.0176, 0.0162],\n",
      "          [0.0267, 0.0147, 0.0035,  ..., 0.0133, 0.0197, 0.0239],\n",
      "          ...,\n",
      "          [0.0183, 0.0246, 0.0204,  ..., 0.2725, 0.1791, 0.1025],\n",
      "          [0.0091, 0.0056, 0.0028,  ..., 0.0878, 0.0618, 0.0337],\n",
      "          [0.0154, 0.0077, 0.0063,  ..., 0.0288, 0.0302, 0.0232]],\n",
      "\n",
      "         [[0.0000, 0.0077, 0.0098,  ..., 0.0098, 0.0211, 0.0197],\n",
      "          [0.0028, 0.0014, 0.0077,  ..., 0.0105, 0.0176, 0.0162],\n",
      "          [0.0267, 0.0147, 0.0035,  ..., 0.0133, 0.0197, 0.0239],\n",
      "          ...,\n",
      "          [0.0183, 0.0246, 0.0204,  ..., 0.2725, 0.1791, 0.1025],\n",
      "          [0.0091, 0.0056, 0.0028,  ..., 0.0878, 0.0618, 0.0337],\n",
      "          [0.0154, 0.0077, 0.0063,  ..., 0.0288, 0.0302, 0.0232]]],\n",
      "\n",
      "\n",
      "        [[[0.0190, 0.0246, 0.0253,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0133, 0.0112, 0.0232,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0105, 0.0063, 0.0105,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0618, 0.0527, 0.0639,  ..., 0.0007, 0.0000, 0.0000],\n",
      "          [0.0583, 0.0681, 0.0787,  ..., 0.0007, 0.0000, 0.0007],\n",
      "          [0.0765, 0.0822, 0.0639,  ..., 0.0007, 0.0007, 0.0007]],\n",
      "\n",
      "         [[0.0190, 0.0246, 0.0253,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0133, 0.0112, 0.0232,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0105, 0.0063, 0.0105,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0618, 0.0527, 0.0639,  ..., 0.0007, 0.0000, 0.0000],\n",
      "          [0.0583, 0.0681, 0.0787,  ..., 0.0007, 0.0000, 0.0007],\n",
      "          [0.0765, 0.0822, 0.0639,  ..., 0.0007, 0.0007, 0.0007]],\n",
      "\n",
      "         [[0.0190, 0.0246, 0.0253,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0133, 0.0112, 0.0232,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0105, 0.0063, 0.0105,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0618, 0.0527, 0.0639,  ..., 0.0007, 0.0000, 0.0000],\n",
      "          [0.0583, 0.0681, 0.0787,  ..., 0.0007, 0.0000, 0.0007],\n",
      "          [0.0765, 0.0822, 0.0639,  ..., 0.0007, 0.0007, 0.0007]]],\n",
      "\n",
      "\n",
      "        [[[0.0190, 0.0197, 0.0190,  ..., 0.0140, 0.0169, 0.0183],\n",
      "          [0.0211, 0.0176, 0.0147,  ..., 0.0169, 0.0162, 0.0197],\n",
      "          [0.0218, 0.0225, 0.0147,  ..., 0.0126, 0.0147, 0.0169],\n",
      "          ...,\n",
      "          [0.0162, 0.0126, 0.0162,  ..., 0.0147, 0.0154, 0.0154],\n",
      "          [0.0105, 0.0140, 0.0204,  ..., 0.0119, 0.0133, 0.0133],\n",
      "          [0.0147, 0.0140, 0.0162,  ..., 0.0154, 0.0147, 0.0162]],\n",
      "\n",
      "         [[0.0190, 0.0197, 0.0190,  ..., 0.0140, 0.0169, 0.0183],\n",
      "          [0.0211, 0.0176, 0.0147,  ..., 0.0169, 0.0162, 0.0197],\n",
      "          [0.0218, 0.0225, 0.0147,  ..., 0.0126, 0.0147, 0.0169],\n",
      "          ...,\n",
      "          [0.0162, 0.0126, 0.0162,  ..., 0.0147, 0.0154, 0.0154],\n",
      "          [0.0105, 0.0140, 0.0204,  ..., 0.0119, 0.0133, 0.0133],\n",
      "          [0.0147, 0.0140, 0.0162,  ..., 0.0154, 0.0147, 0.0162]],\n",
      "\n",
      "         [[0.0190, 0.0197, 0.0190,  ..., 0.0140, 0.0169, 0.0183],\n",
      "          [0.0211, 0.0176, 0.0147,  ..., 0.0169, 0.0162, 0.0197],\n",
      "          [0.0218, 0.0225, 0.0147,  ..., 0.0126, 0.0147, 0.0169],\n",
      "          ...,\n",
      "          [0.0162, 0.0126, 0.0162,  ..., 0.0147, 0.0154, 0.0154],\n",
      "          [0.0105, 0.0140, 0.0204,  ..., 0.0119, 0.0133, 0.0133],\n",
      "          [0.0147, 0.0140, 0.0162,  ..., 0.0154, 0.0147, 0.0162]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0169, 0.0028, 0.0028,  ..., 0.0119, 0.0147, 0.0133],\n",
      "          [0.0190, 0.0105, 0.0077,  ..., 0.0084, 0.0098, 0.0105],\n",
      "          [0.0162, 0.0140, 0.0147,  ..., 0.0049, 0.0091, 0.0162],\n",
      "          ...,\n",
      "          [0.0941, 0.0920, 0.0829,  ..., 0.0716, 0.0779, 0.0815],\n",
      "          [0.0857, 0.0878, 0.0899,  ..., 0.0772, 0.0857, 0.0864],\n",
      "          [0.0843, 0.0948, 0.1004,  ..., 0.0878, 0.0955, 0.0962]],\n",
      "\n",
      "         [[0.0169, 0.0028, 0.0028,  ..., 0.0119, 0.0147, 0.0133],\n",
      "          [0.0190, 0.0105, 0.0077,  ..., 0.0084, 0.0098, 0.0105],\n",
      "          [0.0162, 0.0140, 0.0147,  ..., 0.0049, 0.0091, 0.0162],\n",
      "          ...,\n",
      "          [0.0941, 0.0920, 0.0829,  ..., 0.0716, 0.0779, 0.0815],\n",
      "          [0.0857, 0.0878, 0.0899,  ..., 0.0772, 0.0857, 0.0864],\n",
      "          [0.0843, 0.0948, 0.1004,  ..., 0.0878, 0.0955, 0.0962]],\n",
      "\n",
      "         [[0.0169, 0.0028, 0.0028,  ..., 0.0119, 0.0147, 0.0133],\n",
      "          [0.0190, 0.0105, 0.0077,  ..., 0.0084, 0.0098, 0.0105],\n",
      "          [0.0162, 0.0140, 0.0147,  ..., 0.0049, 0.0091, 0.0162],\n",
      "          ...,\n",
      "          [0.0941, 0.0920, 0.0829,  ..., 0.0716, 0.0779, 0.0815],\n",
      "          [0.0857, 0.0878, 0.0899,  ..., 0.0772, 0.0857, 0.0864],\n",
      "          [0.0843, 0.0948, 0.1004,  ..., 0.0878, 0.0955, 0.0962]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0197, 0.0176, 0.0084,  ..., 0.0183, 0.0154, 0.0162],\n",
      "          [0.0176, 0.0183, 0.0098,  ..., 0.0133, 0.0133, 0.0162],\n",
      "          [0.0197, 0.0197, 0.0126,  ..., 0.0119, 0.0140, 0.0190],\n",
      "          ...,\n",
      "          [0.0653, 0.0604, 0.0674,  ..., 0.0787, 0.0723, 0.0674],\n",
      "          [0.0758, 0.0737, 0.0765,  ..., 0.0857, 0.0779, 0.0695],\n",
      "          [0.0815, 0.0716, 0.0730,  ..., 0.0787, 0.0787, 0.0794]],\n",
      "\n",
      "         [[0.0197, 0.0176, 0.0084,  ..., 0.0183, 0.0154, 0.0162],\n",
      "          [0.0176, 0.0183, 0.0098,  ..., 0.0133, 0.0133, 0.0162],\n",
      "          [0.0197, 0.0197, 0.0126,  ..., 0.0119, 0.0140, 0.0190],\n",
      "          ...,\n",
      "          [0.0653, 0.0604, 0.0674,  ..., 0.0787, 0.0723, 0.0674],\n",
      "          [0.0758, 0.0737, 0.0765,  ..., 0.0857, 0.0779, 0.0695],\n",
      "          [0.0815, 0.0716, 0.0730,  ..., 0.0787, 0.0787, 0.0794]],\n",
      "\n",
      "         [[0.0197, 0.0176, 0.0084,  ..., 0.0183, 0.0154, 0.0162],\n",
      "          [0.0176, 0.0183, 0.0098,  ..., 0.0133, 0.0133, 0.0162],\n",
      "          [0.0197, 0.0197, 0.0126,  ..., 0.0119, 0.0140, 0.0190],\n",
      "          ...,\n",
      "          [0.0653, 0.0604, 0.0674,  ..., 0.0787, 0.0723, 0.0674],\n",
      "          [0.0758, 0.0737, 0.0765,  ..., 0.0857, 0.0779, 0.0695],\n",
      "          [0.0815, 0.0716, 0.0730,  ..., 0.0787, 0.0787, 0.0794]]]],\n",
      "       dtype=torch.float64), tensor([0, 1, 0, 0, 0, 1, 1, 0]), ('lr/E34B1935_20120706_dicom_15401.dcm', 'lr_cat/E456D9EE_20140403_dicom_60109.dcm', 'lr/9A843A11_20041223_dicom_102345.dcm', 'lr/02E1D45F_20090303_dicom_87343.dcm', 'lr/E3A8212B_20091012_dicom_44263.dcm', 'lr_cat/9D31DCEC_20140125_dicom_47683.dcm', 'lr_cat/2ED1F316_20140520_dicom_85755.dcm', 'lr/9824A6B3_20111104_dicom_41953.dcm'), ('lr', 'lr', 'lr', 'lr', 'lr', 'lr', 'lr', 'lr')]\n",
      "[tensor([[[[0.0379, 0.0351, 0.0218,  ..., 0.0091, 0.0133, 0.0119],\n",
      "          [0.0176, 0.0351, 0.0295,  ..., 0.0070, 0.0183, 0.0218],\n",
      "          [0.0077, 0.0232, 0.0267,  ..., 0.0183, 0.0295, 0.0225],\n",
      "          ...,\n",
      "          [0.0744, 0.0758, 0.0611,  ..., 0.0541, 0.0527, 0.0597],\n",
      "          [0.0688, 0.0597, 0.0555,  ..., 0.0534, 0.0485, 0.0506],\n",
      "          [0.0604, 0.0562, 0.0576,  ..., 0.0576, 0.0499, 0.0499]],\n",
      "\n",
      "         [[0.0379, 0.0351, 0.0218,  ..., 0.0091, 0.0133, 0.0119],\n",
      "          [0.0176, 0.0351, 0.0295,  ..., 0.0070, 0.0183, 0.0218],\n",
      "          [0.0077, 0.0232, 0.0267,  ..., 0.0183, 0.0295, 0.0225],\n",
      "          ...,\n",
      "          [0.0744, 0.0758, 0.0611,  ..., 0.0541, 0.0527, 0.0597],\n",
      "          [0.0688, 0.0597, 0.0555,  ..., 0.0534, 0.0485, 0.0506],\n",
      "          [0.0604, 0.0562, 0.0576,  ..., 0.0576, 0.0499, 0.0499]],\n",
      "\n",
      "         [[0.0379, 0.0351, 0.0218,  ..., 0.0091, 0.0133, 0.0119],\n",
      "          [0.0176, 0.0351, 0.0295,  ..., 0.0070, 0.0183, 0.0218],\n",
      "          [0.0077, 0.0232, 0.0267,  ..., 0.0183, 0.0295, 0.0225],\n",
      "          ...,\n",
      "          [0.0744, 0.0758, 0.0611,  ..., 0.0541, 0.0527, 0.0597],\n",
      "          [0.0688, 0.0597, 0.0555,  ..., 0.0534, 0.0485, 0.0506],\n",
      "          [0.0604, 0.0562, 0.0576,  ..., 0.0576, 0.0499, 0.0499]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0119, 0.0126, 0.0154,  ..., 0.0176, 0.0197, 0.0183],\n",
      "          [0.0183, 0.0119, 0.0112,  ..., 0.0190, 0.0253, 0.0211],\n",
      "          [0.0176, 0.0140, 0.0112,  ..., 0.0274, 0.0281, 0.0183],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0183, 0.0190, 0.0112],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0133, 0.0204, 0.0246],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0176, 0.0126, 0.0225]],\n",
      "\n",
      "         [[0.0119, 0.0126, 0.0154,  ..., 0.0176, 0.0197, 0.0183],\n",
      "          [0.0183, 0.0119, 0.0112,  ..., 0.0190, 0.0253, 0.0211],\n",
      "          [0.0176, 0.0140, 0.0112,  ..., 0.0274, 0.0281, 0.0183],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0183, 0.0190, 0.0112],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0133, 0.0204, 0.0246],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0176, 0.0126, 0.0225]],\n",
      "\n",
      "         [[0.0119, 0.0126, 0.0154,  ..., 0.0176, 0.0197, 0.0183],\n",
      "          [0.0183, 0.0119, 0.0112,  ..., 0.0190, 0.0253, 0.0211],\n",
      "          [0.0176, 0.0140, 0.0112,  ..., 0.0274, 0.0281, 0.0183],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0183, 0.0190, 0.0112],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0133, 0.0204, 0.0246],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0176, 0.0126, 0.0225]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0112, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0190, 0.0154, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.3322, 0.3279, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.2346, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0112, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0190, 0.0154, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.3322, 0.3279, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.2346, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0112, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0190, 0.0154, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.3322, 0.3279, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.2346, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0140, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0197, 0.0154, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.2486, 0.1264, 0.0014],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0351, 0.0007, 0.0007],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0007, 0.0007, 0.0014]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0140, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0197, 0.0154, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.2486, 0.1264, 0.0014],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0351, 0.0007, 0.0007],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0007, 0.0007, 0.0014]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0140, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0197, 0.0154, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.2486, 0.1264, 0.0014],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0351, 0.0007, 0.0007],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0007, 0.0007, 0.0014]]],\n",
      "\n",
      "\n",
      "        [[[0.0070, 0.0133, 0.0176,  ..., 0.0162, 0.0162, 0.0190],\n",
      "          [0.0084, 0.0084, 0.0169,  ..., 0.0169, 0.0239, 0.0232],\n",
      "          [0.0119, 0.0084, 0.0119,  ..., 0.0232, 0.0295, 0.0183],\n",
      "          ...,\n",
      "          [0.2114, 0.2128, 0.2128,  ..., 0.3434, 0.3378, 0.3343],\n",
      "          [0.1243, 0.1278, 0.1222,  ..., 0.2170, 0.2149, 0.2100],\n",
      "          [0.1489, 0.1503, 0.1489,  ..., 0.1840, 0.1798, 0.1664]],\n",
      "\n",
      "         [[0.0070, 0.0133, 0.0176,  ..., 0.0162, 0.0162, 0.0190],\n",
      "          [0.0084, 0.0084, 0.0169,  ..., 0.0169, 0.0239, 0.0232],\n",
      "          [0.0119, 0.0084, 0.0119,  ..., 0.0232, 0.0295, 0.0183],\n",
      "          ...,\n",
      "          [0.2114, 0.2128, 0.2128,  ..., 0.3434, 0.3378, 0.3343],\n",
      "          [0.1243, 0.1278, 0.1222,  ..., 0.2170, 0.2149, 0.2100],\n",
      "          [0.1489, 0.1503, 0.1489,  ..., 0.1840, 0.1798, 0.1664]],\n",
      "\n",
      "         [[0.0070, 0.0133, 0.0176,  ..., 0.0162, 0.0162, 0.0190],\n",
      "          [0.0084, 0.0084, 0.0169,  ..., 0.0169, 0.0239, 0.0232],\n",
      "          [0.0119, 0.0084, 0.0119,  ..., 0.0232, 0.0295, 0.0183],\n",
      "          ...,\n",
      "          [0.2114, 0.2128, 0.2128,  ..., 0.3434, 0.3378, 0.3343],\n",
      "          [0.1243, 0.1278, 0.1222,  ..., 0.2170, 0.2149, 0.2100],\n",
      "          [0.1489, 0.1503, 0.1489,  ..., 0.1840, 0.1798, 0.1664]]]],\n",
      "       dtype=torch.float64), tensor([0, 0, 0, 1, 1, 0, 1, 0]), ('lr/FC80A842_20161116_dicom_80103.dcm', 'lr/6D3F0E6F_20110303_dicom_979.dcm', 'lr/98B8FF10_20101118_dicom_86639.dcm', 'lr_cat/8B88ADEE_20161013_dicom_67807.dcm', 'lr_cat/552F18FD_20080229_dicom_109072.dcm', 'lr/1FTLBM8K_20140605_dicom_209447.dcm', 'lr_cat/7285B288_20111116_dicom_70598.dcm', 'lr/01T07MCG_20150406_dicom_260857.dcm'), ('lr', 'lr', 'lr', 'lr', 'lr', 'lr', 'lr', 'lr')]\n",
      "[tensor([[[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.5112e-03,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.0225e-03,\n",
      "           4.9157e-03, 3.5112e-03],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0534e-02,\n",
      "           9.8315e-03, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.5112e-03,\n",
      "           3.5112e-03, 7.0225e-04],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.5112e-03,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.0225e-03,\n",
      "           4.9157e-03, 3.5112e-03],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0534e-02,\n",
      "           9.8315e-03, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.5112e-03,\n",
      "           3.5112e-03, 7.0225e-04],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.5112e-03,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.0225e-03,\n",
      "           4.9157e-03, 3.5112e-03],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0534e-02,\n",
      "           9.8315e-03, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.5112e-03,\n",
      "           3.5112e-03, 7.0225e-04],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[1.7556e-02, 1.8961e-02, 2.0365e-02,  ..., 1.1938e-02,\n",
      "           1.3343e-02, 1.4747e-02],\n",
      "          [1.6854e-02, 1.8258e-02, 1.8961e-02,  ..., 1.2640e-02,\n",
      "           1.5449e-02, 1.6854e-02],\n",
      "          [1.7556e-02, 1.9663e-02, 2.0365e-02,  ..., 1.4747e-02,\n",
      "           1.6854e-02, 1.8961e-02],\n",
      "          ...,\n",
      "          [2.0365e-02, 2.2472e-02, 2.4579e-02,  ..., 8.6376e-01,\n",
      "           8.2093e-01, 7.5632e-01],\n",
      "          [2.0365e-02, 2.0365e-02, 2.3174e-02,  ..., 6.8469e-01,\n",
      "           5.8848e-01, 4.7893e-01],\n",
      "          [1.8961e-02, 1.8961e-02, 2.1067e-02,  ..., 3.9115e-01,\n",
      "           2.9213e-01, 2.0154e-01]],\n",
      "\n",
      "         [[1.7556e-02, 1.8961e-02, 2.0365e-02,  ..., 1.1938e-02,\n",
      "           1.3343e-02, 1.4747e-02],\n",
      "          [1.6854e-02, 1.8258e-02, 1.8961e-02,  ..., 1.2640e-02,\n",
      "           1.5449e-02, 1.6854e-02],\n",
      "          [1.7556e-02, 1.9663e-02, 2.0365e-02,  ..., 1.4747e-02,\n",
      "           1.6854e-02, 1.8961e-02],\n",
      "          ...,\n",
      "          [2.0365e-02, 2.2472e-02, 2.4579e-02,  ..., 8.6376e-01,\n",
      "           8.2093e-01, 7.5632e-01],\n",
      "          [2.0365e-02, 2.0365e-02, 2.3174e-02,  ..., 6.8469e-01,\n",
      "           5.8848e-01, 4.7893e-01],\n",
      "          [1.8961e-02, 1.8961e-02, 2.1067e-02,  ..., 3.9115e-01,\n",
      "           2.9213e-01, 2.0154e-01]],\n",
      "\n",
      "         [[1.7556e-02, 1.8961e-02, 2.0365e-02,  ..., 1.1938e-02,\n",
      "           1.3343e-02, 1.4747e-02],\n",
      "          [1.6854e-02, 1.8258e-02, 1.8961e-02,  ..., 1.2640e-02,\n",
      "           1.5449e-02, 1.6854e-02],\n",
      "          [1.7556e-02, 1.9663e-02, 2.0365e-02,  ..., 1.4747e-02,\n",
      "           1.6854e-02, 1.8961e-02],\n",
      "          ...,\n",
      "          [2.0365e-02, 2.2472e-02, 2.4579e-02,  ..., 8.6376e-01,\n",
      "           8.2093e-01, 7.5632e-01],\n",
      "          [2.0365e-02, 2.0365e-02, 2.3174e-02,  ..., 6.8469e-01,\n",
      "           5.8848e-01, 4.7893e-01],\n",
      "          [1.8961e-02, 1.8961e-02, 2.1067e-02,  ..., 3.9115e-01,\n",
      "           2.9213e-01, 2.0154e-01]]],\n",
      "\n",
      "\n",
      "        [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.1067e-02,\n",
      "           1.1236e-02, 4.9157e-03],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.1938e-02,\n",
      "           1.4045e-03, 3.5112e-03],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.4045e-03,\n",
      "           5.6180e-03, 2.9494e-02],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.5815e-02,\n",
      "           4.2135e-02, 5.1264e-02],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.0028e-02,\n",
      "           5.8989e-02, 7.8652e-02],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.4270e-02,\n",
      "           1.2921e-01, 1.9312e-01]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.1067e-02,\n",
      "           1.1236e-02, 4.9157e-03],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.1938e-02,\n",
      "           1.4045e-03, 3.5112e-03],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.4045e-03,\n",
      "           5.6180e-03, 2.9494e-02],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.5815e-02,\n",
      "           4.2135e-02, 5.1264e-02],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.0028e-02,\n",
      "           5.8989e-02, 7.8652e-02],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.4270e-02,\n",
      "           1.2921e-01, 1.9312e-01]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.1067e-02,\n",
      "           1.1236e-02, 4.9157e-03],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.1938e-02,\n",
      "           1.4045e-03, 3.5112e-03],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.4045e-03,\n",
      "           5.6180e-03, 2.9494e-02],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.5815e-02,\n",
      "           4.2135e-02, 5.1264e-02],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.0028e-02,\n",
      "           5.8989e-02, 7.8652e-02],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.4270e-02,\n",
      "           1.2921e-01, 1.9312e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[2.1067e-02, 2.0365e-02, 1.4747e-02,  ..., 2.3174e-02,\n",
      "           1.8258e-02, 1.1938e-02],\n",
      "          [1.6152e-02, 1.9663e-02, 2.1067e-02,  ..., 1.7556e-02,\n",
      "           1.4045e-02, 1.4747e-02],\n",
      "          [1.7556e-02, 1.8961e-02, 1.7556e-02,  ..., 1.6854e-02,\n",
      "           2.1067e-02, 2.2472e-02],\n",
      "          ...,\n",
      "          [1.5449e-01, 1.2500e-01, 9.9017e-02,  ..., 1.3343e-01,\n",
      "           1.4958e-01, 1.8258e-01],\n",
      "          [3.1250e-01, 2.4087e-01, 1.8118e-01,  ..., 2.2683e-01,\n",
      "           2.8722e-01, 3.5744e-01],\n",
      "          [5.6531e-01, 4.5997e-01, 3.6728e-01,  ..., 4.1573e-01,\n",
      "           5.1264e-01, 6.1025e-01]],\n",
      "\n",
      "         [[2.1067e-02, 2.0365e-02, 1.4747e-02,  ..., 2.3174e-02,\n",
      "           1.8258e-02, 1.1938e-02],\n",
      "          [1.6152e-02, 1.9663e-02, 2.1067e-02,  ..., 1.7556e-02,\n",
      "           1.4045e-02, 1.4747e-02],\n",
      "          [1.7556e-02, 1.8961e-02, 1.7556e-02,  ..., 1.6854e-02,\n",
      "           2.1067e-02, 2.2472e-02],\n",
      "          ...,\n",
      "          [1.5449e-01, 1.2500e-01, 9.9017e-02,  ..., 1.3343e-01,\n",
      "           1.4958e-01, 1.8258e-01],\n",
      "          [3.1250e-01, 2.4087e-01, 1.8118e-01,  ..., 2.2683e-01,\n",
      "           2.8722e-01, 3.5744e-01],\n",
      "          [5.6531e-01, 4.5997e-01, 3.6728e-01,  ..., 4.1573e-01,\n",
      "           5.1264e-01, 6.1025e-01]],\n",
      "\n",
      "         [[2.1067e-02, 2.0365e-02, 1.4747e-02,  ..., 2.3174e-02,\n",
      "           1.8258e-02, 1.1938e-02],\n",
      "          [1.6152e-02, 1.9663e-02, 2.1067e-02,  ..., 1.7556e-02,\n",
      "           1.4045e-02, 1.4747e-02],\n",
      "          [1.7556e-02, 1.8961e-02, 1.7556e-02,  ..., 1.6854e-02,\n",
      "           2.1067e-02, 2.2472e-02],\n",
      "          ...,\n",
      "          [1.5449e-01, 1.2500e-01, 9.9017e-02,  ..., 1.3343e-01,\n",
      "           1.4958e-01, 1.8258e-01],\n",
      "          [3.1250e-01, 2.4087e-01, 1.8118e-01,  ..., 2.2683e-01,\n",
      "           2.8722e-01, 3.5744e-01],\n",
      "          [5.6531e-01, 4.5997e-01, 3.6728e-01,  ..., 4.1573e-01,\n",
      "           5.1264e-01, 6.1025e-01]]],\n",
      "\n",
      "\n",
      "        [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[2.1067e-03, 7.7247e-03, 1.1236e-02,  ..., 1.8961e-02,\n",
      "           1.6854e-02, 9.1292e-03],\n",
      "          [3.5112e-03, 6.3202e-03, 8.4270e-03,  ..., 2.2472e-02,\n",
      "           1.7556e-02, 8.4270e-03],\n",
      "          [9.8315e-03, 5.6180e-03, 9.8315e-03,  ..., 1.1236e-02,\n",
      "           1.1236e-02, 6.3202e-03],\n",
      "          ...,\n",
      "          [7.8652e-02, 8.2163e-02, 8.3567e-02,  ..., 8.9888e-02,\n",
      "           8.2163e-02, 1.0183e-01],\n",
      "          [9.0590e-02, 8.9185e-02, 9.2697e-02,  ..., 1.3694e-01,\n",
      "           1.5309e-01, 1.9944e-01],\n",
      "          [9.1994e-02, 8.7781e-02, 8.8483e-02,  ..., 2.4860e-01,\n",
      "           3.1390e-01, 4.0028e-01]],\n",
      "\n",
      "         [[2.1067e-03, 7.7247e-03, 1.1236e-02,  ..., 1.8961e-02,\n",
      "           1.6854e-02, 9.1292e-03],\n",
      "          [3.5112e-03, 6.3202e-03, 8.4270e-03,  ..., 2.2472e-02,\n",
      "           1.7556e-02, 8.4270e-03],\n",
      "          [9.8315e-03, 5.6180e-03, 9.8315e-03,  ..., 1.1236e-02,\n",
      "           1.1236e-02, 6.3202e-03],\n",
      "          ...,\n",
      "          [7.8652e-02, 8.2163e-02, 8.3567e-02,  ..., 8.9888e-02,\n",
      "           8.2163e-02, 1.0183e-01],\n",
      "          [9.0590e-02, 8.9185e-02, 9.2697e-02,  ..., 1.3694e-01,\n",
      "           1.5309e-01, 1.9944e-01],\n",
      "          [9.1994e-02, 8.7781e-02, 8.8483e-02,  ..., 2.4860e-01,\n",
      "           3.1390e-01, 4.0028e-01]],\n",
      "\n",
      "         [[2.1067e-03, 7.7247e-03, 1.1236e-02,  ..., 1.8961e-02,\n",
      "           1.6854e-02, 9.1292e-03],\n",
      "          [3.5112e-03, 6.3202e-03, 8.4270e-03,  ..., 2.2472e-02,\n",
      "           1.7556e-02, 8.4270e-03],\n",
      "          [9.8315e-03, 5.6180e-03, 9.8315e-03,  ..., 1.1236e-02,\n",
      "           1.1236e-02, 6.3202e-03],\n",
      "          ...,\n",
      "          [7.8652e-02, 8.2163e-02, 8.3567e-02,  ..., 8.9888e-02,\n",
      "           8.2163e-02, 1.0183e-01],\n",
      "          [9.0590e-02, 8.9185e-02, 9.2697e-02,  ..., 1.3694e-01,\n",
      "           1.5309e-01, 1.9944e-01],\n",
      "          [9.1994e-02, 8.7781e-02, 8.8483e-02,  ..., 2.4860e-01,\n",
      "           3.1390e-01, 4.0028e-01]]]], dtype=torch.float64), tensor([0, 1, 0, 0, 0, 1, 0, 0]), ('lr/A5B4290F_20070307_dicom_102798.dcm', 'lr_cat/6B32BD95_20100630_dicom_52407.dcm', 'lr/777F955D_20160407_dicom_55982.dcm', 'lr/27956E43_20100823_dicom_38760.dcm', 'lr/8AB819F2_20090618_dicom_60043.dcm', 'lr_cat/D58DCBDD_20131116_dicom_57045.dcm', 'lr/3737579_20140312_dicom_167895.dcm', 'lr/CBA0C50A_20130114_dicom_66164.dcm'), ('lr', 'lr', 'lr', 'lr', 'lr', 'lr', 'lr', 'lr')]\n",
      "[tensor([[[[0.0162, 0.0147, 0.0169,  ..., 0.0190, 0.0211, 0.0246],\n",
      "          [0.0154, 0.0140, 0.0154,  ..., 0.0211, 0.0204, 0.0197],\n",
      "          [0.0162, 0.0154, 0.0133,  ..., 0.0225, 0.0211, 0.0176],\n",
      "          ...,\n",
      "          [0.0976, 0.0969, 0.0920,  ..., 0.5597, 0.6081, 0.6404],\n",
      "          [0.1011, 0.0983, 0.0934,  ..., 0.6194, 0.6166, 0.5885],\n",
      "          [0.1004, 0.0976, 0.0941,  ..., 0.5162, 0.4670, 0.4059]],\n",
      "\n",
      "         [[0.0162, 0.0147, 0.0169,  ..., 0.0190, 0.0211, 0.0246],\n",
      "          [0.0154, 0.0140, 0.0154,  ..., 0.0211, 0.0204, 0.0197],\n",
      "          [0.0162, 0.0154, 0.0133,  ..., 0.0225, 0.0211, 0.0176],\n",
      "          ...,\n",
      "          [0.0976, 0.0969, 0.0920,  ..., 0.5597, 0.6081, 0.6404],\n",
      "          [0.1011, 0.0983, 0.0934,  ..., 0.6194, 0.6166, 0.5885],\n",
      "          [0.1004, 0.0976, 0.0941,  ..., 0.5162, 0.4670, 0.4059]],\n",
      "\n",
      "         [[0.0162, 0.0147, 0.0169,  ..., 0.0190, 0.0211, 0.0246],\n",
      "          [0.0154, 0.0140, 0.0154,  ..., 0.0211, 0.0204, 0.0197],\n",
      "          [0.0162, 0.0154, 0.0133,  ..., 0.0225, 0.0211, 0.0176],\n",
      "          ...,\n",
      "          [0.0976, 0.0969, 0.0920,  ..., 0.5597, 0.6081, 0.6404],\n",
      "          [0.1011, 0.0983, 0.0934,  ..., 0.6194, 0.6166, 0.5885],\n",
      "          [0.1004, 0.0976, 0.0941,  ..., 0.5162, 0.4670, 0.4059]]],\n",
      "\n",
      "\n",
      "        [[[0.0133, 0.0140, 0.0204,  ..., 0.0112, 0.0126, 0.0098],\n",
      "          [0.0154, 0.0126, 0.0084,  ..., 0.0084, 0.0084, 0.0077],\n",
      "          [0.0098, 0.0154, 0.0077,  ..., 0.0084, 0.0112, 0.0105],\n",
      "          ...,\n",
      "          [0.0899, 0.0962, 0.0927,  ..., 0.0892, 0.0871, 0.0871],\n",
      "          [0.0948, 0.0990, 0.0885,  ..., 0.0878, 0.0871, 0.0822],\n",
      "          [0.0969, 0.0878, 0.0787,  ..., 0.0808, 0.0885, 0.0857]],\n",
      "\n",
      "         [[0.0133, 0.0140, 0.0204,  ..., 0.0112, 0.0126, 0.0098],\n",
      "          [0.0154, 0.0126, 0.0084,  ..., 0.0084, 0.0084, 0.0077],\n",
      "          [0.0098, 0.0154, 0.0077,  ..., 0.0084, 0.0112, 0.0105],\n",
      "          ...,\n",
      "          [0.0899, 0.0962, 0.0927,  ..., 0.0892, 0.0871, 0.0871],\n",
      "          [0.0948, 0.0990, 0.0885,  ..., 0.0878, 0.0871, 0.0822],\n",
      "          [0.0969, 0.0878, 0.0787,  ..., 0.0808, 0.0885, 0.0857]],\n",
      "\n",
      "         [[0.0133, 0.0140, 0.0204,  ..., 0.0112, 0.0126, 0.0098],\n",
      "          [0.0154, 0.0126, 0.0084,  ..., 0.0084, 0.0084, 0.0077],\n",
      "          [0.0098, 0.0154, 0.0077,  ..., 0.0084, 0.0112, 0.0105],\n",
      "          ...,\n",
      "          [0.0899, 0.0962, 0.0927,  ..., 0.0892, 0.0871, 0.0871],\n",
      "          [0.0948, 0.0990, 0.0885,  ..., 0.0878, 0.0871, 0.0822],\n",
      "          [0.0969, 0.0878, 0.0787,  ..., 0.0808, 0.0885, 0.0857]]],\n",
      "\n",
      "\n",
      "        [[[0.0154, 0.0190, 0.0183,  ..., 0.0112, 0.0133, 0.0190],\n",
      "          [0.0147, 0.0204, 0.0190,  ..., 0.0133, 0.0154, 0.0154],\n",
      "          [0.0105, 0.0169, 0.0246,  ..., 0.0154, 0.0147, 0.0162],\n",
      "          ...,\n",
      "          [0.0857, 0.0751, 0.0744,  ..., 0.0864, 0.0772, 0.0772],\n",
      "          [0.0801, 0.0737, 0.0730,  ..., 0.0843, 0.0815, 0.0794],\n",
      "          [0.0737, 0.0744, 0.0787,  ..., 0.0801, 0.0801, 0.0850]],\n",
      "\n",
      "         [[0.0154, 0.0190, 0.0183,  ..., 0.0112, 0.0133, 0.0190],\n",
      "          [0.0147, 0.0204, 0.0190,  ..., 0.0133, 0.0154, 0.0154],\n",
      "          [0.0105, 0.0169, 0.0246,  ..., 0.0154, 0.0147, 0.0162],\n",
      "          ...,\n",
      "          [0.0857, 0.0751, 0.0744,  ..., 0.0864, 0.0772, 0.0772],\n",
      "          [0.0801, 0.0737, 0.0730,  ..., 0.0843, 0.0815, 0.0794],\n",
      "          [0.0737, 0.0744, 0.0787,  ..., 0.0801, 0.0801, 0.0850]],\n",
      "\n",
      "         [[0.0154, 0.0190, 0.0183,  ..., 0.0112, 0.0133, 0.0190],\n",
      "          [0.0147, 0.0204, 0.0190,  ..., 0.0133, 0.0154, 0.0154],\n",
      "          [0.0105, 0.0169, 0.0246,  ..., 0.0154, 0.0147, 0.0162],\n",
      "          ...,\n",
      "          [0.0857, 0.0751, 0.0744,  ..., 0.0864, 0.0772, 0.0772],\n",
      "          [0.0801, 0.0737, 0.0730,  ..., 0.0843, 0.0815, 0.0794],\n",
      "          [0.0737, 0.0744, 0.0787,  ..., 0.0801, 0.0801, 0.0850]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0246, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0246, 0.0042, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0843, 0.0730, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0808, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0246, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0246, 0.0042, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0843, 0.0730, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0808, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0246, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0246, 0.0042, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0843, 0.0730, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0808, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]],\n",
      "       dtype=torch.float64), tensor([1, 1, 0, 0, 1, 1, 0, 1]), ('lr_cat/EC4E20F0_20090401_dicom_46043.dcm', 'lr_cat/FADA2DBE_20050817_dicom_108595.dcm', 'lr/A8D66E08_20070309_dicom_37267.dcm', 'lr/A0C64B0A_20060920_dicom_71055.dcm', 'lr_cat/E290C929_20131112_dicom_12594.dcm', 'lr_cat/864A6EBF_20110202_dicom_95524.dcm', 'lr/8EF8FC2E_20160216_dicom_105003.dcm', 'lr_cat/D99A97A4_20120703_dicom_528.dcm'), ('lr', 'lr', 'lr', 'lr', 'lr', 'lr', 'lr', 'lr')]\n",
      "[tensor([[[[0.0147, 0.0190, 0.0133,  ..., 0.0197, 0.0218, 0.0197],\n",
      "          [0.0084, 0.0154, 0.0197,  ..., 0.0190, 0.0162, 0.0162],\n",
      "          [0.0147, 0.0169, 0.0176,  ..., 0.0140, 0.0154, 0.0176],\n",
      "          ...,\n",
      "          [0.0147, 0.0190, 0.0147,  ..., 0.0021, 0.0035, 0.0133],\n",
      "          [0.0218, 0.0140, 0.0126,  ..., 0.0112, 0.0126, 0.0183],\n",
      "          [0.0133, 0.0077, 0.0112,  ..., 0.0281, 0.0281, 0.0267]],\n",
      "\n",
      "         [[0.0147, 0.0190, 0.0133,  ..., 0.0197, 0.0218, 0.0197],\n",
      "          [0.0084, 0.0154, 0.0197,  ..., 0.0190, 0.0162, 0.0162],\n",
      "          [0.0147, 0.0169, 0.0176,  ..., 0.0140, 0.0154, 0.0176],\n",
      "          ...,\n",
      "          [0.0147, 0.0190, 0.0147,  ..., 0.0021, 0.0035, 0.0133],\n",
      "          [0.0218, 0.0140, 0.0126,  ..., 0.0112, 0.0126, 0.0183],\n",
      "          [0.0133, 0.0077, 0.0112,  ..., 0.0281, 0.0281, 0.0267]],\n",
      "\n",
      "         [[0.0147, 0.0190, 0.0133,  ..., 0.0197, 0.0218, 0.0197],\n",
      "          [0.0084, 0.0154, 0.0197,  ..., 0.0190, 0.0162, 0.0162],\n",
      "          [0.0147, 0.0169, 0.0176,  ..., 0.0140, 0.0154, 0.0176],\n",
      "          ...,\n",
      "          [0.0147, 0.0190, 0.0147,  ..., 0.0021, 0.0035, 0.0133],\n",
      "          [0.0218, 0.0140, 0.0126,  ..., 0.0112, 0.0126, 0.0183],\n",
      "          [0.0133, 0.0077, 0.0112,  ..., 0.0281, 0.0281, 0.0267]]],\n",
      "\n",
      "\n",
      "        [[[0.0126, 0.0246, 0.0204,  ..., 0.0084, 0.0084, 0.0105],\n",
      "          [0.0105, 0.0260, 0.0246,  ..., 0.0077, 0.0112, 0.0133],\n",
      "          [0.0112, 0.0190, 0.0246,  ..., 0.0091, 0.0147, 0.0105],\n",
      "          ...,\n",
      "          [0.7992, 0.7584, 0.6699,  ..., 0.0639, 0.0716, 0.0801],\n",
      "          [0.8294, 0.8455, 0.8048,  ..., 0.0723, 0.0730, 0.0822],\n",
      "          [0.6938, 0.7760, 0.8013,  ..., 0.0695, 0.0702, 0.0730]],\n",
      "\n",
      "         [[0.0126, 0.0246, 0.0204,  ..., 0.0084, 0.0084, 0.0105],\n",
      "          [0.0105, 0.0260, 0.0246,  ..., 0.0077, 0.0112, 0.0133],\n",
      "          [0.0112, 0.0190, 0.0246,  ..., 0.0091, 0.0147, 0.0105],\n",
      "          ...,\n",
      "          [0.7992, 0.7584, 0.6699,  ..., 0.0639, 0.0716, 0.0801],\n",
      "          [0.8294, 0.8455, 0.8048,  ..., 0.0723, 0.0730, 0.0822],\n",
      "          [0.6938, 0.7760, 0.8013,  ..., 0.0695, 0.0702, 0.0730]],\n",
      "\n",
      "         [[0.0126, 0.0246, 0.0204,  ..., 0.0084, 0.0084, 0.0105],\n",
      "          [0.0105, 0.0260, 0.0246,  ..., 0.0077, 0.0112, 0.0133],\n",
      "          [0.0112, 0.0190, 0.0246,  ..., 0.0091, 0.0147, 0.0105],\n",
      "          ...,\n",
      "          [0.7992, 0.7584, 0.6699,  ..., 0.0639, 0.0716, 0.0801],\n",
      "          [0.8294, 0.8455, 0.8048,  ..., 0.0723, 0.0730, 0.0822],\n",
      "          [0.6938, 0.7760, 0.8013,  ..., 0.0695, 0.0702, 0.0730]]],\n",
      "\n",
      "\n",
      "        [[[0.0077, 0.0176, 0.0105,  ..., 0.0169, 0.0105, 0.0140],\n",
      "          [0.0042, 0.0176, 0.0091,  ..., 0.0169, 0.0112, 0.0211],\n",
      "          [0.0126, 0.0225, 0.0147,  ..., 0.0112, 0.0211, 0.0295],\n",
      "          ...,\n",
      "          [0.1440, 0.1383, 0.1341,  ..., 0.1517, 0.1580, 0.1496],\n",
      "          [0.1292, 0.1320, 0.1306,  ..., 0.1404, 0.1517, 0.1397],\n",
      "          [0.1215, 0.1313, 0.1306,  ..., 0.1306, 0.1426, 0.1320]],\n",
      "\n",
      "         [[0.0077, 0.0176, 0.0105,  ..., 0.0169, 0.0105, 0.0140],\n",
      "          [0.0042, 0.0176, 0.0091,  ..., 0.0169, 0.0112, 0.0211],\n",
      "          [0.0126, 0.0225, 0.0147,  ..., 0.0112, 0.0211, 0.0295],\n",
      "          ...,\n",
      "          [0.1440, 0.1383, 0.1341,  ..., 0.1517, 0.1580, 0.1496],\n",
      "          [0.1292, 0.1320, 0.1306,  ..., 0.1404, 0.1517, 0.1397],\n",
      "          [0.1215, 0.1313, 0.1306,  ..., 0.1306, 0.1426, 0.1320]],\n",
      "\n",
      "         [[0.0077, 0.0176, 0.0105,  ..., 0.0169, 0.0105, 0.0140],\n",
      "          [0.0042, 0.0176, 0.0091,  ..., 0.0169, 0.0112, 0.0211],\n",
      "          [0.0126, 0.0225, 0.0147,  ..., 0.0112, 0.0211, 0.0295],\n",
      "          ...,\n",
      "          [0.1440, 0.1383, 0.1341,  ..., 0.1517, 0.1580, 0.1496],\n",
      "          [0.1292, 0.1320, 0.1306,  ..., 0.1404, 0.1517, 0.1397],\n",
      "          [0.1215, 0.1313, 0.1306,  ..., 0.1306, 0.1426, 0.1320]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0225, 0.0232, 0.0162,  ..., 0.0147, 0.0218, 0.0211],\n",
      "          [0.0091, 0.0133, 0.0218,  ..., 0.0239, 0.0190, 0.0112],\n",
      "          [0.0176, 0.0091, 0.0169,  ..., 0.0169, 0.0105, 0.0119],\n",
      "          ...,\n",
      "          [0.0133, 0.0183, 0.0147,  ..., 0.0204, 0.0239, 0.0176],\n",
      "          [0.0140, 0.0133, 0.0091,  ..., 0.0162, 0.0140, 0.0112],\n",
      "          [0.0063, 0.0042, 0.0021,  ..., 0.0225, 0.0154, 0.0084]],\n",
      "\n",
      "         [[0.0225, 0.0232, 0.0162,  ..., 0.0147, 0.0218, 0.0211],\n",
      "          [0.0091, 0.0133, 0.0218,  ..., 0.0239, 0.0190, 0.0112],\n",
      "          [0.0176, 0.0091, 0.0169,  ..., 0.0169, 0.0105, 0.0119],\n",
      "          ...,\n",
      "          [0.0133, 0.0183, 0.0147,  ..., 0.0204, 0.0239, 0.0176],\n",
      "          [0.0140, 0.0133, 0.0091,  ..., 0.0162, 0.0140, 0.0112],\n",
      "          [0.0063, 0.0042, 0.0021,  ..., 0.0225, 0.0154, 0.0084]],\n",
      "\n",
      "         [[0.0225, 0.0232, 0.0162,  ..., 0.0147, 0.0218, 0.0211],\n",
      "          [0.0091, 0.0133, 0.0218,  ..., 0.0239, 0.0190, 0.0112],\n",
      "          [0.0176, 0.0091, 0.0169,  ..., 0.0169, 0.0105, 0.0119],\n",
      "          ...,\n",
      "          [0.0133, 0.0183, 0.0147,  ..., 0.0204, 0.0239, 0.0176],\n",
      "          [0.0140, 0.0133, 0.0091,  ..., 0.0162, 0.0140, 0.0112],\n",
      "          [0.0063, 0.0042, 0.0021,  ..., 0.0225, 0.0154, 0.0084]]],\n",
      "\n",
      "\n",
      "        [[[0.0098, 0.0147, 0.0204,  ..., 0.0176, 0.0147, 0.0183],\n",
      "          [0.0133, 0.0112, 0.0119,  ..., 0.0211, 0.0197, 0.0232],\n",
      "          [0.0147, 0.0204, 0.0162,  ..., 0.0162, 0.0204, 0.0204],\n",
      "          ...,\n",
      "          [0.0765, 0.0779, 0.0829,  ..., 0.0871, 0.0850, 0.0934],\n",
      "          [0.0772, 0.0787, 0.0892,  ..., 0.0871, 0.0829, 0.0843],\n",
      "          [0.0716, 0.0772, 0.0843,  ..., 0.0801, 0.0815, 0.0815]],\n",
      "\n",
      "         [[0.0098, 0.0147, 0.0204,  ..., 0.0176, 0.0147, 0.0183],\n",
      "          [0.0133, 0.0112, 0.0119,  ..., 0.0211, 0.0197, 0.0232],\n",
      "          [0.0147, 0.0204, 0.0162,  ..., 0.0162, 0.0204, 0.0204],\n",
      "          ...,\n",
      "          [0.0765, 0.0779, 0.0829,  ..., 0.0871, 0.0850, 0.0934],\n",
      "          [0.0772, 0.0787, 0.0892,  ..., 0.0871, 0.0829, 0.0843],\n",
      "          [0.0716, 0.0772, 0.0843,  ..., 0.0801, 0.0815, 0.0815]],\n",
      "\n",
      "         [[0.0098, 0.0147, 0.0204,  ..., 0.0176, 0.0147, 0.0183],\n",
      "          [0.0133, 0.0112, 0.0119,  ..., 0.0211, 0.0197, 0.0232],\n",
      "          [0.0147, 0.0204, 0.0162,  ..., 0.0162, 0.0204, 0.0204],\n",
      "          ...,\n",
      "          [0.0765, 0.0779, 0.0829,  ..., 0.0871, 0.0850, 0.0934],\n",
      "          [0.0772, 0.0787, 0.0892,  ..., 0.0871, 0.0829, 0.0843],\n",
      "          [0.0716, 0.0772, 0.0843,  ..., 0.0801, 0.0815, 0.0815]]],\n",
      "\n",
      "\n",
      "        [[[0.0169, 0.0140, 0.0154,  ..., 0.0126, 0.0098, 0.0112],\n",
      "          [0.0183, 0.0140, 0.0126,  ..., 0.0119, 0.0098, 0.0126],\n",
      "          [0.0119, 0.0147, 0.0147,  ..., 0.0119, 0.0133, 0.0162],\n",
      "          ...,\n",
      "          [0.0808, 0.0815, 0.0801,  ..., 0.0744, 0.0794, 0.0801],\n",
      "          [0.0667, 0.0681, 0.0772,  ..., 0.0765, 0.0801, 0.0843],\n",
      "          [0.0646, 0.0646, 0.0716,  ..., 0.0779, 0.0779, 0.0829]],\n",
      "\n",
      "         [[0.0169, 0.0140, 0.0154,  ..., 0.0126, 0.0098, 0.0112],\n",
      "          [0.0183, 0.0140, 0.0126,  ..., 0.0119, 0.0098, 0.0126],\n",
      "          [0.0119, 0.0147, 0.0147,  ..., 0.0119, 0.0133, 0.0162],\n",
      "          ...,\n",
      "          [0.0808, 0.0815, 0.0801,  ..., 0.0744, 0.0794, 0.0801],\n",
      "          [0.0667, 0.0681, 0.0772,  ..., 0.0765, 0.0801, 0.0843],\n",
      "          [0.0646, 0.0646, 0.0716,  ..., 0.0779, 0.0779, 0.0829]],\n",
      "\n",
      "         [[0.0169, 0.0140, 0.0154,  ..., 0.0126, 0.0098, 0.0112],\n",
      "          [0.0183, 0.0140, 0.0126,  ..., 0.0119, 0.0098, 0.0126],\n",
      "          [0.0119, 0.0147, 0.0147,  ..., 0.0119, 0.0133, 0.0162],\n",
      "          ...,\n",
      "          [0.0808, 0.0815, 0.0801,  ..., 0.0744, 0.0794, 0.0801],\n",
      "          [0.0667, 0.0681, 0.0772,  ..., 0.0765, 0.0801, 0.0843],\n",
      "          [0.0646, 0.0646, 0.0716,  ..., 0.0779, 0.0779, 0.0829]]]],\n",
      "       dtype=torch.float64), tensor([1, 0, 1, 1, 1, 1, 0, 1]), ('lr_cat/0003AQC8_20140814_dicom_185038.dcm', 'lr/E21C60A0_20101014_dicom_52494.dcm', 'lr_cat/01SBTGBM_20140524_dicom_286070.dcm', 'lr_cat/BD924F3A_20090202_dicom_40664.dcm', 'lr_cat/84B010F9_20080514_dicom_58123.dcm', 'lr_cat/4A4A3501_20150914_dicom_89865.dcm', 'lr/3E6EA3F7_20080228_dicom_88722.dcm', 'lr_cat/2C7B7001_20051212_dicom_54329.dcm'), ('lr', 'lr', 'lr', 'lr', 'lr', 'lr', 'lr', 'lr')]\n",
      "[tensor([[[[0.0140, 0.0147, 0.0162,  ..., 0.0154, 0.0253, 0.0225],\n",
      "          [0.0162, 0.0133, 0.0119,  ..., 0.0218, 0.0232, 0.0218],\n",
      "          [0.0204, 0.0126, 0.0119,  ..., 0.0183, 0.0204, 0.0260],\n",
      "          ...,\n",
      "          [0.0197, 0.0225, 0.0239,  ..., 0.0169, 0.0162, 0.0176],\n",
      "          [0.0162, 0.0190, 0.0183,  ..., 0.0176, 0.0133, 0.0112],\n",
      "          [0.0169, 0.0197, 0.0183,  ..., 0.0183, 0.0183, 0.0176]],\n",
      "\n",
      "         [[0.0140, 0.0147, 0.0162,  ..., 0.0154, 0.0253, 0.0225],\n",
      "          [0.0162, 0.0133, 0.0119,  ..., 0.0218, 0.0232, 0.0218],\n",
      "          [0.0204, 0.0126, 0.0119,  ..., 0.0183, 0.0204, 0.0260],\n",
      "          ...,\n",
      "          [0.0197, 0.0225, 0.0239,  ..., 0.0169, 0.0162, 0.0176],\n",
      "          [0.0162, 0.0190, 0.0183,  ..., 0.0176, 0.0133, 0.0112],\n",
      "          [0.0169, 0.0197, 0.0183,  ..., 0.0183, 0.0183, 0.0176]],\n",
      "\n",
      "         [[0.0140, 0.0147, 0.0162,  ..., 0.0154, 0.0253, 0.0225],\n",
      "          [0.0162, 0.0133, 0.0119,  ..., 0.0218, 0.0232, 0.0218],\n",
      "          [0.0204, 0.0126, 0.0119,  ..., 0.0183, 0.0204, 0.0260],\n",
      "          ...,\n",
      "          [0.0197, 0.0225, 0.0239,  ..., 0.0169, 0.0162, 0.0176],\n",
      "          [0.0162, 0.0190, 0.0183,  ..., 0.0176, 0.0133, 0.0112],\n",
      "          [0.0169, 0.0197, 0.0183,  ..., 0.0183, 0.0183, 0.0176]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0997, 0.1060, 0.1173,  ..., 0.1159, 0.1243, 0.1257],\n",
      "          [0.1060, 0.1159, 0.1208,  ..., 0.1131, 0.1194, 0.1313],\n",
      "          [0.1236, 0.1243, 0.1103,  ..., 0.1327, 0.1236, 0.1243]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0997, 0.1060, 0.1173,  ..., 0.1159, 0.1243, 0.1257],\n",
      "          [0.1060, 0.1159, 0.1208,  ..., 0.1131, 0.1194, 0.1313],\n",
      "          [0.1236, 0.1243, 0.1103,  ..., 0.1327, 0.1236, 0.1243]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0997, 0.1060, 0.1173,  ..., 0.1159, 0.1243, 0.1257],\n",
      "          [0.1060, 0.1159, 0.1208,  ..., 0.1131, 0.1194, 0.1313],\n",
      "          [0.1236, 0.1243, 0.1103,  ..., 0.1327, 0.1236, 0.1243]]],\n",
      "\n",
      "\n",
      "        [[[0.0154, 0.0183, 0.0197,  ..., 0.0211, 0.0218, 0.0140],\n",
      "          [0.0154, 0.0176, 0.0176,  ..., 0.0169, 0.0154, 0.0140],\n",
      "          [0.0154, 0.0190, 0.0204,  ..., 0.0140, 0.0126, 0.0162],\n",
      "          ...,\n",
      "          [0.0063, 0.0056, 0.0140,  ..., 0.0169, 0.0169, 0.0133],\n",
      "          [0.0070, 0.0133, 0.0232,  ..., 0.0133, 0.0197, 0.0211],\n",
      "          [0.0154, 0.0204, 0.0204,  ..., 0.0098, 0.0091, 0.0126]],\n",
      "\n",
      "         [[0.0154, 0.0183, 0.0197,  ..., 0.0211, 0.0218, 0.0140],\n",
      "          [0.0154, 0.0176, 0.0176,  ..., 0.0169, 0.0154, 0.0140],\n",
      "          [0.0154, 0.0190, 0.0204,  ..., 0.0140, 0.0126, 0.0162],\n",
      "          ...,\n",
      "          [0.0063, 0.0056, 0.0140,  ..., 0.0169, 0.0169, 0.0133],\n",
      "          [0.0070, 0.0133, 0.0232,  ..., 0.0133, 0.0197, 0.0211],\n",
      "          [0.0154, 0.0204, 0.0204,  ..., 0.0098, 0.0091, 0.0126]],\n",
      "\n",
      "         [[0.0154, 0.0183, 0.0197,  ..., 0.0211, 0.0218, 0.0140],\n",
      "          [0.0154, 0.0176, 0.0176,  ..., 0.0169, 0.0154, 0.0140],\n",
      "          [0.0154, 0.0190, 0.0204,  ..., 0.0140, 0.0126, 0.0162],\n",
      "          ...,\n",
      "          [0.0063, 0.0056, 0.0140,  ..., 0.0169, 0.0169, 0.0133],\n",
      "          [0.0070, 0.0133, 0.0232,  ..., 0.0133, 0.0197, 0.0211],\n",
      "          [0.0154, 0.0204, 0.0204,  ..., 0.0098, 0.0091, 0.0126]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0112, 0.0162, 0.0211],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0147, 0.0197, 0.0267],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0225, 0.0176, 0.0190],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.3982, 0.4024, 0.4087],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.2921, 0.2992, 0.2963],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.2261, 0.2346, 0.2261]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0112, 0.0162, 0.0211],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0147, 0.0197, 0.0267],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0225, 0.0176, 0.0190],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.3982, 0.4024, 0.4087],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.2921, 0.2992, 0.2963],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.2261, 0.2346, 0.2261]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0112, 0.0162, 0.0211],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0147, 0.0197, 0.0267],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0225, 0.0176, 0.0190],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.3982, 0.4024, 0.4087],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.2921, 0.2992, 0.2963],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.2261, 0.2346, 0.2261]]],\n",
      "\n",
      "\n",
      "        [[[0.0176, 0.0105, 0.0063,  ..., 0.0183, 0.0098, 0.0119],\n",
      "          [0.0183, 0.0162, 0.0091,  ..., 0.0162, 0.0070, 0.0154],\n",
      "          [0.0154, 0.0169, 0.0154,  ..., 0.0077, 0.0091, 0.0190],\n",
      "          ...,\n",
      "          [0.0063, 0.0077, 0.0119,  ..., 0.0218, 0.0218, 0.0190],\n",
      "          [0.0133, 0.0239, 0.0204,  ..., 0.0147, 0.0204, 0.0253],\n",
      "          [0.0126, 0.0183, 0.0119,  ..., 0.0091, 0.0133, 0.0225]],\n",
      "\n",
      "         [[0.0176, 0.0105, 0.0063,  ..., 0.0183, 0.0098, 0.0119],\n",
      "          [0.0183, 0.0162, 0.0091,  ..., 0.0162, 0.0070, 0.0154],\n",
      "          [0.0154, 0.0169, 0.0154,  ..., 0.0077, 0.0091, 0.0190],\n",
      "          ...,\n",
      "          [0.0063, 0.0077, 0.0119,  ..., 0.0218, 0.0218, 0.0190],\n",
      "          [0.0133, 0.0239, 0.0204,  ..., 0.0147, 0.0204, 0.0253],\n",
      "          [0.0126, 0.0183, 0.0119,  ..., 0.0091, 0.0133, 0.0225]],\n",
      "\n",
      "         [[0.0176, 0.0105, 0.0063,  ..., 0.0183, 0.0098, 0.0119],\n",
      "          [0.0183, 0.0162, 0.0091,  ..., 0.0162, 0.0070, 0.0154],\n",
      "          [0.0154, 0.0169, 0.0154,  ..., 0.0077, 0.0091, 0.0190],\n",
      "          ...,\n",
      "          [0.0063, 0.0077, 0.0119,  ..., 0.0218, 0.0218, 0.0190],\n",
      "          [0.0133, 0.0239, 0.0204,  ..., 0.0147, 0.0204, 0.0253],\n",
      "          [0.0126, 0.0183, 0.0119,  ..., 0.0091, 0.0133, 0.0225]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0056, 0.0119, 0.0077],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0154, 0.0098, 0.0007],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0070, 0.0014, 0.0183],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0119, 0.0014, 0.0183],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0302, 0.0183, 0.0042],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0063, 0.0232, 0.0190]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0056, 0.0119, 0.0077],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0154, 0.0098, 0.0007],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0070, 0.0014, 0.0183],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0119, 0.0014, 0.0183],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0302, 0.0183, 0.0042],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0063, 0.0232, 0.0190]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0056, 0.0119, 0.0077],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0154, 0.0098, 0.0007],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0070, 0.0014, 0.0183],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0119, 0.0014, 0.0183],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0302, 0.0183, 0.0042],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0063, 0.0232, 0.0190]]]],\n",
      "       dtype=torch.float64), tensor([1, 0, 0, 0, 1, 0, 1, 1]), ('lr_cat/7DCEBB7B_20061009_dicom_77662.dcm', 'lr/CB5985AC_20160702_dicom_100397.dcm', 'lr/D1381C6B_20131129_dicom_61557.dcm', 'lr/CF690BF0_20090616_dicom_47320.dcm', 'lr_cat/78F3536F_20111214_dicom_115508.dcm', 'lr/06KRARBZ_20140822_dicom_197448.dcm', 'lr_cat/7A072463_20090327_dicom_59465.dcm', 'lr_cat/06KG98BK_20140701_dicom_192433.dcm'), ('lr', 'lr', 'lr', 'lr', 'lr', 'lr', 'lr', 'lr')]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3a566b024729>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for x,y in model.train_dataloader():\n",
    "    print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Candid (new)",
   "language": "python",
   "name": "candid2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
