{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from catinous.CatsinomModelGramCache import CatsinomModelGramCache\n",
    "from catinous import utils as cutils\n",
    "from catinous import CatsinomDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import pytorch_lightning as pl\n",
    "import sklearn \n",
    "from sklearn.metrics import confusion_matrix, auc, roc_curve\n",
    "import torch\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from py_jotools import mut, slurm\n",
    "import numpy as np\n",
    "import gc\n",
    "import hashlib\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams={'continous':False,\n",
    "         'datasetfile': 'catsinom_lr_dataset.csv',\n",
    "         'noncontinous_train_splits': ['base_train']}\n",
    "# pllogger = cutils.pllogger(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:No continous learning, following parameters are invalidated: \n",
      "transition_phase_after \n",
      "cachemaximum \n",
      "use_cache \n",
      "random_cache \n",
      "force_misclassified \n",
      "direction\n",
      "INFO:root:gpu available: True, used: True\n",
      "INFO:root:VISIBLE GPUS: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 8,\n",
      " 'cachemaximum': 128,\n",
      " 'continous': False,\n",
      " 'datasetfile': 'catsinom_lr_dataset.csv',\n",
      " 'direction': 'lr->hr',\n",
      " 'force_misclassified': False,\n",
      " 'noncontinous_steps': 3000,\n",
      " 'noncontinous_train_splits': ['base_train'],\n",
      " 'random_cache': True,\n",
      " 'root_dir': '/project/catinous/cat_data/',\n",
      " 'run_postfix': '1',\n",
      " 'training_batch_size': 8,\n",
      " 'transition_phase_after': 0.7,\n",
      " 'use_cache': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\n",
      "              Name               Type Params\n",
      "0            model             ResNet   24 M\n",
      "1      model.conv1             Conv2d    9 K\n",
      "2        model.bn1        BatchNorm2d  128  \n",
      "3       model.relu               ReLU    0  \n",
      "4    model.maxpool          MaxPool2d    0  \n",
      "..             ...                ...    ...\n",
      "150       model.fc         Sequential    1 M\n",
      "151     model.fc.0             Linear    1 M\n",
      "152     model.fc.1        BatchNorm1d    1 K\n",
      "153     model.fc.2             Linear  513  \n",
      "154           loss  BCEWithLogitsLoss    0  \n",
      "\n",
      "[155 rows x 3 columns]\n",
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/3095 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 3/3095 [00:01<29:12,  1.76batch/s, batch_idx=2, gpu=0, loss=0.882, v_num=2]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-9992c1f3b6a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpllogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_check_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_gpu_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;31m# ON CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/trainer/distrib_parts.py\u001b[0m in \u001b[0;36msingle_gpu_train\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pretrain_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdp_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_pretrain_routine\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;31m# CORE TRAINING LOOP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;31m# RUN TNG EPOCH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0;31m# -----------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# update LR schedulers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;31m# RUN TRAIN STEP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# ---------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m             \u001b[0mbatch_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm_dic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_step_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_batch\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m                 \u001b[0;31m# track total loss for logging (avoid mem leaks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_loss_value\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m                 \u001b[0;31m# gradient update with accumulated gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = CatsinomModelGramCache(hparams=hparams, device=torch.device('cuda'))\n",
    "logger = cutils.pllogger(model.hparams)\n",
    "trainer = Trainer(gpus=1, max_epochs=1, early_stop_callback=False, logger=logger, val_check_interval=3000, show_progress_bar=True, checkpoint_callback=False)\n",
    "trainer.fit(model)\n",
    "torch.save(model.state_dict(), '/project/catinous/trained_models/' + expname + '_run_'+str(i)+'.pt')\n",
    "save_cache_to_csv(model.trainingscache.cachelist, '/project/catinous/trained_cache/' + expname + '_run_'+str(i)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:gpu available: True, used: True\n",
      "INFO:root:VISIBLE GPUS: 0\n",
      "INFO:root:\n",
      "              Name               Type Params\n",
      "0            model             ResNet   24 M\n",
      "1      model.conv1             Conv2d    9 K\n",
      "2        model.bn1        BatchNorm2d  128  \n",
      "3       model.relu               ReLU    0  \n",
      "4    model.maxpool          MaxPool2d    0  \n",
      "..             ...                ...    ...\n",
      "150       model.fc         Sequential    1 M\n",
      "151     model.fc.0             Linear    1 M\n",
      "152     model.fc.1        BatchNorm1d    1 K\n",
      "153     model.fc.2             Linear  513  \n",
      "154           loss  BCEWithLogitsLoss    0  \n",
      "\n",
      "[155 rows x 3 columns]\n",
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/3095 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  97%|█████████▋| 3000/3095 [14:02<00:30,  3.12batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Validating:   0%|          | 0/95 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 3001/3095 [14:02<00:33,  2.84batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  97%|█████████▋| 3002/3095 [14:03<00:29,  3.19batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  97%|█████████▋| 3003/3095 [14:03<00:27,  3.35batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  97%|█████████▋| 3004/3095 [14:03<00:24,  3.65batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  97%|█████████▋| 3005/3095 [14:03<00:23,  3.81batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  97%|█████████▋| 3006/3095 [14:04<00:23,  3.81batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  97%|█████████▋| 3007/3095 [14:04<00:22,  3.97batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  97%|█████████▋| 3008/3095 [14:04<00:20,  4.17batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  97%|█████████▋| 3009/3095 [14:04<00:21,  4.07batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  97%|█████████▋| 3010/3095 [14:05<00:20,  4.11batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  97%|█████████▋| 3011/3095 [14:05<00:20,  4.16batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  97%|█████████▋| 3012/3095 [14:05<00:20,  4.12batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  97%|█████████▋| 3013/3095 [14:05<00:19,  4.18batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  97%|█████████▋| 3014/3095 [14:06<00:19,  4.12batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  97%|█████████▋| 3015/3095 [14:06<00:18,  4.26batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  97%|█████████▋| 3016/3095 [14:06<00:19,  4.05batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  97%|█████████▋| 3017/3095 [14:06<00:18,  4.17batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  98%|█████████▊| 3018/3095 [14:06<00:18,  4.15batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  98%|█████████▊| 3019/3095 [14:07<00:18,  4.19batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  98%|█████████▊| 3020/3095 [14:07<00:17,  4.20batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  98%|█████████▊| 3021/3095 [14:07<00:17,  4.17batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  98%|█████████▊| 3022/3095 [14:07<00:18,  4.03batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  98%|█████████▊| 3023/3095 [14:08<00:17,  4.10batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  98%|█████████▊| 3024/3095 [14:08<00:17,  4.04batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  98%|█████████▊| 3025/3095 [14:08<00:16,  4.12batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  98%|█████████▊| 3026/3095 [14:08<00:16,  4.26batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  98%|█████████▊| 3027/3095 [14:09<00:16,  4.19batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  98%|█████████▊| 3028/3095 [14:09<00:16,  4.09batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  98%|█████████▊| 3029/3095 [14:09<00:16,  4.01batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  98%|█████████▊| 3030/3095 [14:09<00:15,  4.28batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  98%|█████████▊| 3031/3095 [14:10<00:15,  4.08batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  98%|█████████▊| 3032/3095 [14:10<00:15,  4.02batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  98%|█████████▊| 3033/3095 [14:10<00:15,  3.97batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  98%|█████████▊| 3034/3095 [14:10<00:15,  3.84batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  98%|█████████▊| 3035/3095 [14:11<00:15,  3.94batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  98%|█████████▊| 3036/3095 [14:11<00:14,  3.98batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  98%|█████████▊| 3037/3095 [14:11<00:14,  3.97batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  98%|█████████▊| 3038/3095 [14:11<00:14,  4.02batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  98%|█████████▊| 3039/3095 [14:12<00:13,  4.20batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  98%|█████████▊| 3040/3095 [14:12<00:13,  4.01batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  98%|█████████▊| 3041/3095 [14:12<00:13,  4.09batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  98%|█████████▊| 3042/3095 [14:12<00:13,  3.89batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  98%|█████████▊| 3043/3095 [14:13<00:12,  4.07batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  98%|█████████▊| 3044/3095 [14:13<00:12,  4.08batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  98%|█████████▊| 3045/3095 [14:13<00:12,  4.11batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  98%|█████████▊| 3046/3095 [14:13<00:11,  4.09batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  98%|█████████▊| 3047/3095 [14:14<00:11,  4.17batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  98%|█████████▊| 3048/3095 [14:14<00:11,  4.21batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  99%|█████████▊| 3049/3095 [14:14<00:10,  4.32batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  99%|█████████▊| 3050/3095 [14:14<00:10,  4.20batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  99%|█████████▊| 3051/3095 [14:15<00:10,  4.31batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  99%|█████████▊| 3052/3095 [14:15<00:09,  4.47batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  99%|█████████▊| 3053/3095 [14:15<00:09,  4.56batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  99%|█████████▊| 3054/3095 [14:15<00:09,  4.46batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  99%|█████████▊| 3055/3095 [14:15<00:08,  4.70batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  99%|█████████▊| 3056/3095 [14:16<00:08,  4.53batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  99%|█████████▉| 3057/3095 [14:16<00:08,  4.44batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  99%|█████████▉| 3058/3095 [14:16<00:08,  4.40batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  99%|█████████▉| 3059/3095 [14:16<00:08,  4.43batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  99%|█████████▉| 3060/3095 [14:16<00:07,  4.56batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  99%|█████████▉| 3061/3095 [14:17<00:07,  4.44batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  99%|█████████▉| 3062/3095 [14:17<00:07,  4.54batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  99%|█████████▉| 3063/3095 [14:17<00:06,  4.59batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  99%|█████████▉| 3064/3095 [14:17<00:06,  4.73batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  99%|█████████▉| 3065/3095 [14:18<00:06,  4.67batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  99%|█████████▉| 3066/3095 [14:18<00:06,  4.44batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  99%|█████████▉| 3067/3095 [14:18<00:06,  4.25batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  99%|█████████▉| 3068/3095 [14:18<00:06,  4.42batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  99%|█████████▉| 3069/3095 [14:19<00:06,  4.26batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  99%|█████████▉| 3070/3095 [14:19<00:05,  4.24batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  99%|█████████▉| 3071/3095 [14:19<00:05,  4.22batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  99%|█████████▉| 3072/3095 [14:19<00:05,  4.15batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  99%|█████████▉| 3073/3095 [14:19<00:05,  4.12batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  99%|█████████▉| 3074/3095 [14:20<00:05,  4.11batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  99%|█████████▉| 3075/3095 [14:20<00:04,  4.27batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  99%|█████████▉| 3076/3095 [14:20<00:04,  4.33batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  99%|█████████▉| 3077/3095 [14:20<00:04,  4.17batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  99%|█████████▉| 3078/3095 [14:21<00:04,  4.12batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1:  99%|█████████▉| 3079/3095 [14:21<00:03,  4.03batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1: 100%|█████████▉| 3080/3095 [14:21<00:03,  4.01batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1: 100%|█████████▉| 3081/3095 [14:21<00:03,  4.20batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1: 100%|█████████▉| 3082/3095 [14:22<00:03,  4.18batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1: 100%|█████████▉| 3083/3095 [14:22<00:02,  4.09batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1: 100%|█████████▉| 3084/3095 [14:22<00:02,  4.15batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1: 100%|█████████▉| 3085/3095 [14:22<00:02,  4.40batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1: 100%|█████████▉| 3086/3095 [14:23<00:02,  4.26batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1: 100%|█████████▉| 3087/3095 [14:23<00:01,  4.28batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1: 100%|█████████▉| 3088/3095 [14:23<00:01,  4.27batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1: 100%|█████████▉| 3089/3095 [14:23<00:01,  4.05batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1: 100%|█████████▉| 3090/3095 [14:24<00:01,  4.22batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1: 100%|█████████▉| 3091/3095 [14:24<00:00,  4.35batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1: 100%|█████████▉| 3092/3095 [14:24<00:00,  4.36batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1: 100%|█████████▉| 3093/3095 [14:24<00:00,  4.36batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1: 100%|██████████| 3095/3095 [14:25<00:00,  4.38batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n",
      "Epoch 1: 100%|██████████| 3095/3095 [14:25<00:00,  3.58batch/s, batch_idx=2999, gpu=0, loss=0.080, v_num=1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cache_to_csv(cache, savepath):\n",
    "    df_cache = pd.DataFrame({'filepath':[ci.filepath for ci in cache], 'label': [ci.label.cpu().numpy()[0] for ci in cache], 'res': [ci.res for ci in cache], 'traincounter': [ci.traincounter for ci in cache]})\n",
    "    df_cache.to_csv(savepath, index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:gpu available: True, used: True\n",
      "INFO:root:VISIBLE GPUS: 0\n",
      "INFO:root:\n",
      "              Name               Type Params\n",
      "0            model             ResNet   24 M\n",
      "1      model.conv1             Conv2d    9 K\n",
      "2        model.bn1        BatchNorm2d  128  \n",
      "3       model.relu               ReLU    0  \n",
      "4    model.maxpool          MaxPool2d    0  \n",
      "..             ...                ...    ...\n",
      "150       model.fc         Sequential    1 M\n",
      "151     model.fc.0             Linear    1 M\n",
      "152     model.fc.1        BatchNorm1d    1 K\n",
      "153     model.fc.2             Linear  513  \n",
      "154           loss  BCEWithLogitsLoss    0  \n",
      "\n",
      "[155 rows x 3 columns]\n",
      "/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/callbacks/pt_callbacks.py:314: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  ' skipping.', RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "hparams = get_default_hparams()\n",
    "hparams['force_misclassified'] = True\n",
    "hparams['cachemaximum'] = 128\n",
    "hparams['continous'] = False\n",
    "expname = 'continous_random_cache_transphase_force_misclassified_bsize123'\n",
    "model = CatsinomModelGramCache(argparse.Namespace(**hparams), device = torch.device('cuda'))\n",
    "\n",
    "basemodel = '/project/catinous/trained_models/lrbase_iterations.pt'\n",
    "model.load_state_dict(torch.load(basemodel))\n",
    "\n",
    "logger = pllogging.TestTubeLogger( 'catinous_log_iterations', name=expname)\n",
    "trainer = Trainer(gpus=1, max_epochs=1, early_stop_callback=False, logger=logger, val_check_interval=10, show_progress_bar=False, checkpoint_callback=False)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:gpu available: True, used: True\n",
      "INFO:root:VISIBLE GPUS: 0\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "INFO:root:\n",
      "              Name               Type Params\n",
      "0            model             ResNet   24 M\n",
      "1      model.conv1             Conv2d    9 K\n",
      "2        model.bn1        BatchNorm2d  128  \n",
      "3       model.relu               ReLU    0  \n",
      "4    model.maxpool          MaxPool2d    0  \n",
      "..             ...                ...    ...\n",
      "150       model.fc         Sequential    1 M\n",
      "151     model.fc.0             Linear    1 M\n",
      "152     model.fc.1        BatchNorm1d    1 K\n",
      "153     model.fc.2             Linear  513  \n",
      "154           loss  BCEWithLogitsLoss    0  \n",
      "\n",
      "[155 rows x 3 columns]\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/pytorch_lightning/callbacks/pt_callbacks.py:314: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  ' skipping.', RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "#testing different transition phases\n",
    "\n",
    "transitionphase = [1.0]\n",
    "\n",
    "for tp in transitionphase:\n",
    "    for i in range(2):\n",
    "        hparams = get_default_hparams()\n",
    "        hparams['transition_phase_after'] = tp\n",
    "        \n",
    "        expname = 'continous_random_cache_transphase_' + str(tp)\n",
    "        \n",
    "        model = CatsinomModelGramCache(argparse.Namespace(**hparams), device = torch.device('cuda'))\n",
    "\n",
    "        model.load_state_dict(torch.load(basemodel))\n",
    "\n",
    "        logger = pllogging.TestTubeLogger('catinous_log_iterations', name=expname)\n",
    "        trainer = Trainer(gpus=1, max_epochs=1, early_stop_callback=False, logger=logger, val_check_interval=10, show_progress_bar=False)\n",
    "        trainer.fit(model)\n",
    "        torch.save(model.state_dict(), '/project/catinous/trained_models/' + expname + '_run_'+str(i)+'.pt')\n",
    "\n",
    "        save_cache_to_csv(model.trainingscache.cachelist, '/project/catinous/trained_cache/' + expname + '_run_'+str(i)+'.csv')\n",
    "        \n",
    "        trainer = None\n",
    "        model = None\n",
    "        trainer = None\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing different cache sizes\n",
    "cache_size = [16, 128, 256]\n",
    "\n",
    "for cs in cache_size:\n",
    "    for i in range(3):\n",
    "        hparams = get_default_hparams()\n",
    "        hparams['cachemaximum'] = cs\n",
    "        \n",
    "        expname = 'continous_random_cache_cachesize_' + str(cs)\n",
    "        \n",
    "        model = CatsinomModelGramCache(argparse.Namespace(**hparams), device = torch.device('cuda'))\n",
    "\n",
    "        model.load_state_dict(torch.load(basemodel))\n",
    "\n",
    "        logger = pllogging.TestTubeLogger('catinous_log_iterations', name=expname)\n",
    "        trainer = Trainer(gpus=1, max_epochs=1, early_stop_callback=False, logger=logger, val_check_interval=10, show_progress_bar=False)\n",
    "        trainer.fit(model)\n",
    "        torch.save(model.state_dict(), '/project/catinous/trained_models/' + expname + '_run_'+str(i)+'.pt')\n",
    "\n",
    "        save_cache_to_csv(model.trainingscache.cachelist, '/project/catinous/trained_cache/' + expname + '_run_'+str(i)+'.csv')\n",
    "\n",
    "        trainer = None\n",
    "        model = None\n",
    "        torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Candid (new)",
   "language": "python",
   "name": "candid2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
