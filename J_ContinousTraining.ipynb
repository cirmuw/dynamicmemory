{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from catinous.CatsinomModelGramCache import CatsinomModelGramCache\n",
    "import catinous.CatsinomModelGramCache as catsmodel\n",
    "from catinous import utils as cutils\n",
    "from catinous import CatsinomDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import pytorch_lightning as pl\n",
    "import sklearn \n",
    "from sklearn.metrics import confusion_matrix, auc, roc_curve\n",
    "import torch\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from py_jotools import mut, slurm\n",
    "import numpy as np\n",
    "import gc\n",
    "import hashlib\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_dir': '/project/catinous/cat_data/',\n",
       " 'datasetfile': 'catsinom_combined_dataset.csv',\n",
       " 'batch_size': 8,\n",
       " 'training_batch_size': 8,\n",
       " 'transition_phase_after': 0.7,\n",
       " 'cachemaximum': 128,\n",
       " 'use_cache': True,\n",
       " 'random_cache': True,\n",
       " 'balance_cache': True,\n",
       " 'force_misclassified': False,\n",
       " 'direction': 'lr->hr',\n",
       " 'continous': True,\n",
       " 'noncontinous_steps': 3000,\n",
       " 'noncontinous_train_splits': ['train', 'base_train'],\n",
       " 'val_check_interval': 100,\n",
       " 'base_model': None,\n",
       " 'run_postfix': '1'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CatsinomModelGramCache.get_default_hparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams={'continous':False,\n",
    "         'datasetfile': 'catsinom_lr_dataset.csv',\n",
    "         'noncontinous_train_splits': ['base_train'],\n",
    "         'noncontinous_steps': 101}\n",
    "# pllogger = cutils.pllogger(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:No continous learning, following parameters are invalidated: \n",
      "transition_phase_after \n",
      "cachemaximum \n",
      "use_cache \n",
      "random_cache \n",
      "force_misclassified \n",
      "direction\n",
      "INFO:root:gpu available: True, used: True\n",
      "INFO:root:VISIBLE GPUS: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'balance_cache': True,\n",
      " 'base_model': None,\n",
      " 'batch_size': 8,\n",
      " 'cachemaximum': 128,\n",
      " 'continous': False,\n",
      " 'datasetfile': 'catsinom_lr_dataset.csv',\n",
      " 'direction': 'lr->hr',\n",
      " 'force_misclassified': False,\n",
      " 'noncontinous_steps': 101,\n",
      " 'noncontinous_train_splits': ['base_train'],\n",
      " 'random_cache': True,\n",
      " 'root_dir': '/project/catinous/cat_data/',\n",
      " 'run_postfix': '1',\n",
      " 'training_batch_size': 8,\n",
      " 'transition_phase_after': 0.7,\n",
      " 'use_cache': False,\n",
      " 'val_check_interval': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\n",
      "              Name               Type Params\n",
      "0            model             ResNet   24 M\n",
      "1      model.conv1             Conv2d    9 K\n",
      "2        model.bn1        BatchNorm2d  128  \n",
      "3       model.relu               ReLU    0  \n",
      "4    model.maxpool          MaxPool2d    0  \n",
      "..             ...                ...    ...\n",
      "150       model.fc         Sequential    1 M\n",
      "151     model.fc.0             Linear    1 M\n",
      "152     model.fc.1        BatchNorm1d    1 K\n",
      "153     model.fc.2             Linear  513  \n",
      "154           loss  BCEWithLogitsLoss    0  \n",
      "\n",
      "[155 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "model, logs, df_cache = catsmodel.trained_model(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>epoch</th>\n",
       "      <th>created_at</th>\n",
       "      <th>val_loss_lr</th>\n",
       "      <th>val_acc_lr</th>\n",
       "      <th>val_loss_hr</th>\n",
       "      <th>val_acc_hr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.682046</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-12 10:41:22.160122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.701556</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-12 10:41:24.689199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.933047</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-12 10:41:27.184884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.624065</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-12 10:41:29.724366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.005151</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-12 10:41:32.204642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.448852</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-12 10:41:34.690538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.162357</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-12 10:41:37.180954</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.695668</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-12 10:41:39.679273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.555162</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-12 10:41:42.173327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.579996</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-12 10:41:44.665746</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-12 10:42:08.014324</td>\n",
       "      <td>0.784758</td>\n",
       "      <td>0.510526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_loss  epoch                  created_at  val_loss_lr  val_acc_lr  \\\n",
       "0     0.682046      0  2020-02-12 10:41:22.160122          NaN         NaN   \n",
       "1     0.701556      0  2020-02-12 10:41:24.689199          NaN         NaN   \n",
       "2     0.933047      0  2020-02-12 10:41:27.184884          NaN         NaN   \n",
       "3     0.624065      0  2020-02-12 10:41:29.724366          NaN         NaN   \n",
       "4     1.005151      0  2020-02-12 10:41:32.204642          NaN         NaN   \n",
       "5     0.448852      0  2020-02-12 10:41:34.690538          NaN         NaN   \n",
       "6     1.162357      0  2020-02-12 10:41:37.180954          NaN         NaN   \n",
       "7     0.695668      0  2020-02-12 10:41:39.679273          NaN         NaN   \n",
       "8     0.555162      0  2020-02-12 10:41:42.173327          NaN         NaN   \n",
       "9     0.579996      0  2020-02-12 10:41:44.665746          NaN         NaN   \n",
       "10         NaN      0  2020-02-12 10:42:08.014324     0.784758    0.510526   \n",
       "\n",
       "    val_loss_hr  val_acc_hr  \n",
       "0           NaN         NaN  \n",
       "1           NaN         NaN  \n",
       "2           NaN         NaN  \n",
       "3           NaN         NaN  \n",
       "4           NaN         NaN  \n",
       "5           NaN         NaN  \n",
       "6           NaN         NaN  \n",
       "7           NaN         NaN  \n",
       "8           NaN         NaN  \n",
       "9           NaN         NaN  \n",
       "10          0.0         0.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatsinomModelGramCache(hparams=hparams, device=torch.device('cuda'))\n",
    "logger = cutils.pllogger(model.hparams)\n",
    "trainer = Trainer(gpus=1, max_epochs=1, early_stop_callback=False, logger=logger, val_check_interval=3000, show_progress_bar=True, checkpoint_callback=False)\n",
    "trainer.fit(model)\n",
    "torch.save(model.state_dict(), '/project/catinous/trained_models/' + expname + '_run_'+str(i)+'.pt')\n",
    "save_cache_to_csv(model.trainingscache.cachelist, '/project/catinous/trained_cache/' + expname + '_run_'+str(i)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparams = {\n",
    "    'gpu': 1,\n",
    "    'partitionn': 'full',\n",
    "    'memory': 15000,\n",
    "    'jobname': 'catinous_test'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slurm.srun(trainer.fit, model, params=sparams, remote=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'binary': '/home/jhofmanninger/anaconda3/envs/candid/bin/python',\n",
       " 'outputpath': '/home/cir/jhofmanninger/slurmoutput/',\n",
       " 'jobname': '',\n",
       " 'days': 0,\n",
       " 'hours': '0',\n",
       " 'minutes': '10',\n",
       " 'memory': 2000,\n",
       " 'ntasks': 1,\n",
       " 'cpusptask': 4,\n",
       " 'qos': 'normal',\n",
       " 'mailuser': 'johannes.hofmanninger@meduniwien.ac.at',\n",
       " 'cwd': '/home/jhofmanninger/Projects/catinous',\n",
       " 'dillfile': '',\n",
       " 'gpu': 0,\n",
       " 'partition': 'cir',\n",
       " 'paths': []}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slurm.slurm_params_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cache_to_csv(cache, savepath):\n",
    "    df_cache = pd.DataFrame({'filepath':[ci.filepath for ci in cache], 'label': [ci.label.cpu().numpy()[0] for ci in cache], 'res': [ci.res for ci in cache], 'traincounter': [ci.traincounter for ci in cache]})\n",
    "    df_cache.to_csv(savepath, index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:gpu available: True, used: True\n",
      "INFO:root:VISIBLE GPUS: 0\n",
      "INFO:root:\n",
      "              Name               Type Params\n",
      "0            model             ResNet   24 M\n",
      "1      model.conv1             Conv2d    9 K\n",
      "2        model.bn1        BatchNorm2d  128  \n",
      "3       model.relu               ReLU    0  \n",
      "4    model.maxpool          MaxPool2d    0  \n",
      "..             ...                ...    ...\n",
      "150       model.fc         Sequential    1 M\n",
      "151     model.fc.0             Linear    1 M\n",
      "152     model.fc.1        BatchNorm1d    1 K\n",
      "153     model.fc.2             Linear  513  \n",
      "154           loss  BCEWithLogitsLoss    0  \n",
      "\n",
      "[155 rows x 3 columns]\n",
      "/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/callbacks/pt_callbacks.py:314: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  ' skipping.', RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "hparams = get_default_hparams()\n",
    "hparams['force_misclassified'] = True\n",
    "hparams['cachemaximum'] = 128\n",
    "hparams['continous'] = False\n",
    "expname = 'continous_random_cache_transphase_force_misclassified_bsize123'\n",
    "model = CatsinomModelGramCache(argparse.Namespace(**hparams), device = torch.device('cuda'))\n",
    "\n",
    "basemodel = '/project/catinous/trained_models/lrbase_iterations.pt'\n",
    "model.load_state_dict(torch.load(basemodel))\n",
    "\n",
    "logger = pllogging.TestTubeLogger( 'catinous_log_iterations', name=expname)\n",
    "trainer = Trainer(gpus=1, max_epochs=1, early_stop_callback=False, logger=logger, val_check_interval=10, show_progress_bar=False, checkpoint_callback=False)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:gpu available: True, used: True\n",
      "INFO:root:VISIBLE GPUS: 0\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "INFO:root:\n",
      "              Name               Type Params\n",
      "0            model             ResNet   24 M\n",
      "1      model.conv1             Conv2d    9 K\n",
      "2        model.bn1        BatchNorm2d  128  \n",
      "3       model.relu               ReLU    0  \n",
      "4    model.maxpool          MaxPool2d    0  \n",
      "..             ...                ...    ...\n",
      "150       model.fc         Sequential    1 M\n",
      "151     model.fc.0             Linear    1 M\n",
      "152     model.fc.1        BatchNorm1d    1 K\n",
      "153     model.fc.2             Linear  513  \n",
      "154           loss  BCEWithLogitsLoss    0  \n",
      "\n",
      "[155 rows x 3 columns]\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/pytorch_lightning/callbacks/pt_callbacks.py:314: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  ' skipping.', RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "#testing different transition phases\n",
    "\n",
    "transitionphase = [1.0]\n",
    "\n",
    "for tp in transitionphase:\n",
    "    for i in range(2):\n",
    "        hparams = get_default_hparams()\n",
    "        hparams['transition_phase_after'] = tp\n",
    "        \n",
    "        expname = 'continous_random_cache_transphase_' + str(tp)\n",
    "        \n",
    "        model = CatsinomModelGramCache(argparse.Namespace(**hparams), device = torch.device('cuda'))\n",
    "\n",
    "        model.load_state_dict(torch.load(basemodel))\n",
    "\n",
    "        logger = pllogging.TestTubeLogger('catinous_log_iterations', name=expname)\n",
    "        trainer = Trainer(gpus=1, max_epochs=1, early_stop_callback=False, logger=logger, val_check_interval=10, show_progress_bar=False)\n",
    "        trainer.fit(model)\n",
    "        torch.save(model.state_dict(), '/project/catinous/trained_models/' + expname + '_run_'+str(i)+'.pt')\n",
    "\n",
    "        save_cache_to_csv(model.trainingscache.cachelist, '/project/catinous/trained_cache/' + expname + '_run_'+str(i)+'.csv')\n",
    "        \n",
    "        trainer = None\n",
    "        model = None\n",
    "        trainer = None\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing different cache sizes\n",
    "cache_size = [16, 128, 256]\n",
    "\n",
    "for cs in cache_size:\n",
    "    for i in range(3):\n",
    "        hparams = get_default_hparams()\n",
    "        hparams['cachemaximum'] = cs\n",
    "        \n",
    "        expname = 'continous_random_cache_cachesize_' + str(cs)\n",
    "        \n",
    "        model = CatsinomModelGramCache(argparse.Namespace(**hparams), device = torch.device('cuda'))\n",
    "\n",
    "        model.load_state_dict(torch.load(basemodel))\n",
    "\n",
    "        logger = pllogging.TestTubeLogger('catinous_log_iterations', name=expname)\n",
    "        trainer = Trainer(gpus=1, max_epochs=1, early_stop_callback=False, logger=logger, val_check_interval=10, show_progress_bar=False)\n",
    "        trainer.fit(model)\n",
    "        torch.save(model.state_dict(), '/project/catinous/trained_models/' + expname + '_run_'+str(i)+'.pt')\n",
    "\n",
    "        save_cache_to_csv(model.trainingscache.cachelist, '/project/catinous/trained_cache/' + expname + '_run_'+str(i)+'.csv')\n",
    "\n",
    "        trainer = None\n",
    "        model = None\n",
    "        torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Candid (new)",
   "language": "python",
   "name": "candid2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
