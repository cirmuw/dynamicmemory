{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from catinous.CatsinomModelGramCache import CatsinomModelGramCache\n",
    "import catinous.CatsinomModelGramCache as catsmodel\n",
    "from catinous import utils as cutils\n",
    "from catinous import CatsinomDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import pytorch_lightning as pl\n",
    "import sklearn \n",
    "from sklearn.metrics import confusion_matrix, auc, roc_curve\n",
    "import torch\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from py_jotools import mut, slurm\n",
    "import numpy as np\n",
    "import gc\n",
    "import hashlib\n",
    "import dill\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_dir': '/project/catinous/cat_data/',\n",
       " 'datasetfile': 'catsinom_combined_dataset.csv',\n",
       " 'batch_size': 8,\n",
       " 'training_batch_size': 8,\n",
       " 'transition_phase_after': 0.7,\n",
       " 'cachemaximum': 128,\n",
       " 'use_cache': True,\n",
       " 'random_cache': True,\n",
       " 'balance_cache': True,\n",
       " 'force_misclassified': False,\n",
       " 'direction': 'lr->hr',\n",
       " 'continous': True,\n",
       " 'noncontinous_steps': 3000,\n",
       " 'noncontinous_train_splits': ['train', 'base_train'],\n",
       " 'val_check_interval': 100,\n",
       " 'base_model': None,\n",
       " 'run_postfix': '1'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CatsinomModelGramCache.get_default_hparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams={'continous':False,\n",
    "         'datasetfile': 'catsinom_lr_dataset.csv',\n",
    "         'noncontinous_train_splits': ['base_train'],\n",
    "         'noncontinous_steps': 103}\n",
    "# pllogger = cutils.pllogger(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:No continous learning, following parameters are invalidated: \n",
      "transition_phase_after \n",
      "cachemaximum \n",
      "use_cache \n",
      "random_cache \n",
      "force_misclassified \n",
      "direction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'balance_cache': True,\n",
      " 'base_model': None,\n",
      " 'batch_size': 8,\n",
      " 'cachemaximum': 128,\n",
      " 'continous': False,\n",
      " 'datasetfile': 'catsinom_lr_dataset.csv',\n",
      " 'direction': 'lr->hr',\n",
      " 'force_misclassified': False,\n",
      " 'noncontinous_steps': 103,\n",
      " 'noncontinous_train_splits': ['base_train'],\n",
      " 'random_cache': True,\n",
      " 'root_dir': '/project/catinous/cat_data/',\n",
      " 'run_postfix': '1',\n",
      " 'training_batch_size': 8,\n",
      " 'transition_phase_after': 0.7,\n",
      " 'use_cache': False,\n",
      " 'val_check_interval': 100}\n"
     ]
    }
   ],
   "source": [
    "model, logs, df_cache = catsmodel.trained_model(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15815110948576212\n",
      "sshpass -f ~/.ssh/pass ssh cn1.cir.meduniwien.ac.at sbatch --export=NONE --partition full /scratch/15815110948576212.job\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/scratch/15815110948576212_res.dll'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparams = {\n",
    "    'binary': '/home/cir/jhofmanninger/env/candid/bin/python',\n",
    "    'cwd': '/home/cir/jhofmanninger/Projects/catinous',\n",
    "    'gpu': 1,\n",
    "    'partition': 'full',\n",
    "    'memory': 15000,\n",
    "    'jobname': 'catinous_test'}\n",
    "slurm.srun(catsmodel.trained_model, [hparams], params=sparams, remote=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:No continous learning, following parameters are invalidated: \n",
      "transition_phase_after \n",
      "cachemaximum \n",
      "use_cache \n",
      "random_cache \n",
      "force_misclassified \n",
      "direction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'balance_cache': True,\n",
      " 'base_model': None,\n",
      " 'batch_size': 8,\n",
      " 'cachemaximum': 128,\n",
      " 'continous': False,\n",
      " 'datasetfile': 'catsinom_lr_dataset.csv',\n",
      " 'direction': 'lr->hr',\n",
      " 'force_misclassified': False,\n",
      " 'noncontinous_steps': 101,\n",
      " 'noncontinous_train_splits': ['base_train'],\n",
      " 'random_cache': True,\n",
      " 'root_dir': '/project/catinous/cat_data/',\n",
      " 'run_postfix': '1',\n",
      " 'training_batch_size': 8,\n",
      " 'transition_phase_after': 0.7,\n",
      " 'use_cache': False,\n",
      " 'val_check_interval': 100}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(CatsinomModelGramCache(\n",
       "   (model): ResNet(\n",
       "     (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "     (layer1): Sequential(\n",
       "       (0): Bottleneck(\n",
       "         (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "         (downsample): Sequential(\n",
       "           (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "           (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "       (1): Bottleneck(\n",
       "         (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "       )\n",
       "       (2): Bottleneck(\n",
       "         (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "       )\n",
       "     )\n",
       "     (layer2): Sequential(\n",
       "       (0): Bottleneck(\n",
       "         (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "         (downsample): Sequential(\n",
       "           (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "           (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "       (1): Bottleneck(\n",
       "         (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "       )\n",
       "       (2): Bottleneck(\n",
       "         (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "       )\n",
       "       (3): Bottleneck(\n",
       "         (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "       )\n",
       "     )\n",
       "     (layer3): Sequential(\n",
       "       (0): Bottleneck(\n",
       "         (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "         (downsample): Sequential(\n",
       "           (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "           (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "       (1): Bottleneck(\n",
       "         (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "       )\n",
       "       (2): Bottleneck(\n",
       "         (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "       )\n",
       "       (3): Bottleneck(\n",
       "         (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "       )\n",
       "       (4): Bottleneck(\n",
       "         (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "       )\n",
       "       (5): Bottleneck(\n",
       "         (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "       )\n",
       "     )\n",
       "     (layer4): Sequential(\n",
       "       (0): Bottleneck(\n",
       "         (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "         (downsample): Sequential(\n",
       "           (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "           (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "       (1): Bottleneck(\n",
       "         (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "       )\n",
       "       (2): Bottleneck(\n",
       "         (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "       )\n",
       "     )\n",
       "     (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "     (fc): Sequential(\n",
       "       (0): Linear(in_features=2048, out_features=512, bias=True)\n",
       "       (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): Linear(in_features=512, out_features=1, bias=True)\n",
       "     )\n",
       "   )\n",
       "   (loss): BCEWithLogitsLoss()\n",
       " ),\n",
       "     train_loss  epoch                  created_at  val_loss_lr  val_acc_lr  \\\n",
       " 0     0.793888      0  2020-02-12 10:45:09.529655          NaN         NaN   \n",
       " 1     1.396561      0  2020-02-12 10:45:12.250744          NaN         NaN   \n",
       " 2     1.450891      0  2020-02-12 10:45:14.833379          NaN         NaN   \n",
       " 3     0.831389      0  2020-02-12 10:45:17.338178          NaN         NaN   \n",
       " 4     0.626384      0  2020-02-12 10:45:19.841732          NaN         NaN   \n",
       " 5     0.862868      0  2020-02-12 10:45:22.354178          NaN         NaN   \n",
       " 6     0.842171      0  2020-02-12 10:45:24.853181          NaN         NaN   \n",
       " 7     0.417683      0  2020-02-12 10:45:27.422950          NaN         NaN   \n",
       " 8     0.621118      0  2020-02-12 10:45:29.940435          NaN         NaN   \n",
       " 9     0.804076      0  2020-02-12 10:45:32.456792          NaN         NaN   \n",
       " 10         NaN      0  2020-02-12 10:45:55.959520     1.047225    0.502632   \n",
       " 11    0.773014      0  2020-02-12 10:45:56.457707          NaN         NaN   \n",
       " \n",
       "     val_loss_hr  val_acc_hr  \n",
       " 0           NaN         NaN  \n",
       " 1           NaN         NaN  \n",
       " 2           NaN         NaN  \n",
       " 3           NaN         NaN  \n",
       " 4           NaN         NaN  \n",
       " 5           NaN         NaN  \n",
       " 6           NaN         NaN  \n",
       " 7           NaN         NaN  \n",
       " 8           NaN         NaN  \n",
       " 9           NaN         NaN  \n",
       " 10          0.0         0.0  \n",
       " 11          NaN         NaN  ,\n",
       " None)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dill.load(open('/scratch/158150528649969.dll','rb'))['function'](hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/scratch/15815045002145245_res.dll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatsinomModelGramCache(hparams=hparams, device=torch.device('cuda'))\n",
    "logger = cutils.pllogger(model.hparams)\n",
    "trainer = Trainer(gpus=1, max_epochs=1, early_stop_callback=False, logger=logger, val_check_interval=3000, show_progress_bar=True, checkpoint_callback=False)\n",
    "trainer.fit(model)\n",
    "torch.save(model.state_dict(), '/project/catinous/trained_models/' + expname + '_run_'+str(i)+'.pt')\n",
    "save_cache_to_csv(model.trainingscache.cachelist, '/project/catinous/trained_cache/' + expname + '_run_'+str(i)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slurm.srun(trainer.fit, model, params=sparams, remote=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'binary': '/home/jhofmanninger/anaconda3/envs/candid/bin/python',\n",
       " 'outputpath': '/home/cir/jhofmanninger/slurmoutput/',\n",
       " 'jobname': '',\n",
       " 'days': 0,\n",
       " 'hours': '0',\n",
       " 'minutes': '10',\n",
       " 'memory': 2000,\n",
       " 'ntasks': 1,\n",
       " 'cpusptask': 4,\n",
       " 'qos': 'normal',\n",
       " 'mailuser': 'johannes.hofmanninger@meduniwien.ac.at',\n",
       " 'cwd': '/home/jhofmanninger/Projects/catinous',\n",
       " 'dillfile': '',\n",
       " 'gpu': 0,\n",
       " 'partition': 'cir',\n",
       " 'paths': []}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slurm.slurm_params_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cache_to_csv(cache, savepath):\n",
    "    df_cache = pd.DataFrame({'filepath':[ci.filepath for ci in cache], 'label': [ci.label.cpu().numpy()[0] for ci in cache], 'res': [ci.res for ci in cache], 'traincounter': [ci.traincounter for ci in cache]})\n",
    "    df_cache.to_csv(savepath, index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:gpu available: True, used: True\n",
      "INFO:root:VISIBLE GPUS: 0\n",
      "INFO:root:\n",
      "              Name               Type Params\n",
      "0            model             ResNet   24 M\n",
      "1      model.conv1             Conv2d    9 K\n",
      "2        model.bn1        BatchNorm2d  128  \n",
      "3       model.relu               ReLU    0  \n",
      "4    model.maxpool          MaxPool2d    0  \n",
      "..             ...                ...    ...\n",
      "150       model.fc         Sequential    1 M\n",
      "151     model.fc.0             Linear    1 M\n",
      "152     model.fc.1        BatchNorm1d    1 K\n",
      "153     model.fc.2             Linear  513  \n",
      "154           loss  BCEWithLogitsLoss    0  \n",
      "\n",
      "[155 rows x 3 columns]\n",
      "/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/callbacks/pt_callbacks.py:314: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  ' skipping.', RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "hparams = get_default_hparams()\n",
    "hparams['force_misclassified'] = True\n",
    "hparams['cachemaximum'] = 128\n",
    "hparams['continous'] = False\n",
    "expname = 'continous_random_cache_transphase_force_misclassified_bsize123'\n",
    "model = CatsinomModelGramCache(argparse.Namespace(**hparams), device = torch.device('cuda'))\n",
    "\n",
    "basemodel = '/project/catinous/trained_models/lrbase_iterations.pt'\n",
    "model.load_state_dict(torch.load(basemodel))\n",
    "\n",
    "logger = pllogging.TestTubeLogger( 'catinous_log_iterations', name=expname)\n",
    "trainer = Trainer(gpus=1, max_epochs=1, early_stop_callback=False, logger=logger, val_check_interval=10, show_progress_bar=False, checkpoint_callback=False)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:gpu available: True, used: True\n",
      "INFO:root:VISIBLE GPUS: 0\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "INFO:root:\n",
      "              Name               Type Params\n",
      "0            model             ResNet   24 M\n",
      "1      model.conv1             Conv2d    9 K\n",
      "2        model.bn1        BatchNorm2d  128  \n",
      "3       model.relu               ReLU    0  \n",
      "4    model.maxpool          MaxPool2d    0  \n",
      "..             ...                ...    ...\n",
      "150       model.fc         Sequential    1 M\n",
      "151     model.fc.0             Linear    1 M\n",
      "152     model.fc.1        BatchNorm1d    1 K\n",
      "153     model.fc.2             Linear  513  \n",
      "154           loss  BCEWithLogitsLoss    0  \n",
      "\n",
      "[155 rows x 3 columns]\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/pytorch_lightning/callbacks/pt_callbacks.py:314: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  ' skipping.', RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "#testing different transition phases\n",
    "\n",
    "transitionphase = [1.0]\n",
    "\n",
    "for tp in transitionphase:\n",
    "    for i in range(2):\n",
    "        hparams = get_default_hparams()\n",
    "        hparams['transition_phase_after'] = tp\n",
    "        \n",
    "        expname = 'continous_random_cache_transphase_' + str(tp)\n",
    "        \n",
    "        model = CatsinomModelGramCache(argparse.Namespace(**hparams), device = torch.device('cuda'))\n",
    "\n",
    "        model.load_state_dict(torch.load(basemodel))\n",
    "\n",
    "        logger = pllogging.TestTubeLogger('catinous_log_iterations', name=expname)\n",
    "        trainer = Trainer(gpus=1, max_epochs=1, early_stop_callback=False, logger=logger, val_check_interval=10, show_progress_bar=False)\n",
    "        trainer.fit(model)\n",
    "        torch.save(model.state_dict(), '/project/catinous/trained_models/' + expname + '_run_'+str(i)+'.pt')\n",
    "\n",
    "        save_cache_to_csv(model.trainingscache.cachelist, '/project/catinous/trained_cache/' + expname + '_run_'+str(i)+'.csv')\n",
    "        \n",
    "        trainer = None\n",
    "        model = None\n",
    "        trainer = None\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing different cache sizes\n",
    "cache_size = [16, 128, 256]\n",
    "\n",
    "for cs in cache_size:\n",
    "    for i in range(3):\n",
    "        hparams = get_default_hparams()\n",
    "        hparams['cachemaximum'] = cs\n",
    "        \n",
    "        expname = 'continous_random_cache_cachesize_' + str(cs)\n",
    "        \n",
    "        model = CatsinomModelGramCache(argparse.Namespace(**hparams), device = torch.device('cuda'))\n",
    "\n",
    "        model.load_state_dict(torch.load(basemodel))\n",
    "\n",
    "        logger = pllogging.TestTubeLogger('catinous_log_iterations', name=expname)\n",
    "        trainer = Trainer(gpus=1, max_epochs=1, early_stop_callback=False, logger=logger, val_check_interval=10, show_progress_bar=False)\n",
    "        trainer.fit(model)\n",
    "        torch.save(model.state_dict(), '/project/catinous/trained_models/' + expname + '_run_'+str(i)+'.pt')\n",
    "\n",
    "        save_cache_to_csv(model.trainingscache.cachelist, '/project/catinous/trained_cache/' + expname + '_run_'+str(i)+'.csv')\n",
    "\n",
    "        trainer = None\n",
    "        model = None\n",
    "        torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Candid (new)",
   "language": "python",
   "name": "candid2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
