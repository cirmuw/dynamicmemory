{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from catinous.CatsinomModelGramCache import CatsinomModelGramCache\n",
    "import catinous.CatsinomModelGramCache as catsmodel\n",
    "from catinous import utils as cutils\n",
    "from catinous import CatsinomDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import pytorch_lightning as pl\n",
    "import sklearn \n",
    "from sklearn.metrics import confusion_matrix, auc, roc_curve\n",
    "import torch\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from py_jotools import mut, slurm\n",
    "import numpy as np\n",
    "import gc\n",
    "import hashlib\n",
    "import dill\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### default parameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_dir': '/project/catinous/cat_data/',\n",
       " 'datasetfile': 'catsinom_combined_dataset.csv',\n",
       " 'batch_size': 8,\n",
       " 'training_batch_size': 8,\n",
       " 'transition_phase_after': 0.7,\n",
       " 'cachemaximum': 128,\n",
       " 'use_cache': True,\n",
       " 'random_cache': True,\n",
       " 'balance_cache': True,\n",
       " 'force_misclassified': False,\n",
       " 'direction': 'lr->hr',\n",
       " 'continous': True,\n",
       " 'noncontinous_steps': 3000,\n",
       " 'noncontinous_train_splits': ['train', 'base_train'],\n",
       " 'val_check_interval': 100,\n",
       " 'base_model': None,\n",
       " 'run_postfix': '1'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CatsinomModelGramCache.get_default_hparams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameteres for slurm scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparams = {\n",
    "    'binary': '/home/cir/jhofmanninger/env/candid/bin/python',\n",
    "    'cwd': '/home/cir/jhofmanninger/Projects/catinous/',\n",
    "    'gpu': 1,\n",
    "    'partition': 'full',\n",
    "    'memory': 15000,\n",
    "    'jobname': 'catinous_base',\n",
    "    'outputpath': '/home/cir/jhofmanninger/slurmoutput/',\n",
    "    'mailuser': 'matthias.perkonigg@meduniwien.ac.at',\n",
    "    'minutes': '240'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read: /project/catinous/trained_models/batch_lr_base_train_1_2d20289ac9.pt\n",
      "Read: /project/catinous/trained_models/batch_hr_base_train_1_98bf44d0f0.pt\n"
     ]
    }
   ],
   "source": [
    "schedule = False\n",
    "\n",
    "hparams={'continous':False,\n",
    "         'datasetfile': 'catsinom_lr_dataset.csv',\n",
    "         'noncontinous_train_splits': ['base_train'],\n",
    "         'noncontinous_steps': 3000}\n",
    "if schedule:\n",
    "    slurm.srun(catsmodel.trained_model, [hparams], params=sparams, remote=True)\n",
    "else:\n",
    "    model, logs, df_cache, basemodel_lr = catsmodel.trained_model(hparams)\n",
    "hparams['datasetfile'] = 'catsinom_hr_dataset.csv'\n",
    "if schedule:\n",
    "    slurm.srun(catsmodel.trained_model, [hparams], params=sparams, remote=True)\n",
    "else:\n",
    "    model, logs, df_cache, basemodel_hr = catsmodel.trained_model(hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continous training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lr->hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Gram hooks and cache initialized. Cachesize: 256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1582018235661091\n",
      "sshpass -f ~/.ssh/pass ssh cn1.cir.meduniwien.ac.at sbatch --export=NONE --partition full /scratch/1582018235661091.job\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Gram hooks and cache initialized. Cachesize: 256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15820182394876163\n",
      "sshpass -f ~/.ssh/pass ssh cn1.cir.meduniwien.ac.at sbatch --export=NONE --partition full /scratch/15820182394876163.job\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Gram hooks and cache initialized. Cachesize: 256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15820182415981078\n",
      "sshpass -f ~/.ssh/pass ssh cn1.cir.meduniwien.ac.at sbatch --export=NONE --partition full /scratch/15820182415981078.job\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Gram hooks and cache initialized. Cachesize: 256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15820182434725463\n",
      "sshpass -f ~/.ssh/pass ssh cn1.cir.meduniwien.ac.at sbatch --export=NONE --partition full /scratch/15820182434725463.job\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Gram hooks and cache initialized. Cachesize: 256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15820182465091124\n",
      "sshpass -f ~/.ssh/pass ssh cn1.cir.meduniwien.ac.at sbatch --export=NONE --partition full /scratch/15820182465091124.job\n"
     ]
    }
   ],
   "source": [
    "hparams={'continous': True,\n",
    "         'force_misclassified': True,\n",
    "         'datasetfile': 'catsinom_combined_dataset.csv',\n",
    "         'base_model': basemodel_lr,\n",
    "         'val_check_interval': 30,\n",
    "         'cachemaximum': 256}\n",
    "base_lr_continous_params = []\n",
    "for i in range(5):\n",
    "    base_lr_continous_params.append(hparams.copy())\n",
    "    base_lr_continous_params[-1]['run_postfix'] = i+1\n",
    "    if not catsmodel.is_cached(base_lr_continous_params[-1]):\n",
    "        slurm.srun(catsmodel.trained_model, [base_lr_continous_params[-1]], params=sparams, remote=True)    \n",
    "    else:\n",
    "        print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Gram hooks and cache initialized. Cachesize: 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Gram hooks and cache initialized. Cachesize: 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Gram hooks and cache initialized. Cachesize: 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Gram hooks and cache initialized. Cachesize: 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Gram hooks and cache initialized. Cachesize: 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "hparams={'continous': True,\n",
    "         'use_cache': False,\n",
    "         'datasetfile': 'catsinom_combined_dataset.csv',\n",
    "         'base_model': basemodel_lr,\n",
    "         'val_check_interval': 30}\n",
    "base_lr_continous_nocache_params = []\n",
    "for i in range(5):\n",
    "    base_lr_continous_nocache_params.append(hparams.copy())\n",
    "    base_lr_continous_nocache_params[-1]['run_postfix'] = i+1\n",
    "    if not catsmodel.is_cached(base_lr_continous_nocache_params[-1]):\n",
    "        slurm.srun(catsmodel.trained_model, [base_lr_continous_nocache_params[-1]], params=sparams, remote=True)   \n",
    "    else:\n",
    "        print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Gram hooks and cache initialized. Cachesize: 128\n",
      "/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/callbacks/pt_callbacks.py:401: DeprecationWarning: Epochs indexing of `scheduling` starts from \"1\" until v0.6.x, but will start from \"0\" in v0.8.0.\n",
      "  ' but will start from \"0\" in v0.8.0.', DeprecationWarning)\n",
      "INFO:root:GPU available: True, used: True\n",
      "INFO:root:VISIBLE GPUS: 0\n",
      "INFO:root:\n",
      "    | Name                        | Type              | Params\n",
      "--------------------------------------------------------------\n",
      "0   | model                       | ResNet            | 24 M  \n",
      "1   | model.conv1                 | Conv2d            | 9 K   \n",
      "2   | model.bn1                   | BatchNorm2d       | 128   \n",
      "3   | model.relu                  | ReLU              | 0     \n",
      "4   | model.maxpool               | MaxPool2d         | 0     \n",
      "5   | model.layer1                | Sequential        | 215 K \n",
      "6   | model.layer1.0              | Bottleneck        | 75 K  \n",
      "7   | model.layer1.0.conv1        | Conv2d            | 4 K   \n",
      "8   | model.layer1.0.bn1          | BatchNorm2d       | 128   \n",
      "9   | model.layer1.0.conv2        | Conv2d            | 36 K  \n",
      "10  | model.layer1.0.bn2          | BatchNorm2d       | 128   \n",
      "11  | model.layer1.0.conv3        | Conv2d            | 16 K  \n",
      "12  | model.layer1.0.bn3          | BatchNorm2d       | 512   \n",
      "13  | model.layer1.0.relu         | ReLU              | 0     \n",
      "14  | model.layer1.0.downsample   | Sequential        | 16 K  \n",
      "15  | model.layer1.0.downsample.0 | Conv2d            | 16 K  \n",
      "16  | model.layer1.0.downsample.1 | BatchNorm2d       | 512   \n",
      "17  | model.layer1.1              | Bottleneck        | 70 K  \n",
      "18  | model.layer1.1.conv1        | Conv2d            | 16 K  \n",
      "19  | model.layer1.1.bn1          | BatchNorm2d       | 128   \n",
      "20  | model.layer1.1.conv2        | Conv2d            | 36 K  \n",
      "21  | model.layer1.1.bn2          | BatchNorm2d       | 128   \n",
      "22  | model.layer1.1.conv3        | Conv2d            | 16 K  \n",
      "23  | model.layer1.1.bn3          | BatchNorm2d       | 512   \n",
      "24  | model.layer1.1.relu         | ReLU              | 0     \n",
      "25  | model.layer1.2              | Bottleneck        | 70 K  \n",
      "26  | model.layer1.2.conv1        | Conv2d            | 16 K  \n",
      "27  | model.layer1.2.bn1          | BatchNorm2d       | 128   \n",
      "28  | model.layer1.2.conv2        | Conv2d            | 36 K  \n",
      "29  | model.layer1.2.bn2          | BatchNorm2d       | 128   \n",
      "30  | model.layer1.2.conv3        | Conv2d            | 16 K  \n",
      "31  | model.layer1.2.bn3          | BatchNorm2d       | 512   \n",
      "32  | model.layer1.2.relu         | ReLU              | 0     \n",
      "33  | model.layer2                | Sequential        | 1 M   \n",
      "34  | model.layer2.0              | Bottleneck        | 379 K \n",
      "35  | model.layer2.0.conv1        | Conv2d            | 32 K  \n",
      "36  | model.layer2.0.bn1          | BatchNorm2d       | 256   \n",
      "37  | model.layer2.0.conv2        | Conv2d            | 147 K \n",
      "38  | model.layer2.0.bn2          | BatchNorm2d       | 256   \n",
      "39  | model.layer2.0.conv3        | Conv2d            | 65 K  \n",
      "40  | model.layer2.0.bn3          | BatchNorm2d       | 1 K   \n",
      "41  | model.layer2.0.relu         | ReLU              | 0     \n",
      "42  | model.layer2.0.downsample   | Sequential        | 132 K \n",
      "43  | model.layer2.0.downsample.0 | Conv2d            | 131 K \n",
      "44  | model.layer2.0.downsample.1 | BatchNorm2d       | 1 K   \n",
      "45  | model.layer2.1              | Bottleneck        | 280 K \n",
      "46  | model.layer2.1.conv1        | Conv2d            | 65 K  \n",
      "47  | model.layer2.1.bn1          | BatchNorm2d       | 256   \n",
      "48  | model.layer2.1.conv2        | Conv2d            | 147 K \n",
      "49  | model.layer2.1.bn2          | BatchNorm2d       | 256   \n",
      "50  | model.layer2.1.conv3        | Conv2d            | 65 K  \n",
      "51  | model.layer2.1.bn3          | BatchNorm2d       | 1 K   \n",
      "52  | model.layer2.1.relu         | ReLU              | 0     \n",
      "53  | model.layer2.2              | Bottleneck        | 280 K \n",
      "54  | model.layer2.2.conv1        | Conv2d            | 65 K  \n",
      "55  | model.layer2.2.bn1          | BatchNorm2d       | 256   \n",
      "56  | model.layer2.2.conv2        | Conv2d            | 147 K \n",
      "57  | model.layer2.2.bn2          | BatchNorm2d       | 256   \n",
      "58  | model.layer2.2.conv3        | Conv2d            | 65 K  \n",
      "59  | model.layer2.2.bn3          | BatchNorm2d       | 1 K   \n",
      "60  | model.layer2.2.relu         | ReLU              | 0     \n",
      "61  | model.layer2.3              | Bottleneck        | 280 K \n",
      "62  | model.layer2.3.conv1        | Conv2d            | 65 K  \n",
      "63  | model.layer2.3.bn1          | BatchNorm2d       | 256   \n",
      "64  | model.layer2.3.conv2        | Conv2d            | 147 K \n",
      "65  | model.layer2.3.bn2          | BatchNorm2d       | 256   \n",
      "66  | model.layer2.3.conv3        | Conv2d            | 65 K  \n",
      "67  | model.layer2.3.bn3          | BatchNorm2d       | 1 K   \n",
      "68  | model.layer2.3.relu         | ReLU              | 0     \n",
      "69  | model.layer3                | Sequential        | 7 M   \n",
      "70  | model.layer3.0              | Bottleneck        | 1 M   \n",
      "71  | model.layer3.0.conv1        | Conv2d            | 131 K \n",
      "72  | model.layer3.0.bn1          | BatchNorm2d       | 512   \n",
      "73  | model.layer3.0.conv2        | Conv2d            | 589 K \n",
      "74  | model.layer3.0.bn2          | BatchNorm2d       | 512   \n",
      "75  | model.layer3.0.conv3        | Conv2d            | 262 K \n",
      "76  | model.layer3.0.bn3          | BatchNorm2d       | 2 K   \n",
      "77  | model.layer3.0.relu         | ReLU              | 0     \n",
      "78  | model.layer3.0.downsample   | Sequential        | 526 K \n",
      "79  | model.layer3.0.downsample.0 | Conv2d            | 524 K \n",
      "80  | model.layer3.0.downsample.1 | BatchNorm2d       | 2 K   \n",
      "81  | model.layer3.1              | Bottleneck        | 1 M   \n",
      "82  | model.layer3.1.conv1        | Conv2d            | 262 K \n",
      "83  | model.layer3.1.bn1          | BatchNorm2d       | 512   \n",
      "84  | model.layer3.1.conv2        | Conv2d            | 589 K \n",
      "85  | model.layer3.1.bn2          | BatchNorm2d       | 512   \n",
      "86  | model.layer3.1.conv3        | Conv2d            | 262 K \n",
      "87  | model.layer3.1.bn3          | BatchNorm2d       | 2 K   \n",
      "88  | model.layer3.1.relu         | ReLU              | 0     \n",
      "89  | model.layer3.2              | Bottleneck        | 1 M   \n",
      "90  | model.layer3.2.conv1        | Conv2d            | 262 K \n",
      "91  | model.layer3.2.bn1          | BatchNorm2d       | 512   \n",
      "92  | model.layer3.2.conv2        | Conv2d            | 589 K \n",
      "93  | model.layer3.2.bn2          | BatchNorm2d       | 512   \n",
      "94  | model.layer3.2.conv3        | Conv2d            | 262 K \n",
      "95  | model.layer3.2.bn3          | BatchNorm2d       | 2 K   \n",
      "96  | model.layer3.2.relu         | ReLU              | 0     \n",
      "97  | model.layer3.3              | Bottleneck        | 1 M   \n",
      "98  | model.layer3.3.conv1        | Conv2d            | 262 K \n",
      "99  | model.layer3.3.bn1          | BatchNorm2d       | 512   \n",
      "100 | model.layer3.3.conv2        | Conv2d            | 589 K \n",
      "101 | model.layer3.3.bn2          | BatchNorm2d       | 512   \n",
      "102 | model.layer3.3.conv3        | Conv2d            | 262 K \n",
      "103 | model.layer3.3.bn3          | BatchNorm2d       | 2 K   \n",
      "104 | model.layer3.3.relu         | ReLU              | 0     \n",
      "105 | model.layer3.4              | Bottleneck        | 1 M   \n",
      "106 | model.layer3.4.conv1        | Conv2d            | 262 K \n",
      "107 | model.layer3.4.bn1          | BatchNorm2d       | 512   \n",
      "108 | model.layer3.4.conv2        | Conv2d            | 589 K \n",
      "109 | model.layer3.4.bn2          | BatchNorm2d       | 512   \n",
      "110 | model.layer3.4.conv3        | Conv2d            | 262 K \n",
      "111 | model.layer3.4.bn3          | BatchNorm2d       | 2 K   \n",
      "112 | model.layer3.4.relu         | ReLU              | 0     \n",
      "113 | model.layer3.5              | Bottleneck        | 1 M   \n",
      "114 | model.layer3.5.conv1        | Conv2d            | 262 K \n",
      "115 | model.layer3.5.bn1          | BatchNorm2d       | 512   \n",
      "116 | model.layer3.5.conv2        | Conv2d            | 589 K \n",
      "117 | model.layer3.5.bn2          | BatchNorm2d       | 512   \n",
      "118 | model.layer3.5.conv3        | Conv2d            | 262 K \n",
      "119 | model.layer3.5.bn3          | BatchNorm2d       | 2 K   \n",
      "120 | model.layer3.5.relu         | ReLU              | 0     \n",
      "121 | model.layer4                | Sequential        | 14 M  \n",
      "122 | model.layer4.0              | Bottleneck        | 6 M   \n",
      "123 | model.layer4.0.conv1        | Conv2d            | 524 K \n",
      "124 | model.layer4.0.bn1          | BatchNorm2d       | 1 K   \n",
      "125 | model.layer4.0.conv2        | Conv2d            | 2 M   \n",
      "126 | model.layer4.0.bn2          | BatchNorm2d       | 1 K   \n",
      "127 | model.layer4.0.conv3        | Conv2d            | 1 M   \n",
      "128 | model.layer4.0.bn3          | BatchNorm2d       | 4 K   \n",
      "129 | model.layer4.0.relu         | ReLU              | 0     \n",
      "130 | model.layer4.0.downsample   | Sequential        | 2 M   \n",
      "131 | model.layer4.0.downsample.0 | Conv2d            | 2 M   \n",
      "132 | model.layer4.0.downsample.1 | BatchNorm2d       | 4 K   \n",
      "133 | model.layer4.1              | Bottleneck        | 4 M   \n",
      "134 | model.layer4.1.conv1        | Conv2d            | 1 M   \n",
      "135 | model.layer4.1.bn1          | BatchNorm2d       | 1 K   \n",
      "136 | model.layer4.1.conv2        | Conv2d            | 2 M   \n",
      "137 | model.layer4.1.bn2          | BatchNorm2d       | 1 K   \n",
      "138 | model.layer4.1.conv3        | Conv2d            | 1 M   \n",
      "139 | model.layer4.1.bn3          | BatchNorm2d       | 4 K   \n",
      "140 | model.layer4.1.relu         | ReLU              | 0     \n",
      "141 | model.layer4.2              | Bottleneck        | 4 M   \n",
      "142 | model.layer4.2.conv1        | Conv2d            | 1 M   \n",
      "143 | model.layer4.2.bn1          | BatchNorm2d       | 1 K   \n",
      "144 | model.layer4.2.conv2        | Conv2d            | 2 M   \n",
      "145 | model.layer4.2.bn2          | BatchNorm2d       | 1 K   \n",
      "146 | model.layer4.2.conv3        | Conv2d            | 1 M   \n",
      "147 | model.layer4.2.bn3          | BatchNorm2d       | 4 K   \n",
      "148 | model.layer4.2.relu         | ReLU              | 0     \n",
      "149 | model.avgpool               | AdaptiveAvgPool2d | 0     \n",
      "150 | model.fc                    | Sequential        | 1 M   \n",
      "151 | model.fc.0                  | Linear            | 1 M   \n",
      "152 | model.fc.1                  | BatchNorm1d       | 1 K   \n",
      "153 | model.fc.2                  | Linear            | 513   \n",
      "154 | loss                        | BCEWithLogitsLoss | 0     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f45f464b7648d2a71fa359129fc02e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validation sanity check', layout=Layout(flex='2'), max=5, sty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe8ed16838347edb2dd6d6fcbe422b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', layout=Layout(flex='2'), max=1), HTML(value='')), layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py:286: DeprecationWarning: Displayed epoch numbers in the progress bar start from \"1\" until v0.6.x, but will start from \"0\" in v0.8.0.\n",
      "  ' but will start from \"0\" in v0.8.0.', DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9061cb2dcca2433f8555e6e713c141b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validating', layout=Layout(flex='2'), max=201, style=Progress…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828d2e3766a54b6e8ca60e86d3fb159d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validating', layout=Layout(flex='2'), max=201, style=Progress…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eef180e9a4c4b39bbef86fc977636ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validating', layout=Layout(flex='2'), max=201, style=Progress…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599091af91bd4acf8eacd4965037c242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validating', layout=Layout(flex='2'), max=201, style=Progress…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90702cd0220c44faab59bcdee790239b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validating', layout=Layout(flex='2'), max=201, style=Progress…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94e1b5f5bc2740f2828e1c0740f0b81e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validating', layout=Layout(flex='2'), max=201, style=Progress…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9de298e0e5f4db7bc2aa57700654bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validating', layout=Layout(flex='2'), max=201, style=Progress…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b773a6ffb1e348c5b50d728220cd16e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validating', layout=Layout(flex='2'), max=201, style=Progress…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee0de765bfc04c78ae61e61954c3df6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validating', layout=Layout(flex='2'), max=201, style=Progress…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "011cce14734541058ff8e0745e43db48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validating', layout=Layout(flex='2'), max=201, style=Progress…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "INFO:root:\n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3319, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-46-a9cfe90d3685>\", line 1, in <module>\n",
      "    model, logs, df_cache, basemodel_lr = catsmodel.trained_model(base_lr_continous_nocache_params[-1], show_progress=True)\n",
      "  File \"/home/jhofmanninger/Projects/catinous/catinous/CatsinomModelGramCache.py\", line 370, in trained_model\n",
      "    torch.save(model.state_dict(), weights_path)\n",
      "  File \"/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 766, in fit\n",
      "    self.single_gpu_train(model)\n",
      "  File \"/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/trainer/distrib_parts.py\", line 441, in single_gpu_train\n",
      "    self.run_pretrain_routine(model)\n",
      "  File \"/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 904, in run_pretrain_routine\n",
      "    self.train()\n",
      "  File \"/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py\", line 336, in train\n",
      "    self.run_training_epoch()\n",
      "  File \"/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py\", line 412, in run_training_epoch\n",
      "    self.run_evaluation(test=self.testing)\n",
      "  File \"/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/trainer/evaluation_loop.py\", line 305, in run_evaluation\n",
      "    test)\n",
      "  File \"/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/trainer/evaluation_loop.py\", line 218, in evaluate\n",
      "    for batch_idx, batch in enumerate(dataloader):\n",
      "  File \"/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 804, in __next__\n",
      "    idx, data = self._get_data()\n",
      "  File \"/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 771, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "  File \"/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 724, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "  File \"/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2034, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "model, logs, df_cache, basemodel_lr = catsmodel.trained_model(base_lr_continous_nocache_params[-1], show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_acc_hr</th>\n",
       "      <th>val_acc_lr</th>\n",
       "      <th>val_loss_hr</th>\n",
       "      <th>val_loss_lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-13 11:50:32.981780</td>\n",
       "      <td>0</td>\n",
       "      <td>0.758581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-13 11:50:37.581619</td>\n",
       "      <td>0</td>\n",
       "      <td>0.670475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2020-02-13 11:50:43.870400</td>\n",
       "      <td>0</td>\n",
       "      <td>0.653133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2020-02-13 11:50:50.094833</td>\n",
       "      <td>0</td>\n",
       "      <td>0.827174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2020-02-13 11:50:55.395019</td>\n",
       "      <td>0</td>\n",
       "      <td>1.230527</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>2020-02-13 12:32:26.755774</td>\n",
       "      <td>0</td>\n",
       "      <td>0.163441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>326</td>\n",
       "      <td>2020-02-13 12:32:31.734975</td>\n",
       "      <td>0</td>\n",
       "      <td>0.461115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>327</td>\n",
       "      <td>2020-02-13 12:32:37.083267</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>328</td>\n",
       "      <td>2020-02-13 12:32:42.182645</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>329</td>\n",
       "      <td>2020-02-13 12:33:21.275623</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.926887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.274671</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>330 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     created_at  epoch  train_loss  val_acc_hr  val_acc_lr  \\\n",
       "0    2020-02-13 11:50:32.981780      0    0.758581         NaN         NaN   \n",
       "1    2020-02-13 11:50:37.581619      0    0.670475         NaN         NaN   \n",
       "2    2020-02-13 11:50:43.870400      0    0.653133         NaN         NaN   \n",
       "3    2020-02-13 11:50:50.094833      0    0.827174         NaN         NaN   \n",
       "4    2020-02-13 11:50:55.395019      0    1.230527         NaN         NaN   \n",
       "..                          ...    ...         ...         ...         ...   \n",
       "325  2020-02-13 12:32:26.755774      0    0.163441         NaN         NaN   \n",
       "326  2020-02-13 12:32:31.734975      0    0.461115         NaN         NaN   \n",
       "327  2020-02-13 12:32:37.083267      0    0.055282         NaN         NaN   \n",
       "328  2020-02-13 12:32:42.182645      0    0.121794         NaN         NaN   \n",
       "329  2020-02-13 12:33:21.275623      0         NaN    0.926887         0.0   \n",
       "\n",
       "     val_loss_hr  val_loss_lr  \n",
       "0            NaN          NaN  \n",
       "1            NaN          NaN  \n",
       "2            NaN          NaN  \n",
       "3            NaN          NaN  \n",
       "4            NaN          NaN  \n",
       "..           ...          ...  \n",
       "325          NaN          NaN  \n",
       "326          NaN          NaN  \n",
       "327          NaN          NaN  \n",
       "328          NaN          NaN  \n",
       "329     0.274671          0.0  \n",
       "\n",
       "[330 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hr->lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1581931605124311\n",
      "sshpass -f ~/.ssh/pass ssh cn1.cir.meduniwien.ac.at sbatch --export=NONE --partition full /scratch/1581931605124311.job\n",
      "15819316076048906\n",
      "sshpass -f ~/.ssh/pass ssh cn1.cir.meduniwien.ac.at sbatch --export=NONE --partition full /scratch/15819316076048906.job\n",
      "15819316091844318\n",
      "sshpass -f ~/.ssh/pass ssh cn1.cir.meduniwien.ac.at sbatch --export=NONE --partition full /scratch/15819316091844318.job\n",
      "15819316107077065\n",
      "sshpass -f ~/.ssh/pass ssh cn1.cir.meduniwien.ac.at sbatch --export=NONE --partition full /scratch/15819316107077065.job\n",
      "15819316125707395\n",
      "sshpass -f ~/.ssh/pass ssh cn1.cir.meduniwien.ac.at sbatch --export=NONE --partition full /scratch/15819316125707395.job\n"
     ]
    }
   ],
   "source": [
    "hparams['base_model'] = basemodel_hr,\n",
    "hparams['direction'] = 'hr->lr'     \n",
    "base_lr_continous_params = []\n",
    "for i in range(5):\n",
    "    base_lr_continous_params.append(hparams.copy())\n",
    "    base_lr_continous_params[-1]['run_postfix'] = i+1\n",
    "    if schedule:\n",
    "        slurm.srun(catsmodel.trained_model, [base_lr_continous_params[-1]], params=sparams, remote=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Gram hooks and cache initialized. Cachesize: 128\n",
      "/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/callbacks/pt_callbacks.py:401: DeprecationWarning: Epochs indexing of `scheduling` starts from \"1\" until v0.6.x, but will start from \"0\" in v0.8.0.\n",
      "  ' but will start from \"0\" in v0.8.0.', DeprecationWarning)\n",
      "INFO:root:GPU available: True, used: True\n",
      "INFO:root:VISIBLE GPUS: 0\n",
      "INFO:root:\n",
      "    | Name                        | Type              | Params\n",
      "--------------------------------------------------------------\n",
      "0   | model                       | ResNet            | 24 M  \n",
      "1   | model.conv1                 | Conv2d            | 9 K   \n",
      "2   | model.bn1                   | BatchNorm2d       | 128   \n",
      "3   | model.relu                  | ReLU              | 0     \n",
      "4   | model.maxpool               | MaxPool2d         | 0     \n",
      "5   | model.layer1                | Sequential        | 215 K \n",
      "6   | model.layer1.0              | Bottleneck        | 75 K  \n",
      "7   | model.layer1.0.conv1        | Conv2d            | 4 K   \n",
      "8   | model.layer1.0.bn1          | BatchNorm2d       | 128   \n",
      "9   | model.layer1.0.conv2        | Conv2d            | 36 K  \n",
      "10  | model.layer1.0.bn2          | BatchNorm2d       | 128   \n",
      "11  | model.layer1.0.conv3        | Conv2d            | 16 K  \n",
      "12  | model.layer1.0.bn3          | BatchNorm2d       | 512   \n",
      "13  | model.layer1.0.relu         | ReLU              | 0     \n",
      "14  | model.layer1.0.downsample   | Sequential        | 16 K  \n",
      "15  | model.layer1.0.downsample.0 | Conv2d            | 16 K  \n",
      "16  | model.layer1.0.downsample.1 | BatchNorm2d       | 512   \n",
      "17  | model.layer1.1              | Bottleneck        | 70 K  \n",
      "18  | model.layer1.1.conv1        | Conv2d            | 16 K  \n",
      "19  | model.layer1.1.bn1          | BatchNorm2d       | 128   \n",
      "20  | model.layer1.1.conv2        | Conv2d            | 36 K  \n",
      "21  | model.layer1.1.bn2          | BatchNorm2d       | 128   \n",
      "22  | model.layer1.1.conv3        | Conv2d            | 16 K  \n",
      "23  | model.layer1.1.bn3          | BatchNorm2d       | 512   \n",
      "24  | model.layer1.1.relu         | ReLU              | 0     \n",
      "25  | model.layer1.2              | Bottleneck        | 70 K  \n",
      "26  | model.layer1.2.conv1        | Conv2d            | 16 K  \n",
      "27  | model.layer1.2.bn1          | BatchNorm2d       | 128   \n",
      "28  | model.layer1.2.conv2        | Conv2d            | 36 K  \n",
      "29  | model.layer1.2.bn2          | BatchNorm2d       | 128   \n",
      "30  | model.layer1.2.conv3        | Conv2d            | 16 K  \n",
      "31  | model.layer1.2.bn3          | BatchNorm2d       | 512   \n",
      "32  | model.layer1.2.relu         | ReLU              | 0     \n",
      "33  | model.layer2                | Sequential        | 1 M   \n",
      "34  | model.layer2.0              | Bottleneck        | 379 K \n",
      "35  | model.layer2.0.conv1        | Conv2d            | 32 K  \n",
      "36  | model.layer2.0.bn1          | BatchNorm2d       | 256   \n",
      "37  | model.layer2.0.conv2        | Conv2d            | 147 K \n",
      "38  | model.layer2.0.bn2          | BatchNorm2d       | 256   \n",
      "39  | model.layer2.0.conv3        | Conv2d            | 65 K  \n",
      "40  | model.layer2.0.bn3          | BatchNorm2d       | 1 K   \n",
      "41  | model.layer2.0.relu         | ReLU              | 0     \n",
      "42  | model.layer2.0.downsample   | Sequential        | 132 K \n",
      "43  | model.layer2.0.downsample.0 | Conv2d            | 131 K \n",
      "44  | model.layer2.0.downsample.1 | BatchNorm2d       | 1 K   \n",
      "45  | model.layer2.1              | Bottleneck        | 280 K \n",
      "46  | model.layer2.1.conv1        | Conv2d            | 65 K  \n",
      "47  | model.layer2.1.bn1          | BatchNorm2d       | 256   \n",
      "48  | model.layer2.1.conv2        | Conv2d            | 147 K \n",
      "49  | model.layer2.1.bn2          | BatchNorm2d       | 256   \n",
      "50  | model.layer2.1.conv3        | Conv2d            | 65 K  \n",
      "51  | model.layer2.1.bn3          | BatchNorm2d       | 1 K   \n",
      "52  | model.layer2.1.relu         | ReLU              | 0     \n",
      "53  | model.layer2.2              | Bottleneck        | 280 K \n",
      "54  | model.layer2.2.conv1        | Conv2d            | 65 K  \n",
      "55  | model.layer2.2.bn1          | BatchNorm2d       | 256   \n",
      "56  | model.layer2.2.conv2        | Conv2d            | 147 K \n",
      "57  | model.layer2.2.bn2          | BatchNorm2d       | 256   \n",
      "58  | model.layer2.2.conv3        | Conv2d            | 65 K  \n",
      "59  | model.layer2.2.bn3          | BatchNorm2d       | 1 K   \n",
      "60  | model.layer2.2.relu         | ReLU              | 0     \n",
      "61  | model.layer2.3              | Bottleneck        | 280 K \n",
      "62  | model.layer2.3.conv1        | Conv2d            | 65 K  \n",
      "63  | model.layer2.3.bn1          | BatchNorm2d       | 256   \n",
      "64  | model.layer2.3.conv2        | Conv2d            | 147 K \n",
      "65  | model.layer2.3.bn2          | BatchNorm2d       | 256   \n",
      "66  | model.layer2.3.conv3        | Conv2d            | 65 K  \n",
      "67  | model.layer2.3.bn3          | BatchNorm2d       | 1 K   \n",
      "68  | model.layer2.3.relu         | ReLU              | 0     \n",
      "69  | model.layer3                | Sequential        | 7 M   \n",
      "70  | model.layer3.0              | Bottleneck        | 1 M   \n",
      "71  | model.layer3.0.conv1        | Conv2d            | 131 K \n",
      "72  | model.layer3.0.bn1          | BatchNorm2d       | 512   \n",
      "73  | model.layer3.0.conv2        | Conv2d            | 589 K \n",
      "74  | model.layer3.0.bn2          | BatchNorm2d       | 512   \n",
      "75  | model.layer3.0.conv3        | Conv2d            | 262 K \n",
      "76  | model.layer3.0.bn3          | BatchNorm2d       | 2 K   \n",
      "77  | model.layer3.0.relu         | ReLU              | 0     \n",
      "78  | model.layer3.0.downsample   | Sequential        | 526 K \n",
      "79  | model.layer3.0.downsample.0 | Conv2d            | 524 K \n",
      "80  | model.layer3.0.downsample.1 | BatchNorm2d       | 2 K   \n",
      "81  | model.layer3.1              | Bottleneck        | 1 M   \n",
      "82  | model.layer3.1.conv1        | Conv2d            | 262 K \n",
      "83  | model.layer3.1.bn1          | BatchNorm2d       | 512   \n",
      "84  | model.layer3.1.conv2        | Conv2d            | 589 K \n",
      "85  | model.layer3.1.bn2          | BatchNorm2d       | 512   \n",
      "86  | model.layer3.1.conv3        | Conv2d            | 262 K \n",
      "87  | model.layer3.1.bn3          | BatchNorm2d       | 2 K   \n",
      "88  | model.layer3.1.relu         | ReLU              | 0     \n",
      "89  | model.layer3.2              | Bottleneck        | 1 M   \n",
      "90  | model.layer3.2.conv1        | Conv2d            | 262 K \n",
      "91  | model.layer3.2.bn1          | BatchNorm2d       | 512   \n",
      "92  | model.layer3.2.conv2        | Conv2d            | 589 K \n",
      "93  | model.layer3.2.bn2          | BatchNorm2d       | 512   \n",
      "94  | model.layer3.2.conv3        | Conv2d            | 262 K \n",
      "95  | model.layer3.2.bn3          | BatchNorm2d       | 2 K   \n",
      "96  | model.layer3.2.relu         | ReLU              | 0     \n",
      "97  | model.layer3.3              | Bottleneck        | 1 M   \n",
      "98  | model.layer3.3.conv1        | Conv2d            | 262 K \n",
      "99  | model.layer3.3.bn1          | BatchNorm2d       | 512   \n",
      "100 | model.layer3.3.conv2        | Conv2d            | 589 K \n",
      "101 | model.layer3.3.bn2          | BatchNorm2d       | 512   \n",
      "102 | model.layer3.3.conv3        | Conv2d            | 262 K \n",
      "103 | model.layer3.3.bn3          | BatchNorm2d       | 2 K   \n",
      "104 | model.layer3.3.relu         | ReLU              | 0     \n",
      "105 | model.layer3.4              | Bottleneck        | 1 M   \n",
      "106 | model.layer3.4.conv1        | Conv2d            | 262 K \n",
      "107 | model.layer3.4.bn1          | BatchNorm2d       | 512   \n",
      "108 | model.layer3.4.conv2        | Conv2d            | 589 K \n",
      "109 | model.layer3.4.bn2          | BatchNorm2d       | 512   \n",
      "110 | model.layer3.4.conv3        | Conv2d            | 262 K \n",
      "111 | model.layer3.4.bn3          | BatchNorm2d       | 2 K   \n",
      "112 | model.layer3.4.relu         | ReLU              | 0     \n",
      "113 | model.layer3.5              | Bottleneck        | 1 M   \n",
      "114 | model.layer3.5.conv1        | Conv2d            | 262 K \n",
      "115 | model.layer3.5.bn1          | BatchNorm2d       | 512   \n",
      "116 | model.layer3.5.conv2        | Conv2d            | 589 K \n",
      "117 | model.layer3.5.bn2          | BatchNorm2d       | 512   \n",
      "118 | model.layer3.5.conv3        | Conv2d            | 262 K \n",
      "119 | model.layer3.5.bn3          | BatchNorm2d       | 2 K   \n",
      "120 | model.layer3.5.relu         | ReLU              | 0     \n",
      "121 | model.layer4                | Sequential        | 14 M  \n",
      "122 | model.layer4.0              | Bottleneck        | 6 M   \n",
      "123 | model.layer4.0.conv1        | Conv2d            | 524 K \n",
      "124 | model.layer4.0.bn1          | BatchNorm2d       | 1 K   \n",
      "125 | model.layer4.0.conv2        | Conv2d            | 2 M   \n",
      "126 | model.layer4.0.bn2          | BatchNorm2d       | 1 K   \n",
      "127 | model.layer4.0.conv3        | Conv2d            | 1 M   \n",
      "128 | model.layer4.0.bn3          | BatchNorm2d       | 4 K   \n",
      "129 | model.layer4.0.relu         | ReLU              | 0     \n",
      "130 | model.layer4.0.downsample   | Sequential        | 2 M   \n",
      "131 | model.layer4.0.downsample.0 | Conv2d            | 2 M   \n",
      "132 | model.layer4.0.downsample.1 | BatchNorm2d       | 4 K   \n",
      "133 | model.layer4.1              | Bottleneck        | 4 M   \n",
      "134 | model.layer4.1.conv1        | Conv2d            | 1 M   \n",
      "135 | model.layer4.1.bn1          | BatchNorm2d       | 1 K   \n",
      "136 | model.layer4.1.conv2        | Conv2d            | 2 M   \n",
      "137 | model.layer4.1.bn2          | BatchNorm2d       | 1 K   \n",
      "138 | model.layer4.1.conv3        | Conv2d            | 1 M   \n",
      "139 | model.layer4.1.bn3          | BatchNorm2d       | 4 K   \n",
      "140 | model.layer4.1.relu         | ReLU              | 0     \n",
      "141 | model.layer4.2              | Bottleneck        | 4 M   \n",
      "142 | model.layer4.2.conv1        | Conv2d            | 1 M   \n",
      "143 | model.layer4.2.bn1          | BatchNorm2d       | 1 K   \n",
      "144 | model.layer4.2.conv2        | Conv2d            | 2 M   \n",
      "145 | model.layer4.2.bn2          | BatchNorm2d       | 1 K   \n",
      "146 | model.layer4.2.conv3        | Conv2d            | 1 M   \n",
      "147 | model.layer4.2.bn3          | BatchNorm2d       | 4 K   \n",
      "148 | model.layer4.2.relu         | ReLU              | 0     \n",
      "149 | model.avgpool               | AdaptiveAvgPool2d | 0     \n",
      "150 | model.fc                    | Sequential        | 1 M   \n",
      "151 | model.fc.0                  | Linear            | 1 M   \n",
      "152 | model.fc.1                  | BatchNorm1d       | 1 K   \n",
      "153 | model.fc.2                  | Linear            | 513   \n",
      "154 | loss                        | BCEWithLogitsLoss | 0     \n",
      "/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py:286: DeprecationWarning: Displayed epoch numbers in the progress bar start from \"1\" until v0.6.x, but will start from \"0\" in v0.8.0.\n",
      "  ' but will start from \"0\" in v0.8.0.', DeprecationWarning)\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f1aacfca860>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/multiprocessing/process.py\", line 124, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/multiprocessing/popen_fork.py\", line 50, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-11d5ad0f1a8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_cache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatsmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_lr_continous_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/catinous/catinous/CatsinomModelGramCache.py\u001b[0m in \u001b[0;36mtrained_model\u001b[0;34m(hparams)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpllogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_check_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_check_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_gpu_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0;31m# ON CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/trainer/distrib_parts.py\u001b[0m in \u001b[0;36msingle_gpu_train\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pretrain_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdp_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_pretrain_routine\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0;31m# CORE TRAINING LOOP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0;31m# summarize profile results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# RUN TNG EPOCH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;31m# -----------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0;31m# update LR schedulers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;31m# RUN TRAIN STEP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;31m# ---------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m             \u001b[0mbatch_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm_dic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_step_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_batch\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m                 \u001b[0;31m# calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m                 \u001b[0;31m# nan grads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36moptimizer_closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    505\u001b[0m                     \u001b[0mmodel_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_backward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m                         \u001b[0mmodel_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_amp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m                     \u001b[0;31m# track metrics for callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/core/hooks.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, use_amp, loss, optimizer, optimizer_idx)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/candid/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if schedule\n",
    "model, logs, df_cache, modelpath = catsmodel.trained_model(base_lr_continous_params[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CatsinomModelGramCache(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Linear(in_features=512, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (loss): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15815110948576212\n",
      "sshpass -f ~/.ssh/pass ssh cn1.cir.meduniwien.ac.at sbatch --export=NONE --partition full /scratch/15815110948576212.job\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/scratch/15815110948576212_res.dll'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparams = {\n",
    "    'binary': '/home/cir/jhofmanninger/env/candid/bin/python',\n",
    "    'cwd': '/home/cir/jhofmanninger/Projects/catinous',\n",
    "    'gpu': 1,\n",
    "    'partition': 'full',\n",
    "    'memory': 15000,\n",
    "    'jobname': 'catinous_test'}\n",
    "slurm.srun(catsmodel.trained_model, [hparams], params=sparams, remote=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.load(open('/scratch/158150528649969.dll','rb'))['function'](hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/scratch/15815045002145245_res.dll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatsinomModelGramCache(hparams=hparams, device=torch.device('cuda'))\n",
    "logger = cutils.pllogger(model.hparams)\n",
    "trainer = Trainer(gpus=1, max_epochs=1, early_stop_callback=False, logger=logger, val_check_interval=3000, show_progress_bar=True, checkpoint_callback=False)\n",
    "trainer.fit(model)\n",
    "torch.save(model.state_dict(), '/project/catinous/trained_models/' + expname + '_run_'+str(i)+'.pt')\n",
    "save_cache_to_csv(model.trainingscache.cachelist, '/project/catinous/trained_cache/' + expname + '_run_'+str(i)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slurm.srun(trainer.fit, model, params=sparams, remote=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'binary': '/home/jhofmanninger/anaconda3/envs/candid/bin/python',\n",
       " 'outputpath': '/home/cir/jhofmanninger/slurmoutput/',\n",
       " 'jobname': '',\n",
       " 'days': 0,\n",
       " 'hours': '0',\n",
       " 'minutes': '10',\n",
       " 'memory': 2000,\n",
       " 'ntasks': 1,\n",
       " 'cpusptask': 4,\n",
       " 'qos': 'normal',\n",
       " 'mailuser': 'johannes.hofmanninger@meduniwien.ac.at',\n",
       " 'cwd': '/home/jhofmanninger/Projects/catinous',\n",
       " 'dillfile': '',\n",
       " 'gpu': 0,\n",
       " 'partition': 'cir',\n",
       " 'paths': []}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slurm.slurm_params_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cache_to_csv(cache, savepath):\n",
    "    df_cache = pd.DataFrame({'filepath':[ci.filepath for ci in cache], 'label': [ci.label.cpu().numpy()[0] for ci in cache], 'res': [ci.res for ci in cache], 'traincounter': [ci.traincounter for ci in cache]})\n",
    "    df_cache.to_csv(savepath, index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:gpu available: True, used: True\n",
      "INFO:root:VISIBLE GPUS: 0\n",
      "INFO:root:\n",
      "              Name               Type Params\n",
      "0            model             ResNet   24 M\n",
      "1      model.conv1             Conv2d    9 K\n",
      "2        model.bn1        BatchNorm2d  128  \n",
      "3       model.relu               ReLU    0  \n",
      "4    model.maxpool          MaxPool2d    0  \n",
      "..             ...                ...    ...\n",
      "150       model.fc         Sequential    1 M\n",
      "151     model.fc.0             Linear    1 M\n",
      "152     model.fc.1        BatchNorm1d    1 K\n",
      "153     model.fc.2             Linear  513  \n",
      "154           loss  BCEWithLogitsLoss    0  \n",
      "\n",
      "[155 rows x 3 columns]\n",
      "/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/callbacks/pt_callbacks.py:314: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  ' skipping.', RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "hparams = get_default_hparams()\n",
    "hparams['force_misclassified'] = True\n",
    "hparams['cachemaximum'] = 128\n",
    "hparams['continous'] = False\n",
    "expname = 'continous_random_cache_transphase_force_misclassified_bsize123'\n",
    "model = CatsinomModelGramCache(argparse.Namespace(**hparams), device = torch.device('cuda'))\n",
    "\n",
    "basemodel = '/project/catinous/trained_models/lrbase_iterations.pt'\n",
    "model.load_state_dict(torch.load(basemodel))\n",
    "\n",
    "logger = pllogging.TestTubeLogger( 'catinous_log_iterations', name=expname)\n",
    "trainer = Trainer(gpus=1, max_epochs=1, early_stop_callback=False, logger=logger, val_check_interval=10, show_progress_bar=False, checkpoint_callback=False)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:gpu available: True, used: True\n",
      "INFO:root:VISIBLE GPUS: 0\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "INFO:root:\n",
      "              Name               Type Params\n",
      "0            model             ResNet   24 M\n",
      "1      model.conv1             Conv2d    9 K\n",
      "2        model.bn1        BatchNorm2d  128  \n",
      "3       model.relu               ReLU    0  \n",
      "4    model.maxpool          MaxPool2d    0  \n",
      "..             ...                ...    ...\n",
      "150       model.fc         Sequential    1 M\n",
      "151     model.fc.0             Linear    1 M\n",
      "152     model.fc.1        BatchNorm1d    1 K\n",
      "153     model.fc.2             Linear  513  \n",
      "154           loss  BCEWithLogitsLoss    0  \n",
      "\n",
      "[155 rows x 3 columns]\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/pytorch_lightning/callbacks/pt_callbacks.py:314: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  ' skipping.', RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "#testing different transition phases\n",
    "\n",
    "transitionphase = [1.0]\n",
    "\n",
    "for tp in transitionphase:\n",
    "    for i in range(2):\n",
    "        hparams = get_default_hparams()\n",
    "        hparams['transition_phase_after'] = tp\n",
    "        \n",
    "        expname = 'continous_random_cache_transphase_' + str(tp)\n",
    "        \n",
    "        model = CatsinomModelGramCache(argparse.Namespace(**hparams), device = torch.device('cuda'))\n",
    "\n",
    "        model.load_state_dict(torch.load(basemodel))\n",
    "\n",
    "        logger = pllogging.TestTubeLogger('catinous_log_iterations', name=expname)\n",
    "        trainer = Trainer(gpus=1, max_epochs=1, early_stop_callback=False, logger=logger, val_check_interval=10, show_progress_bar=False)\n",
    "        trainer.fit(model)\n",
    "        torch.save(model.state_dict(), '/project/catinous/trained_models/' + expname + '_run_'+str(i)+'.pt')\n",
    "\n",
    "        save_cache_to_csv(model.trainingscache.cachelist, '/project/catinous/trained_cache/' + expname + '_run_'+str(i)+'.csv')\n",
    "        \n",
    "        trainer = None\n",
    "        model = None\n",
    "        trainer = None\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing different cache sizes\n",
    "cache_size = [16, 128, 256]\n",
    "\n",
    "for cs in cache_size:\n",
    "    for i in range(3):\n",
    "        hparams = get_default_hparams()\n",
    "        hparams['cachemaximum'] = cs\n",
    "        \n",
    "        expname = 'continous_random_cache_cachesize_' + str(cs)\n",
    "        \n",
    "        model = CatsinomModelGramCache(argparse.Namespace(**hparams), device = torch.device('cuda'))\n",
    "\n",
    "        model.load_state_dict(torch.load(basemodel))\n",
    "\n",
    "        logger = pllogging.TestTubeLogger('catinous_log_iterations', name=expname)\n",
    "        trainer = Trainer(gpus=1, max_epochs=1, early_stop_callback=False, logger=logger, val_check_interval=10, show_progress_bar=False)\n",
    "        trainer.fit(model)\n",
    "        torch.save(model.state_dict(), '/project/catinous/trained_models/' + expname + '_run_'+str(i)+'.pt')\n",
    "\n",
    "        save_cache_to_csv(model.trainingscache.cachelist, '/project/catinous/trained_cache/' + expname + '_run_'+str(i)+'.csv')\n",
    "\n",
    "        trainer = None\n",
    "        model = None\n",
    "        torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Candid (new)",
   "language": "python",
   "name": "candid2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
