{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "#from catinous.CatsinomModel import CatsinomModel\n",
    "from catinous.CatsinomDataset import CatsinomDataset\n",
    "import catinous.CatsinomModelGramCache as catsmodel\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.metrics import confusion_matrix, auc, roc_curve\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from catinous.CatsinomDataset import Catsinom_Dataset_CatineousStream as StreamedDS\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "import pickle\n",
    "from py_jotools import mut\n",
    "import SimpleITK as sitk\n",
    "import joblib\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Gram hooks and cache initialized. Cachesize: 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read: /project/catinous/trained_models/cont_combined_basemodel_lr_fmiss_cache_tf07_1_b3a984e2d4.pt\n"
     ]
    }
   ],
   "source": [
    "# data = 'catsinom_combined_hrlowshift_dataset.csv'\n",
    "data = 'catsinom_combined_dataset.csv'\n",
    "\n",
    "\n",
    "# df_randomcache = pd.DataFrame()\n",
    "hparams={'continous': True,\n",
    "         'force_misclassified': True,\n",
    "         'datasetfile': data,\n",
    "         'base_model': 'batch_lr_base_train_1_2d20289ac9.pt',\n",
    "         'val_check_interval': 30,\n",
    "         'cachemaximum': 64,\n",
    "         'run_postfix': 1}\n",
    "# model = catsmodel.CatsinomModelGramCache(hparams=hparams)\n",
    "# model.freeze()\n",
    "model, logs, df_cache, modelpath = catsmodel.trained_model(hparams)\n",
    "suffix = '_continous_modalityshift'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cont_data = pd.read_csv('catsinom_combined_hrlowshift_dataset.csv', index_col=0)\n",
    "# valdata = cont_data.query('split == \"val\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_cont = DataLoader(CatsinomDataset('/project/catinous/cat_data/', data, split='val'), batch_size=8, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 801"
     ]
    }
   ],
   "source": [
    "mxlvl1 = np.zeros((801,256,256),dtype=np.float16)\n",
    "mxlvl2 = np.zeros((801,512,512),dtype=np.float16)\n",
    "mxlvl3 = np.zeros((801,1024,1024),dtype=np.float16)\n",
    "mxlvl4 = np.zeros((801,2048,2048),dtype=np.float16)\n",
    "cnt = 0\n",
    "full_res = []\n",
    "full_y = []\n",
    "for x, y, img, res in val_cont:\n",
    "    full_res.extend(res)\n",
    "    full_y.extend(y)\n",
    "    model.grammatrices = []\n",
    "    torch.sigmoid(model(x.float()))\n",
    "    mxlvl1[cnt:cnt+len(y)] = np.asarray([x.numpy() for x in model.grammatrices[0]]).astype(np.float16)\n",
    "    mxlvl2[cnt:cnt+len(y)] = np.asarray([x.numpy() for x in model.grammatrices[1]]).astype(np.float16)\n",
    "    mxlvl3[cnt:cnt+len(y)] = np.asarray([x.numpy() for x in model.grammatrices[2]]).astype(np.float16)\n",
    "    mxlvl4[cnt:cnt+len(y)] = np.asarray([x.numpy() for x in model.grammatrices[3]]).astype(np.float16)\n",
    "    cnt += len(y)\n",
    "    print('\\r %i' % cnt, end='')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_yy = [int(x.numpy()) for x in full_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 63"
     ]
    }
   ],
   "source": [
    "n_cache = len(df_cache)\n",
    "mxlvl1 = np.pad(mxlvl1, ((0,n_cache),(0,0),(0,0)), mode='constant', constant_values=0)\n",
    "mxlvl2 = np.pad(mxlvl2, ((0,n_cache),(0,0),(0,0)), mode='constant', constant_values=0)\n",
    "mxlvl3 = np.pad(mxlvl3, ((0,n_cache),(0,0),(0,0)), mode='constant', constant_values=0)\n",
    "mxlvl4 = np.pad(mxlvl4, ((0,n_cache),(0,0),(0,0)), mode='constant', constant_values=0)\n",
    "\n",
    "full_res_c = []\n",
    "full_y_c = []\n",
    "for i,r in df_cache.iterrows():\n",
    "    simg = sitk.ReadImage(os.path.join('/project/catinous/cat_data/', r.filepath))\n",
    "    img = sitk.GetArrayFromImage(simg)\n",
    "    img = mut.intensity_window(img, low=-1024, high=400)\n",
    "    img = torch.tensor(np.tile(mut.norm01(img),(3,1,1))[None,:,:,:])\n",
    "    full_res_c.append(r.res)\n",
    "    full_y_c.append(r.label)\n",
    "    model.grammatrices = []\n",
    "    torch.sigmoid(model(img.float()))\n",
    "    mxlvl1[801+i] = np.asarray([x.numpy() for x in model.grammatrices[0]]).astype(np.float16)\n",
    "    mxlvl2[801+i] = np.asarray([x.numpy() for x in model.grammatrices[1]]).astype(np.float16)\n",
    "    mxlvl3[801+i] = np.asarray([x.numpy() for x in model.grammatrices[2]]).astype(np.float16)\n",
    "    mxlvl4[801+i] = np.asarray([x.numpy() for x in model.grammatrices[3]]).astype(np.float16)\n",
    "    print('\\r %i' % i, end='')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/project/catinous/results_data/val_full_y_continous_modalityshift.p']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(mxlvl1, \"/project/catinous/results_data/val_grams1\" + suffix + \".p\")\n",
    "joblib.dump(mxlvl2, \"/project/catinous/results_data/val_grams2\" + suffix + \".p\")\n",
    "joblib.dump(mxlvl3, \"/project/catinous/results_data/val_grams3\" + suffix + \".p\")\n",
    "joblib.dump(mxlvl4, \"/project/catinous/results_data/val_grams4\" + suffix + \".p\")\n",
    "joblib.dump(full_res, \"/project/catinous/results_data/val_res\" + suffix + \".p\")\n",
    "joblib.dump(full_yy, \"/project/catinous/results_data/val_full_y\" + suffix + \".p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mxlvl1 = joblib.load(\"/project/catinous/results_data/val_grams1\" + suffix + \".p\")\n",
    "mxlvl2 = joblib.load(\"/project/catinous/results_data/val_grams2\" + suffix + \".p\")\n",
    "mxlvl3 = joblib.load(\"/project/catinous/results_data/val_grams3\" + suffix + \".p\")\n",
    "mxlvl4 = joblib.load(\"/project/catinous/results_data/val_grams4\" + suffix + \".p\")\n",
    "full_res = joblib.load(\"/project/catinous/results_data/val_res\" + suffix + \".p\")\n",
    "full_yy = joblib.load(\"/project/catinous/results_data/val_full_y\" + suffix + \".p\")\n",
    "lrbool = np.asarray([x == 'lr' for x in full_res])\n",
    "catbool = np.asarray([x == 1 for x in full_yy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 863 864"
     ]
    }
   ],
   "source": [
    "affinity_matrix = np.zeros((mxlvl1.shape[0],mxlvl1.shape[0]), dtype = np.float32)\n",
    "for i in range(mxlvl1.shape[0]):\n",
    "    for j in range(i+1,mxlvl1.shape[0]):\n",
    "        t = np.mean((mxlvl1[i].astype(np.float32)-mxlvl1[j].astype(np.float32))**2)\n",
    "        t += np.mean((mxlvl2[i].astype(np.float32)-mxlvl2[j].astype(np.float32))**2)\n",
    "        t += np.mean((mxlvl3[i].astype(np.float32)-mxlvl3[j].astype(np.float32))**2)\n",
    "        t += np.mean((mxlvl4[i].astype(np.float32)-mxlvl4[j].astype(np.float32))**2)\n",
    "        affinity_matrix[i,j] = t\n",
    "        affinity_matrix[j,i] = t\n",
    "        print('\\r %i %i' % (i,j),end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/project/catinous/results_data/affinity_matrix_continous_modalityshift.p']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(affinity_matrix, \"/project/catinous/results_data/affinity_matrix\" + suffix + \".p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affinity_matrix = np.pad(affinity_matrix, ((0,n_cache),(0,n_cache)), mode='constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 63"
     ]
    }
   ],
   "source": [
    "# for i in range(n_cache):\n",
    "#     for j in range(n_cache):\n",
    "#         t = np.mean((mxlvl1c[i].astype(np.float32)-mxlvl1c[j].astype(np.float32))**2)\n",
    "#         t += np.mean((mxlvl2c[i].astype(np.float32)-mxlvl2c[j].astype(np.float32))**2)\n",
    "#         t += np.mean((mxlvl3c[i].astype(np.float32)-mxlvl3c[j].astype(np.float32))**2)\n",
    "#         t += np.mean((mxlvl4c[i].astype(np.float32)-mxlvl4c[j].astype(np.float32))**2)\n",
    "#         affinity_matrix[801+i,801+j] = t\n",
    "#         print('\\r %i' % i, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "X_embedded = TSNE(n_components=2).fit_transform(affinity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax.set_title(\"Perplexity=%d\" % perplexity)\n",
    "marker_size = 4\n",
    "plt.scatter(X_embedded[np.where(np.logical_and(lrbool, ~catbool)),0], X_embedded[np.where(np.logical_and(lrbool, ~catbool)),1], c=(1,0,0), s=marker_size)\n",
    "plt.scatter(X_embedded[np.where(np.logical_and(lrbool, catbool)),0], X_embedded[np.where(np.logical_and(lrbool, catbool)),1], c=(.5,0,0), s=marker_size)\n",
    "\n",
    "plt.scatter(X_embedded[np.where(np.logical_and(~lrbool, ~catbool)),0], X_embedded[np.where(np.logical_and(~lrbool, ~catbool)),1], c=(0,.5,1), s=marker_size)\n",
    "plt.scatter(X_embedded[np.where(np.logical_and(~lrbool, catbool)),0], X_embedded[np.where(np.logical_and(~lrbool, catbool)),1], c=(0,0,.6), s=marker_size)\n",
    "\n",
    "plt.scatter(X_embedded[801:,0], X_embedded[801:,1], c=(.96, .25, 0.93), s=marker_size)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.legend(['a-','a+','b-','b+'])\n",
    "# plt.scatter(Y[green, 0], Y[green, 1], c=\"g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(801, 2)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.994927\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j = 708\n",
    "t = np.mean(mxlvl1[i].astype(np.float32)-mxlvl1[j].astype(np.float32)**2)\n",
    "t += np.mean(mxlvl2[i].astype(np.float32)-mxlvl2[j].astype(np.float32)**2)\n",
    "t += np.mean(mxlvl3[i].astype(np.float32)-mxlvl3[j].astype(np.float32)**2)\n",
    "t += np.mean(mxlvl4[i].astype(np.float32)-mxlvl4[j].astype(np.float32)**2)\n",
    "print(-np.log(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.623411e-06"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.067918e-05"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mxlvl1[0].astype(np.float32)-mxlvl1[1].astype(np.float32)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.99"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(affinity_matrix[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.528698"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.log(np.mean(blubb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.39834e-10"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((mxlvl1[0].astype(np.float32)-mxlvl1[2].astype(np.float32))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.3983e-10)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.mse_loss(torch.tensor(mxlvl1[0].astype(np.float32)),torch.tensor(mxlvl1[2].astype(np.float32)),reduce='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0424],\n",
       "        [0.0208],\n",
       "        [0.0312],\n",
       "        [0.0479],\n",
       "        [0.0296],\n",
       "        [0.0330],\n",
       "        [0.0586],\n",
       "        [0.0277]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.grammatrices = []\n",
    "torch.sigmoid(model(x.float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0424],\n",
       "        [0.0208],\n",
       "        [0.0312],\n",
       "        [0.0479],\n",
       "        [0.0296],\n",
       "        [0.0330],\n",
       "        [0.0586],\n",
       "        [0.0277]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(model(x.float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 256])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.grammatrices[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 256])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.grammatrices[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammatrix = [gm[0].cpu() for gm in model.grammatrices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float16)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Candid",
   "language": "python",
   "name": "candid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
