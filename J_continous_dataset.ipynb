{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "candid2",
   "display_name": "Candid (new)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from catinous.CatsinomModel import CatsinomModel\n",
    "from catinous.CatsinomDataset import CatsinomDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import visualizationutils as vu\n",
    "import argparse\n",
    "import pytorch_lightning.logging as pllogging\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsname = 'lr'\n",
    "\n",
    "def trained_full_dataset(dsname = 'lr', base_only=False):\n",
    "    \n",
    "    hparams = dict()\n",
    "    hparams['root_dir'] = '/project/catinous/cat_data/'\n",
    "    hparams['datasetfile'] = 'catsinom_' + dsname + '_dataset.csv'\n",
    "    hparams['batch_size'] = 8\n",
    "    hparams['train_iterations'] = 3000\n",
    "\n",
    "    if base_only:\n",
    "        hparams['trainsplit'] = ['base_train']\n",
    "        outname = '/project/catinous/trained_models/' + dsname + 'base_iterations.pt'\n",
    "    else:\n",
    "        hparams['trainsplit'] = ['train','base_train']\n",
    "        outname = '/project/catinous/trained_models/' + dsname + '_iterations.pt'\n",
    "\n",
    "    if not os.path.exists(outname):\n",
    "        logger = pllogging.TestTubeLogger('catinous_log_iterations', name=dsname)\n",
    "        trainer = Trainer(gpus=1, max_epochs=1, early_stop_callback=False, logger=logger, val_check_interval=500)\n",
    "        trainer.fit(model)\n",
    "        torch.save(model.state_dict(), outname)\n",
    "\n",
    "    return outname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "508/3288 [02:24<13:05,  3.54batch/s, batch_idx=499, gpu=0, loss=0.044, v_num=2]\nEpoch 1:  15%|█▌        | 509/3288 [02:24<15:20,  3.02batch/s, batch_idx=499, gpu=0, loss=0.044, v_num=2]\nEpoch 1:  16%|█▌        | 511/3288 [02:24<14:20,  3.23batch/s, batch_idx=499, gpu=0, loss=0.044, v_num=2]\nEpoch 1:  16%|█▌        | 513/3288 [02:25<13:56,  3.32batch/s, batch_idx=499, gpu=0, loss=0.044, v_num=2]\nEpoch 1:  16%|█▌        | 515/3288 [02:26<13:50,  3.34batch/s, batch_idx=499, gpu=0, loss=0.044, v_num=2]\nEpoch 1:  16%|█▌        | 517/3288 [02:26<13:39,  3.38batch/s, batch_idx=499, gpu=0, loss=0.044, v_num=2]\nEpoch 1:  16%|█▌        | 519/3288 [02:27<16:04,  2.87batch/s, batch_idx=499, gpu=0, loss=0.044, v_num=2]\nEpoch 1:  16%|█▌        | 521/3288 [02:28<17:40,  2.61batch/s, batch_idx=499, gpu=0, loss=0.044, v_num=2]\nEpoch 1:  16%|█▌        | 522/3288 [02:28<13:46,  3.35batch/s, batch_idx=499, gpu=0, loss=0.044, v_num=2]\nEpoch 1:  16%|█▌        | 523/3288 [02:29<21:34,  2.14batch/s, batch_idx=499, gpu=0, loss=0.044, v_num=2]\nEpoch 1:  16%|█▌        | 525/3288 [02:30<20:53,  2.20batch/s, batch_idx=499, gpu=0, loss=0.044, v_num=2]\nEpoch 1:  16%|█▌        | 527/3288 [02:31<19:26,  2.37batch/s, batch_idx=499, gpu=0, loss=0.044, v_num=2]\nEpoch 1:  16%|█▌        | 529/3288 [02:31<19:26,  2.37batch/s, batch_idx=499, gpu=0, loss=0.044, v_num=2]\nEpoch 1:  16%|█▌        | 531/3288 [02:32<17:16,  2.66batch/s, batch_idx=499, gpu=0, loss=0.044, v_num=2]\nEpoch 1:  16%|█▌        | 533/3288 [02:33<16:04,  2.86batch/s, batch_idx=499, gpu=0, loss=0.044, v_num=2]\nEpoch 1:  16%|█▌        | 534/3288 [02:33<12:58,  3.54batch/s, batch_idx=499, gpu=0, loss=0.044, v_num=2]\nEpoch 1:  16%|█▋        | 535/3288 [02:33<15:22,  2.98batch/s, batch_idx=499, gpu=0, loss=0.044, v_num=2]\nEpoch 1:  16%|█▋        | 537/3288 [02:34<14:38,  3.13batch/s, batch_idx=499, gpu=0, loss=0.044, v_num=2]\nEpoch 1:  16%|█▋        | 539/3288 [02:34<14:18,  3.20batch/s, batch_idx=499, gpu=0, loss=0.044, v_num=2]\nEpoch 1:  16%|█▋        | 541/3288 [02:35<13:54,  3.29batch/s, batch_idx=499, gpu=0, loss=0.044, v_num=2]\nEpoch 1:  17%|█▋        | 543/3288 [02:35<13:59,  3.27batch/s, batch_idx=499, gpu=0, loss=0.044, v_num=2]\nEpoch 1:  17%|█▋        | 545/3288 [02:36<15:12,  3.01batch/s, batch_idx=499, gpu=0, loss=0.044, v_num=2]\nEpoch 1:  17%|█▋        | 548/3288 [02:37<14:15,  3.20batch/s, batch_idx=499, gpu=0, loss=0.044, v_num=2]\nEpoch 1:  32%|███▏      | 1048/3288 [04:58<10:21,  3.60batch/s, batch_idx=999, gpu=0, loss=0.064, v_num=2]\nValidating:   0%|          | 0/48 [00:00<?, ?batch/s]\u001b[A\nEpoch 1:  32%|███▏      | 1049/3288 [04:59<16:36,  2.25batch/s, batch_idx=999, gpu=0, loss=0.064, v_num=2]\nEpoch 1:  32%|███▏      | 1051/3288 [04:59<14:54,  2.50batch/s, batch_idx=999, gpu=0, loss=0.064, v_num=2]\nEpoch 1:  32%|███▏      | 1053/3288 [05:00<13:51,  2.69batch/s, batch_idx=999, gpu=0, loss=0.064, v_num=2]\nEpoch 1:  32%|███▏      | 1055/3288 [05:00<12:46,  2.91batch/s, batch_idx=999, gpu=0, loss=0.064, v_num=2]\nEpoch 1:  32%|███▏      | 1057/3288 [05:01<12:18,  3.02batch/s, batch_idx=999, gpu=0, loss=0.064, v_num=2]\nEpoch 1:  32%|███▏      | 1059/3288 [05:01<11:47,  3.15batch/s, batch_idx=999, gpu=0, loss=0.064, v_num=2]\nEpoch 1:  32%|███▏      | 1061/3288 [05:02<11:38,  3.19batch/s, batch_idx=999, gpu=0, loss=0.064, v_num=2]\nEpoch 1:  32%|███▏      | 1063/3288 [05:03<11:15,  3.29batch/s, batch_idx=999, gpu=0, loss=0.064, v_num=2]\nEpoch 1:  32%|███▏      | 1065/3288 [05:03<11:07,  3.33batch/s, batch_idx=999, gpu=0, loss=0.064, v_num=2]\nEpoch 1:  32%|███▏      | 1067/3288 [05:04<10:50,  3.41batch/s, batch_idx=999, gpu=0, loss=0.064, v_num=2]\nEpoch 1:  33%|███▎      | 1069/3288 [05:04<10:45,  3.44batch/s, batch_idx=999, gpu=0, loss=0.064, v_num=2]\nEpoch 1:  33%|███▎      | 1071/3288 [05:05<10:40,  3.46batch/s, batch_idx=999, gpu=0, loss=0.064, v_num=2]\nEpoch 1:  33%|███▎      | 1073/3288 [05:05<10:46,  3.43batch/s, batch_idx=999, gpu=0, loss=0.064, v_num=2]\nEpoch 1:  33%|███▎      | 1075/3288 [05:06<10:43,  3.44batch/s, batch_idx=999, gpu=0, loss=0.064, v_num=2]\nEpoch 1:  33%|███▎      | 1076/3288 [05:06<08:48,  4.19batch/s, batch_idx=999, gpu=0, loss=0.064, v_num=2]\nEpoch 1:  33%|███▎      | 1077/3288 [05:07<11:29,  3.21batch/s, batch_idx=999, gpu=0, loss=0.064, v_num=2]\nEpoch 1:  33%|███▎      | 1079/3288 [05:07<11:22,  3.24batch/s, batch_idx=999, gpu=0, loss=0.064, v_num=2]\nEpoch 1:  33%|███▎      | 1081/3288 [05:08<11:05,  3.32batch/s, batch_idx=999, gpu=0, loss=0.064, v_num=2]\nEpoch 1:  33%|███▎      | 1082/3288 [05:08<08:54,  4.13batch/s, batch_idx=999, gpu=0, loss=0.064, v_num=2]\nEpoch 1:  33%|███▎      | 1083/3288 [05:08<11:10,  3.29batch/s, batch_idx=999, gpu=0, loss=0.064, v_num=2]\nEpoch 1:  33%|███▎      | 1085/3288 [05:09<10:52,  3.38batch/s, batch_idx=999, gpu=0, loss=0.064, v_num=2]\nEpoch 1:  33%|███▎      | 1086/3288 [05:09<09:14,  3.97batch/s, batch_idx=999, gpu=0, loss=0.064, v_num=2]\nEpoch 1:  33%|███▎      | 1087/3288 [05:10<12:10,  3.01batch/s, batch_idx=999, gpu=0, loss=0.064, v_num=2]\nEpoch 1:  33%|███▎      | 1089/3288 [05:10<11:41,  3.13batch/s, batch_idx=999, gpu=0, loss=0.064, v_num=2]\nEpoch 1:  33%|███▎      | 1090/3288 [05:10<09:25,  3.88batch/s, batch_idx=999, gpu=0, loss=0.064, v_num=2]\nEpoch 1:  33%|███▎      | 1091/3288 [05:11<11:36,  3.15batch/s, batch_idx=999, gpu=0, loss=0.064, v_num=2]\nEpoch 1:  33%|███▎      | 1093/3288 [05:11<10:59,  3.33batch/s, batch_idx=999, gpu=0, loss=0.064, v_num=2]\nEpoch 1:  33%|███▎      | 1094/3288 [05:11<08:54,  4.10batch/s, batch_idx=999, gpu=0, loss=0.064, v_num=2]\nEpoch 1:  33%|███▎      | 1096/3288 [05:12<11:28,  3.18batch/s, batch_idx=999, gpu=0, loss=0.064, v_num=2]\nEpoch 1:  49%|████▊     | 1596/3288 [07:33<07:47,  3.62batch/s, batch_idx=1499, gpu=0, loss=0.154, v_num=2]\nValidating:   0%|          | 0/48 [00:00<?, ?batch/s]\u001b[A\nEpoch 1:  49%|████▊     | 1597/3288 [07:34<13:13,  2.13batch/s, batch_idx=1499, gpu=0, loss=0.154, v_num=2]\nEpoch 1:  49%|████▊     | 1598/3288 [07:34<10:06,  2.79batch/s, batch_idx=1499, gpu=0, loss=0.154, v_num=2]\nEpoch 1:  49%|████▊     | 1599/3288 [07:34<10:48,  2.60batch/s, batch_idx=1499, gpu=0, loss=0.154, v_num=2]\nEpoch 1:  49%|████▊     | 1601/3288 [07:35<09:53,  2.84batch/s, batch_idx=1499, gpu=0, loss=0.154, v_num=2]\nEpoch 1:  49%|████▉     | 1603/3288 [07:35<09:17,  3.02batch/s, batch_idx=1499, gpu=0, loss=0.154, v_num=2]\nEpoch 1:  49%|████▉     | 1604/3288 [07:35<07:27,  3.76batch/s, batch_idx=1499, gpu=0, loss=0.154, v_num=2]\nEpoch 1:  49%|████▉     | 1605/3288 [07:36<09:34,  2.93batch/s, batch_idx=1499, gpu=0, loss=0.154, v_num=2]\nEpoch 1:  49%|████▉     | 1607/3288 [07:36<08:59,  3.12batch/s, batch_idx=1499, gpu=0, loss=0.154, v_num=2]\nValidating:  25%|██▌       | 12/48 [00:03<00:10,  3.56batch/s]\u001b[A\nEpoch 1:  49%|████▉     | 1609/3288 [07:37<08:40,  3.22batch/s, batch_idx=1499, gpu=0, loss=0.154, v_num=2]\nEpoch 1:  49%|████▉     | 1611/3288 [07:38<08:22,  3.34batch/s, batch_idx=1499, gpu=0, loss=0.154, v_num=2]\nValidating:  33%|███▎      | 16/48 [00:04<00:08,  3.96batch/s]\u001b[A\nEpoch 1:  49%|████▉     | 1613/3288 [07:38<08:17,  3.37batch/s, batch_idx=1499, gpu=0, loss=0.154, v_num=2]\nEpoch 1:  49%|████▉     | 1615/3288 [07:39<08:14,  3.38batch/s, batch_idx=1499, gpu=0, loss=0.154, v_num=2]\nEpoch 1:  49%|████▉     | 1617/3288 [07:39<08:17,  3.36batch/s, batch_idx=1499, gpu=0, loss=0.154, v_num=2]\nEpoch 1:  49%|████▉     | 1619/3288 [07:40<08:02,  3.46batch/s, batch_idx=1499, gpu=0, loss=0.154, v_num=2]\nEpoch 1:  49%|████▉     | 1621/3288 [07:40<07:57,  3.49batch/s, batch_idx=1499, gpu=0, loss=0.154, v_num=2]\nEpoch 1:  49%|████▉     | 1623/3288 [07:41<08:04,  3.44batch/s, batch_idx=1499, gpu=0, loss=0.154, v_num=2]\nEpoch 1:  49%|████▉     | 1625/3288 [07:42<08:06,  3.42batch/s, batch_idx=1499, gpu=0, loss=0.154, v_num=2]\nEpoch 1:  49%|████▉     | 1626/3288 [07:42<06:33,  4.22batch/s, batch_idx=1499, gpu=0, loss=0.154, v_num=2]\nEpoch 1:  49%|████▉     | 1627/3288 [07:42<08:50,  3.13batch/s, batch_idx=1499, gpu=0, loss=0.154, v_num=2]\nEpoch 1:  50%|████▉     | 1629/3288 [07:43<08:26,  3.28batch/s, batch_idx=1499, gpu=0, loss=0.154, v_num=2]\nEpoch 1:  50%|████▉     | 1631/3288 [07:43<08:22,  3.30batch/s, batch_idx=1499, gpu=0, loss=0.154, v_num=2]\nEpoch 1:  50%|████▉     | 1632/3288 [07:44<07:04,  3.90batch/s, batch_idx=1499, gpu=0, loss=0.154, v_num=2]\nEpoch 1:  50%|████▉     | 1633/3288 [07:44<09:19,  2.96batch/s, batch_idx=1499, gpu=0, loss=0.154, v_num=2]\nEpoch 1:  50%|████▉     | 1635/3288 [07:45<08:48,  3.13batch/s, batch_idx=1499, gpu=0, loss=0.154, v_num=2]\nEpoch 1:  50%|████▉     | 1637/3288 [07:45<08:32,  3.22batch/s, batch_idx=1499, gpu=0, loss=0.154, v_num=2]\nEpoch 1:  50%|████▉     | 1639/3288 [07:46<08:26,  3.26batch/s, batch_idx=1499, gpu=0, loss=0.154, v_num=2]\nEpoch 1:  50%|████▉     | 1641/3288 [07:46<08:14,  3.33batch/s, batch_idx=1499, gpu=0, loss=0.154, v_num=2]\nValidating:  96%|█████████▌| 46/48 [00:13<00:00,  4.13batch/s]\u001b[A\nEpoch 1:  50%|█████     | 1644/3288 [07:47<07:56,  3.45batch/s, batch_idx=1499, gpu=0, loss=0.154, v_num=2]\nEpoch 1:  65%|██████▌   | 2144/3288 [10:08<05:22,  3.54batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nValidating:   0%|          | 0/48 [00:00<?, ?batch/s]\u001b[A\nEpoch 1:  65%|██████▌   | 2145/3288 [10:09<08:46,  2.17batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  65%|██████▌   | 2147/3288 [10:09<07:30,  2.53batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  65%|██████▌   | 2149/3288 [10:10<06:45,  2.81batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  65%|██████▌   | 2150/3288 [10:10<05:29,  3.45batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  65%|██████▌   | 2151/3288 [10:10<06:26,  2.94batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  65%|██████▌   | 2152/3288 [10:11<05:05,  3.72batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  65%|██████▌   | 2153/3288 [10:11<06:08,  3.08batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  66%|██████▌   | 2154/3288 [10:11<04:56,  3.83batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  66%|██████▌   | 2155/3288 [10:12<06:20,  2.98batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  66%|██████▌   | 2156/3288 [10:12<05:09,  3.66batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  66%|██████▌   | 2157/3288 [10:12<06:14,  3.02batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  66%|██████▌   | 2158/3288 [10:12<05:07,  3.68batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  66%|██████▌   | 2159/3288 [10:13<06:02,  3.12batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  66%|██████▌   | 2160/3288 [10:13<04:53,  3.84batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  66%|██████▌   | 2161/3288 [10:13<05:45,  3.26batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  66%|██████▌   | 2162/3288 [10:13<04:52,  3.85batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  66%|██████▌   | 2163/3288 [10:14<05:37,  3.34batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  66%|██████▌   | 2164/3288 [10:14<04:58,  3.76batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  66%|██████▌   | 2165/3288 [10:14<05:53,  3.17batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  66%|██████▌   | 2166/3288 [10:15<04:57,  3.77batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  66%|██████▌   | 2167/3288 [10:15<05:56,  3.14batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  66%|██████▌   | 2168/3288 [10:15<04:43,  3.95batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  66%|██████▌   | 2169/3288 [10:16<06:17,  2.96batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nValidating:  54%|█████▍    | 26/48 [00:07<00:05,  3.77batch/s]\u001b[A\nEpoch 1:  66%|██████▌   | 2171/3288 [10:16<06:00,  3.10batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  66%|██████▌   | 2173/3288 [10:17<05:39,  3.29batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  66%|██████▌   | 2175/3288 [10:17<05:31,  3.36batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  66%|██████▌   | 2176/3288 [10:17<04:29,  4.12batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  66%|██████▌   | 2177/3288 [10:18<05:52,  3.15batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  66%|██████▋   | 2179/3288 [10:18<05:40,  3.26batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nValidating:  75%|███████▌  | 36/48 [00:10<00:02,  4.08batch/s]\u001b[A\nEpoch 1:  66%|██████▋   | 2181/3288 [10:19<05:31,  3.34batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  66%|██████▋   | 2183/3288 [10:20<05:25,  3.40batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  66%|██████▋   | 2185/3288 [10:20<05:16,  3.48batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  67%|██████▋   | 2187/3288 [10:21<05:17,  3.46batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  67%|██████▋   | 2189/3288 [10:21<05:10,  3.54batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  67%|██████▋   | 2192/3288 [10:22<04:57,  3.68batch/s, batch_idx=1999, gpu=0, loss=0.263, v_num=2]\nEpoch 1:  82%|████████▏ | 2692/3288 [12:42<02:49,  3.52batch/s, batch_idx=2499, gpu=0, loss=0.041, v_num=2]\nValidating:   0%|          | 0/48 [00:00<?, ?batch/s]\u001b[A\nEpoch 1:  82%|████████▏ | 2693/3288 [12:43<04:33,  2.18batch/s, batch_idx=2499, gpu=0, loss=0.041, v_num=2]\nEpoch 1:  82%|████████▏ | 2695/3288 [12:44<03:59,  2.47batch/s, batch_idx=2499, gpu=0, loss=0.041, v_num=2]\nEpoch 1:  82%|████████▏ | 2696/3288 [12:44<03:08,  3.14batch/s, batch_idx=2499, gpu=0, loss=0.041, v_num=2]\nEpoch 1:  82%|████████▏ | 2697/3288 [12:44<03:27,  2.84batch/s, batch_idx=2499, gpu=0, loss=0.041, v_num=2]\nEpoch 1:  82%|████████▏ | 2698/3288 [12:45<02:47,  3.52batch/s, batch_idx=2499, gpu=0, loss=0.041, v_num=2]\nEpoch 1:  82%|████████▏ | 2699/3288 [12:45<03:22,  2.91batch/s, batch_idx=2499, gpu=0, loss=0.041, v_num=2]\nEpoch 1:  82%|████████▏ | 2700/3288 [12:45<02:53,  3.39batch/s, batch_idx=2499, gpu=0, loss=0.041, v_num=2]\nEpoch 1:  82%|████████▏ | 2701/3288 [12:46<03:27,  2.83batch/s, batch_idx=2499, gpu=0, loss=0.041, v_num=2]\nEpoch 1:  82%|████████▏ | 2702/3288 [12:46<02:43,  3.59batch/s, batch_idx=2499, gpu=0, loss=0.041, v_num=2]\nEpoch 1:  82%|████████▏ | 2703/3288 [12:46<03:18,  2.95batch/s, batch_idx=2499, gpu=0, loss=0.041, v_num=2]\nEpoch 1:  82%|████████▏ | 2705/3288 [12:47<03:09,  3.08batch/s, batch_idx=2499, gpu=0, loss=0.041, v_num=2]\nEpoch 1:  82%|████████▏ | 2707/3288 [12:47<03:02,  3.19batch/s, batch_idx=2499, gpu=0, loss=0.041, v_num=2]\nEpoch 1:  82%|████████▏ | 2708/3288 [12:48<02:26,  3.96batch/s, batch_idx=2499, gpu=0, loss=0.041, v_num=2]\nEpoch 1:  82%|████████▏ | 2709/3288 [12:48<02:58,  3.25batch/s, batch_idx=2499, gpu=0, loss=0.041, v_num=2]\nEpoch 1:  82%|████████▏ | 2711/3288 [12:49<02:49,  3.40batch/s, batch_idx=2499, gpu=0, loss=0.041, v_num=2]\nEpoch 1:  83%|████████▎ | 2713/3288 [12:49<02:50,  3.38batch/s, batch_idx=2499, gpu=0, loss=0.041, v_num=2]\nEpoch 1:  83%|████████▎ | 2715/3288 [12:50<02:50,  3.36batch/s, batch_idx=2499, gpu=0, loss=0.041, v_num=2]\nEpoch 1:  83%|████████▎ | 2717/3288 [12:50<02:44,  3.48batch/s, batch_idx=2499, gpu=0, loss=0.041, v_num=2]\nEpoch 1:  83%|████████▎ | 2719/3288 [12:51<02:42,  3.49batch/s, batch_idx=2499, gpu=0, loss=0.041, v_num=2]\nEpoch 1:  83%|████████▎ | 2721/3288 [12:51<02:45,  3.42batch/s, batch_idx=2499, gpu=0, loss=0.041, v_num=2]\nEpoch 1:  83%|████████▎ | 2723/3288 [12:52<02:40,  3.51batch/s, batch_idx=2499, gpu=0, loss=0.041, v_num=2]\nEpoch 1:  83%|████████▎ | 2725/3288 [12:53<02:44,  3.42batch/s, batch_idx=2499, gpu=0, loss=0.041, v_num=2]\nEpoch 1:  83%|████████▎ | 2727/3288 [12:53<02:47,  3.35batch/s, batch_idx=2499, gpu=0, loss=0.041, v_num=2]\nValidating:  75%|███████▌  | 36/48 [00:10<00:02,  4.21batch/s]\u001b[A\nEpoch 1:  83%|████████▎ | 2729/3288 [12:54<02:45,  3.37batch/s, batch_idx=2499, gpu=0, loss=0.041, v_num=2]\nValidating:  79%|███████▉  | 38/48 [00:11<00:02,  3.99batch/s]\u001b[A\nEpoch 1:  83%|████████▎ | 2731/3288 [12:54<02:50,  3.27batch/s, batch_idx=2499, gpu=0, loss=0.041, v_num=2]\nEpoch 1:  83%|████████▎ | 2733/3288 [12:55<02:44,  3.37batch/s, batch_idx=2499, gpu=0, loss=0.041, v_num=2]\nEpoch 1:  83%|████████▎ | 2735/3288 [12:56<02:45,  3.34batch/s, batch_idx=2499, gpu=0, loss=0.041, v_num=2]\nEpoch 1:  83%|████████▎ | 2737/3288 [12:56<02:42,  3.39batch/s, batch_idx=2499, gpu=0, loss=0.041, v_num=2]\nEpoch 1:  83%|████████▎ | 2740/3288 [12:57<02:43,  3.35batch/s, batch_idx=2499, gpu=0, loss=0.041, v_num=2]\nEpoch 1:  99%|█████████▊| 3240/3288 [15:18<00:13,  3.63batch/s, batch_idx=2999, gpu=0, loss=0.049, v_num=2]\nValidating:   0%|          | 0/48 [00:00<?, ?batch/s]\u001b[A\nEpoch 1:  99%|█████████▊| 3241/3288 [15:19<00:20,  2.27batch/s, batch_idx=2999, gpu=0, loss=0.049, v_num=2]\nEpoch 1:  99%|█████████▊| 3243/3288 [15:19<00:17,  2.54batch/s, batch_idx=2999, gpu=0, loss=0.049, v_num=2]\nEpoch 1:  99%|█████████▊| 3245/3288 [15:20<00:15,  2.77batch/s, batch_idx=2999, gpu=0, loss=0.049, v_num=2]\nEpoch 1:  99%|█████████▉| 3247/3288 [15:20<00:14,  2.88batch/s, batch_idx=2999, gpu=0, loss=0.049, v_num=2]\nValidating:  17%|█▋        | 8/48 [00:02<00:14,  2.77batch/s]\u001b[A\nEpoch 1:  99%|█████████▉| 3249/3288 [15:21<00:13,  2.95batch/s, batch_idx=2999, gpu=0, loss=0.049, v_num=2]\nEpoch 1:  99%|█████████▉| 3251/3288 [15:22<00:12,  3.07batch/s, batch_idx=2999, gpu=0, loss=0.049, v_num=2]\nEpoch 1:  99%|█████████▉| 3252/3288 [15:22<00:09,  3.80batch/s, batch_idx=2999, gpu=0, loss=0.049, v_num=2]\nEpoch 1:  99%|█████████▉| 3253/3288 [15:22<00:11,  2.93batch/s, batch_idx=2999, gpu=0, loss=0.049, v_num=2]\nEpoch 1:  99%|█████████▉| 3255/3288 [15:23<00:10,  3.10batch/s, batch_idx=2999, gpu=0, loss=0.049, v_num=2]\nEpoch 1:  99%|█████████▉| 3257/3288 [15:23<00:09,  3.13batch/s, batch_idx=2999, gpu=0, loss=0.049, v_num=2]\nEpoch 1:  99%|█████████▉| 3259/3288 [15:24<00:09,  3.20batch/s, batch_idx=2999, gpu=0, loss=0.049, v_num=2]\nEpoch 1:  99%|█████████▉| 3260/3288 [15:24<00:07,  3.97batch/s, batch_idx=2999, gpu=0, loss=0.049, v_num=2]\nEpoch 1:  99%|█████████▉| 3261/3288 [15:25<00:08,  3.08batch/s, batch_idx=2999, gpu=0, loss=0.049, v_num=2]\nEpoch 1:  99%|█████████▉| 3263/3288 [15:25<00:07,  3.27batch/s, batch_idx=2999, gpu=0, loss=0.049, v_num=2]\nEpoch 1:  99%|█████████▉| 3265/3288 [15:26<00:07,  3.25batch/s, batch_idx=2999, gpu=0, loss=0.049, v_num=2]\nEpoch 1:  99%|█████████▉| 3267/3288 [15:26<00:06,  3.35batch/s, batch_idx=2999, gpu=0, loss=0.049, v_num=2]\nValidating:  58%|█████▊    | 28/48 [00:08<00:04,  4.16batch/s]\u001b[A\nEpoch 1:  99%|█████████▉| 3269/3288 [15:27<00:05,  3.31batch/s, batch_idx=2999, gpu=0, loss=0.049, v_num=2]\nEpoch 1:  99%|█████████▉| 3271/3288 [15:28<00:05,  3.06batch/s, batch_idx=2999, gpu=0, loss=0.049, v_num=2]\nEpoch 1: 100%|█████████▉| 3273/3288 [15:28<00:04,  3.11batch/s, batch_idx=2999, gpu=0, loss=0.049, v_num=2]\nEpoch 1: 100%|█████████▉| 3275/3288 [15:29<00:04,  2.97batch/s, batch_idx=2999, gpu=0, loss=0.049, v_num=2]\nEpoch 1: 100%|█████████▉| 3276/3288 [15:29<00:03,  3.69batch/s, batch_idx=2999, gpu=0, loss=0.049, v_num=2]\nEpoch 1: 100%|█████████▉| 3277/3288 [15:30<00:03,  3.02batch/s, batch_idx=2999, gpu=0, loss=0.049, v_num=2]\nEpoch 1: 100%|█████████▉| 3279/3288 [15:30<00:02,  3.12batch/s, batch_idx=2999, gpu=0, loss=0.049, v_num=2]\nEpoch 1: 100%|█████████▉| 3281/3288 [15:31<00:02,  3.19batch/s, batch_idx=2999, gpu=0, loss=0.049, v_num=2]\nEpoch 1: 100%|█████████▉| 3282/3288 [15:31<00:01,  3.94batch/s, batch_idx=2999, gpu=0, loss=0.049, v_num=2]\nEpoch 1: 100%|█████████▉| 3283/3288 [15:31<00:01,  2.82batch/s, batch_idx=2999, gpu=0, loss=0.049, v_num=2]\nEpoch 1: 100%|█████████▉| 3285/3288 [15:32<00:01,  2.99batch/s, batch_idx=2999, gpu=0, loss=0.049, v_num=2]\nEpoch 1: 100%|██████████| 3288/3288 [15:33<00:00,  3.16batch/s, batch_idx=2999, gpu=0, loss=0.049, v_num=2]\nEpoch 1: 100%|██████████| 3288/3288 [15:33<00:00,  3.52batch/s, batch_idx=2999, gpu=0, loss=0.049, v_num=2]\n"
    },
    {
     "data": {
      "text/plain": "'/project/catinous/trained_models/lrbase_iterations.pt'"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_full_dataset('hr')\n",
    "trained_full_dataset('lr')\n",
    "trained_full_dataset('combined')\n",
    "trained_full_dataset('hr', base_only=True)\n",
    "trained_full_dataset('lr', base_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['MLFlowLogger', 'TensorBoardLogger']"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pllogging.__all__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<module 'pytorch_lightning.logging' from '/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/logging/__init__.py'>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pllogging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[4 2 1 3 5 6]\n"
    }
   ],
   "source": [
    "np.random.seed(9375)\n",
    "perm = np.random.permutation([1,2,3,4,5,6])\n",
    "print(perm)"
   ]
  }
 ]
}