{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from catinous.CatsinomModel import CatsinomModel\n",
    "from catinous.CatsinomDataset import CatsinomDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import visualizationutils as vu\n",
    "import argparse\n",
    "import pytorch_lightning.logging as pllogging\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsname = 'lr'\n",
    "\n",
    "def trained_full_dataset(dsname = 'lr', base_only=False, continue_from=None):\n",
    "    \n",
    "    hparams = dict()\n",
    "    hparams['root_dir'] = '/project/catinous/cat_data/'\n",
    "    hparams['datasetfile'] = 'catsinom_' + dsname + '_dataset.csv'\n",
    "    hparams['batch_size'] = 8\n",
    "    hparams['train_iterations'] = 3000\n",
    "\n",
    "    if base_only:\n",
    "        hparams['trainsplit'] = ['base_train']\n",
    "        dsname = dsname + 'base'\n",
    "    else:\n",
    "        hparams['trainsplit'] = ['train','base_train']\n",
    "    \n",
    "    model = CatsinomModel(argparse.Namespace(**hparams))\n",
    "\n",
    "    if continue_from is not None:\n",
    "        model.load_state_dict(torch.load('/project/catinous/trained_models/' + continue_from + '_iterations.pt'))\n",
    "        outname = '/project/catinous/trained_models/' + continue_from + dsname + '_iterations.pt'\n",
    "        dsname = dsname + continue_from\n",
    "    else:\n",
    "        outname = '/project/catinous/trained_models/' + dsname + '_iterations.pt'\n",
    "        \n",
    "    if not os.path.exists(outname):\n",
    "        logger = pllogging.TestTubeLogger('catinous_log_iterations', name=dsname)\n",
    "        trainer = Trainer(gpus=1, max_epochs=1, early_stop_callback=False, logger=logger, val_check_interval=500)\n",
    "        trainer.fit(model)\n",
    "        torch.save(model.state_dict(), outname)\n",
    "\n",
    "    return outname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:gpu available: True, used: True\n",
      "INFO:root:VISIBLE GPUS: 0\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/mperkonigg/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "INFO:root:\n",
      "              Name               Type Params\n",
      "0            model             ResNet   24 M\n",
      "1      model.conv1             Conv2d    9 K\n",
      "2        model.bn1        BatchNorm2d  128  \n",
      "3       model.relu               ReLU    0  \n",
      "4    model.maxpool          MaxPool2d    0  \n",
      "..             ...                ...    ...\n",
      "150       model.fc         Sequential    1 M\n",
      "151     model.fc.0             Linear    1 M\n",
      "152     model.fc.1        BatchNorm1d    1 K\n",
      "153     model.fc.2             Linear  513  \n",
      "154           loss  BCEWithLogitsLoss    0  \n",
      "\n",
      "[155 rows x 3 columns]\n",
      "Validation sanity check:   0%|          | 0/5 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/catinous/cat_data/ catsinom_hr_dataset.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/3318 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  15%|█▌        | 500/3318 [02:08<11:51,  3.96batch/s, batch_idx=499, gpu=0, loss=0.551, v_num=0]\n",
      "Validating:   0%|          | 0/53 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 501/3318 [02:09<24:34,  1.91batch/s, batch_idx=499, gpu=0, loss=0.551, v_num=0]\n",
      "Epoch 1:  15%|█▌        | 503/3318 [02:10<23:01,  2.04batch/s, batch_idx=499, gpu=0, loss=0.551, v_num=0]\n",
      "Epoch 1:  15%|█▌        | 505/3318 [02:11<23:02,  2.04batch/s, batch_idx=499, gpu=0, loss=0.551, v_num=0]\n",
      "Epoch 1:  15%|█▌        | 507/3318 [02:12<21:59,  2.13batch/s, batch_idx=499, gpu=0, loss=0.551, v_num=0]\n",
      "Epoch 1:  15%|█▌        | 509/3318 [02:12<20:59,  2.23batch/s, batch_idx=499, gpu=0, loss=0.551, v_num=0]\n",
      "Epoch 1:  15%|█▌        | 511/3318 [02:13<20:47,  2.25batch/s, batch_idx=499, gpu=0, loss=0.551, v_num=0]\n",
      "Epoch 1:  15%|█▌        | 513/3318 [02:14<19:49,  2.36batch/s, batch_idx=499, gpu=0, loss=0.551, v_num=0]\n",
      "Epoch 1:  16%|█▌        | 515/3318 [02:15<19:27,  2.40batch/s, batch_idx=499, gpu=0, loss=0.551, v_num=0]\n",
      "Epoch 1:  16%|█▌        | 517/3318 [02:15<18:16,  2.55batch/s, batch_idx=499, gpu=0, loss=0.551, v_num=0]\n",
      "Epoch 1:  16%|█▌        | 519/3318 [02:16<18:18,  2.55batch/s, batch_idx=499, gpu=0, loss=0.551, v_num=0]\n",
      "Epoch 1:  16%|█▌        | 521/3318 [02:17<17:47,  2.62batch/s, batch_idx=499, gpu=0, loss=0.551, v_num=0]\n",
      "Epoch 1:  16%|█▌        | 523/3318 [02:18<17:29,  2.66batch/s, batch_idx=499, gpu=0, loss=0.551, v_num=0]\n",
      "Epoch 1:  16%|█▌        | 525/3318 [02:18<16:56,  2.75batch/s, batch_idx=499, gpu=0, loss=0.551, v_num=0]\n",
      "Epoch 1:  16%|█▌        | 527/3318 [02:19<16:36,  2.80batch/s, batch_idx=499, gpu=0, loss=0.551, v_num=0]\n",
      "Epoch 1:  16%|█▌        | 529/3318 [02:20<18:09,  2.56batch/s, batch_idx=499, gpu=0, loss=0.551, v_num=0]\n",
      "Epoch 1:  16%|█▌        | 531/3318 [02:21<18:54,  2.46batch/s, batch_idx=499, gpu=0, loss=0.551, v_num=0]\n",
      "Epoch 1:  16%|█▌        | 533/3318 [02:22<18:58,  2.45batch/s, batch_idx=499, gpu=0, loss=0.551, v_num=0]\n",
      "Epoch 1:  16%|█▌        | 535/3318 [02:22<19:06,  2.43batch/s, batch_idx=499, gpu=0, loss=0.551, v_num=0]\n",
      "Epoch 1:  16%|█▌        | 537/3318 [02:23<18:15,  2.54batch/s, batch_idx=499, gpu=0, loss=0.551, v_num=0]\n",
      "Epoch 1:  16%|█▌        | 539/3318 [02:24<17:54,  2.59batch/s, batch_idx=499, gpu=0, loss=0.551, v_num=0]\n",
      "Epoch 1:  16%|█▋        | 541/3318 [02:25<19:20,  2.39batch/s, batch_idx=499, gpu=0, loss=0.551, v_num=0]\n",
      "Epoch 1:  16%|█▋        | 543/3318 [02:26<18:31,  2.50batch/s, batch_idx=499, gpu=0, loss=0.551, v_num=0]\n",
      "Epoch 1:  16%|█▋        | 545/3318 [02:26<18:40,  2.48batch/s, batch_idx=499, gpu=0, loss=0.551, v_num=0]\n",
      "Epoch 1:  16%|█▋        | 547/3318 [02:27<19:22,  2.38batch/s, batch_idx=499, gpu=0, loss=0.551, v_num=0]\n",
      "Epoch 1:  17%|█▋        | 549/3318 [02:28<19:55,  2.32batch/s, batch_idx=499, gpu=0, loss=0.551, v_num=0]\n",
      "Epoch 1:  17%|█▋        | 551/3318 [02:29<20:53,  2.21batch/s, batch_idx=499, gpu=0, loss=0.551, v_num=0]\n",
      "Epoch 1:  17%|█▋        | 553/3318 [02:30<19:20,  2.38batch/s, batch_idx=499, gpu=0, loss=0.551, v_num=0]\n",
      "Epoch 1:  32%|███▏      | 1053/3318 [04:36<09:13,  4.09batch/s, batch_idx=999, gpu=0, loss=0.192, v_num=0]\n",
      "Validating:   0%|          | 0/53 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1054/3318 [04:37<16:13,  2.33batch/s, batch_idx=999, gpu=0, loss=0.192, v_num=0]\n",
      "Epoch 1:  32%|███▏      | 1056/3318 [04:37<14:19,  2.63batch/s, batch_idx=999, gpu=0, loss=0.192, v_num=0]\n",
      "Epoch 1:  32%|███▏      | 1058/3318 [04:38<13:25,  2.81batch/s, batch_idx=999, gpu=0, loss=0.192, v_num=0]\n",
      "Epoch 1:  32%|███▏      | 1060/3318 [04:38<12:27,  3.02batch/s, batch_idx=999, gpu=0, loss=0.192, v_num=0]\n",
      "Epoch 1:  32%|███▏      | 1062/3318 [04:39<11:59,  3.13batch/s, batch_idx=999, gpu=0, loss=0.192, v_num=0]\n",
      "Epoch 1:  32%|███▏      | 1064/3318 [04:39<11:43,  3.20batch/s, batch_idx=999, gpu=0, loss=0.192, v_num=0]\n",
      "Epoch 1:  32%|███▏      | 1066/3318 [04:40<11:22,  3.30batch/s, batch_idx=999, gpu=0, loss=0.192, v_num=0]\n",
      "Epoch 1:  32%|███▏      | 1068/3318 [04:41<11:14,  3.34batch/s, batch_idx=999, gpu=0, loss=0.192, v_num=0]\n",
      "Epoch 1:  32%|███▏      | 1070/3318 [04:41<11:08,  3.36batch/s, batch_idx=999, gpu=0, loss=0.192, v_num=0]\n",
      "Epoch 1:  32%|███▏      | 1072/3318 [04:42<10:57,  3.42batch/s, batch_idx=999, gpu=0, loss=0.192, v_num=0]\n",
      "Epoch 1:  32%|███▏      | 1074/3318 [04:42<10:36,  3.52batch/s, batch_idx=999, gpu=0, loss=0.192, v_num=0]\n",
      "Epoch 1:  32%|███▏      | 1076/3318 [04:43<10:53,  3.43batch/s, batch_idx=999, gpu=0, loss=0.192, v_num=0]\n",
      "Epoch 1:  32%|███▏      | 1078/3318 [04:44<11:15,  3.32batch/s, batch_idx=999, gpu=0, loss=0.192, v_num=0]\n",
      "Epoch 1:  33%|███▎      | 1080/3318 [04:44<12:40,  2.94batch/s, batch_idx=999, gpu=0, loss=0.192, v_num=0]\n",
      "Epoch 1:  33%|███▎      | 1082/3318 [04:45<13:38,  2.73batch/s, batch_idx=999, gpu=0, loss=0.192, v_num=0]\n",
      "Epoch 1:  33%|███▎      | 1084/3318 [04:46<12:56,  2.88batch/s, batch_idx=999, gpu=0, loss=0.192, v_num=0]\n",
      "Epoch 1:  33%|███▎      | 1086/3318 [04:47<12:25,  2.99batch/s, batch_idx=999, gpu=0, loss=0.192, v_num=0]\n",
      "Epoch 1:  33%|███▎      | 1088/3318 [04:47<11:55,  3.12batch/s, batch_idx=999, gpu=0, loss=0.192, v_num=0]\n",
      "Epoch 1:  33%|███▎      | 1090/3318 [04:48<11:16,  3.29batch/s, batch_idx=999, gpu=0, loss=0.192, v_num=0]\n",
      "Epoch 1:  33%|███▎      | 1092/3318 [04:48<11:23,  3.26batch/s, batch_idx=999, gpu=0, loss=0.192, v_num=0]\n",
      "Epoch 1:  33%|███▎      | 1094/3318 [04:49<10:53,  3.41batch/s, batch_idx=999, gpu=0, loss=0.192, v_num=0]\n",
      "Epoch 1:  33%|███▎      | 1096/3318 [04:49<10:41,  3.46batch/s, batch_idx=999, gpu=0, loss=0.192, v_num=0]\n",
      "Epoch 1:  33%|███▎      | 1098/3318 [04:50<10:34,  3.50batch/s, batch_idx=999, gpu=0, loss=0.192, v_num=0]\n",
      "Epoch 1:  33%|███▎      | 1100/3318 [04:50<10:28,  3.53batch/s, batch_idx=999, gpu=0, loss=0.192, v_num=0]\n",
      "Epoch 1:  33%|███▎      | 1102/3318 [04:51<10:43,  3.44batch/s, batch_idx=999, gpu=0, loss=0.192, v_num=0]\n",
      "Epoch 1:  33%|███▎      | 1104/3318 [04:52<10:45,  3.43batch/s, batch_idx=999, gpu=0, loss=0.192, v_num=0]\n",
      "Epoch 1:  33%|███▎      | 1106/3318 [04:52<10:27,  3.53batch/s, batch_idx=999, gpu=0, loss=0.192, v_num=0]\n",
      "Epoch 1:  48%|████▊     | 1606/3318 [06:56<07:01,  4.06batch/s, batch_idx=1499, gpu=0, loss=0.155, v_num=0]\n",
      "Validating:   0%|          | 0/53 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 1607/3318 [06:57<11:40,  2.44batch/s, batch_idx=1499, gpu=0, loss=0.155, v_num=0]\n",
      "Epoch 1:  48%|████▊     | 1609/3318 [06:58<10:50,  2.63batch/s, batch_idx=1499, gpu=0, loss=0.155, v_num=0]\n",
      "Epoch 1:  49%|████▊     | 1611/3318 [06:58<10:03,  2.83batch/s, batch_idx=1499, gpu=0, loss=0.155, v_num=0]\n",
      "Epoch 1:  49%|████▊     | 1613/3318 [06:59<09:25,  3.02batch/s, batch_idx=1499, gpu=0, loss=0.155, v_num=0]\n",
      "Epoch 1:  49%|████▊     | 1615/3318 [06:59<08:59,  3.16batch/s, batch_idx=1499, gpu=0, loss=0.155, v_num=0]\n",
      "Epoch 1:  49%|████▊     | 1617/3318 [07:00<08:47,  3.23batch/s, batch_idx=1499, gpu=0, loss=0.155, v_num=0]\n",
      "Epoch 1:  49%|████▉     | 1619/3318 [07:00<08:18,  3.41batch/s, batch_idx=1499, gpu=0, loss=0.155, v_num=0]\n",
      "Epoch 1:  49%|████▉     | 1621/3318 [07:01<08:25,  3.36batch/s, batch_idx=1499, gpu=0, loss=0.155, v_num=0]\n",
      "Epoch 1:  49%|████▉     | 1623/3318 [07:01<08:10,  3.46batch/s, batch_idx=1499, gpu=0, loss=0.155, v_num=0]\n",
      "Epoch 1:  49%|████▉     | 1625/3318 [07:02<08:14,  3.42batch/s, batch_idx=1499, gpu=0, loss=0.155, v_num=0]\n",
      "Epoch 1:  49%|████▉     | 1627/3318 [07:03<08:08,  3.46batch/s, batch_idx=1499, gpu=0, loss=0.155, v_num=0]\n",
      "Epoch 1:  49%|████▉     | 1629/3318 [07:03<08:27,  3.33batch/s, batch_idx=1499, gpu=0, loss=0.155, v_num=0]\n",
      "Epoch 1:  49%|████▉     | 1631/3318 [07:04<08:14,  3.41batch/s, batch_idx=1499, gpu=0, loss=0.155, v_num=0]\n",
      "Epoch 1:  49%|████▉     | 1633/3318 [07:04<08:07,  3.45batch/s, batch_idx=1499, gpu=0, loss=0.155, v_num=0]\n",
      "Epoch 1:  49%|████▉     | 1635/3318 [07:05<08:07,  3.45batch/s, batch_idx=1499, gpu=0, loss=0.155, v_num=0]\n",
      "Epoch 1:  49%|████▉     | 1637/3318 [07:06<08:00,  3.50batch/s, batch_idx=1499, gpu=0, loss=0.155, v_num=0]\n",
      "Epoch 1:  49%|████▉     | 1639/3318 [07:06<07:51,  3.56batch/s, batch_idx=1499, gpu=0, loss=0.155, v_num=0]\n",
      "Epoch 1:  49%|████▉     | 1641/3318 [07:07<08:00,  3.49batch/s, batch_idx=1499, gpu=0, loss=0.155, v_num=0]\n",
      "Epoch 1:  50%|████▉     | 1643/3318 [07:07<07:53,  3.53batch/s, batch_idx=1499, gpu=0, loss=0.155, v_num=0]\n",
      "Epoch 1:  50%|████▉     | 1645/3318 [07:08<07:54,  3.53batch/s, batch_idx=1499, gpu=0, loss=0.155, v_num=0]\n",
      "Epoch 1:  50%|████▉     | 1647/3318 [07:08<07:59,  3.49batch/s, batch_idx=1499, gpu=0, loss=0.155, v_num=0]\n",
      "Epoch 1:  50%|████▉     | 1649/3318 [07:09<07:58,  3.49batch/s, batch_idx=1499, gpu=0, loss=0.155, v_num=0]\n",
      "Epoch 1:  50%|████▉     | 1651/3318 [07:10<08:14,  3.37batch/s, batch_idx=1499, gpu=0, loss=0.155, v_num=0]\n",
      "Epoch 1:  50%|████▉     | 1653/3318 [07:10<08:06,  3.42batch/s, batch_idx=1499, gpu=0, loss=0.155, v_num=0]\n",
      "Epoch 1:  50%|████▉     | 1655/3318 [07:11<07:53,  3.51batch/s, batch_idx=1499, gpu=0, loss=0.155, v_num=0]\n",
      "Epoch 1:  50%|████▉     | 1657/3318 [07:11<07:43,  3.58batch/s, batch_idx=1499, gpu=0, loss=0.155, v_num=0]\n",
      "Epoch 1:  50%|█████     | 1659/3318 [07:12<07:39,  3.61batch/s, batch_idx=1499, gpu=0, loss=0.155, v_num=0]\n",
      "Epoch 1:  65%|██████▌   | 2159/3318 [09:15<04:45,  4.06batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Validating:   0%|          | 0/53 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2160/3318 [09:16<07:59,  2.41batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  65%|██████▌   | 2162/3318 [09:17<07:06,  2.71batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  65%|██████▌   | 2164/3318 [09:17<06:37,  2.90batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  65%|██████▌   | 2166/3318 [09:18<06:12,  3.09batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  65%|██████▌   | 2168/3318 [09:18<05:53,  3.26batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  65%|██████▌   | 2170/3318 [09:19<05:37,  3.40batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  65%|██████▌   | 2172/3318 [09:20<05:40,  3.36batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  66%|██████▌   | 2174/3318 [09:20<05:38,  3.38batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  66%|██████▌   | 2176/3318 [09:21<05:33,  3.42batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  66%|██████▌   | 2178/3318 [09:21<05:29,  3.45batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  66%|██████▌   | 2180/3318 [09:22<05:21,  3.53batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  66%|██████▌   | 2182/3318 [09:22<05:18,  3.56batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  66%|██████▌   | 2183/3318 [09:23<04:26,  4.25batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  66%|██████▌   | 2184/3318 [09:23<05:28,  3.46batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  66%|██████▌   | 2185/3318 [09:23<04:47,  3.93batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  66%|██████▌   | 2186/3318 [09:24<05:49,  3.24batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  66%|██████▌   | 2188/3318 [09:24<05:36,  3.36batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  66%|██████▌   | 2189/3318 [09:24<04:32,  4.15batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  66%|██████▌   | 2190/3318 [09:25<05:53,  3.19batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  66%|██████▌   | 2191/3318 [09:25<04:46,  3.94batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  66%|██████▌   | 2192/3318 [09:25<05:59,  3.13batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  66%|██████▌   | 2193/3318 [09:25<05:13,  3.59batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  66%|██████▌   | 2194/3318 [09:26<06:05,  3.08batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  66%|██████▌   | 2195/3318 [09:26<05:17,  3.54batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  66%|██████▌   | 2196/3318 [09:26<05:58,  3.13batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  66%|██████▌   | 2197/3318 [09:27<05:12,  3.59batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  66%|██████▌   | 2198/3318 [09:27<05:40,  3.29batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  66%|██████▋   | 2199/3318 [09:27<05:02,  3.70batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  66%|██████▋   | 2200/3318 [09:28<05:37,  3.31batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  66%|██████▋   | 2201/3318 [09:28<05:12,  3.58batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  66%|██████▋   | 2202/3318 [09:28<05:38,  3.30batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  66%|██████▋   | 2203/3318 [09:28<05:33,  3.35batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  66%|██████▋   | 2204/3318 [09:29<05:24,  3.43batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  66%|██████▋   | 2205/3318 [09:29<05:41,  3.26batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  66%|██████▋   | 2206/3318 [09:29<05:13,  3.54batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  67%|██████▋   | 2207/3318 [09:30<05:23,  3.43batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  67%|██████▋   | 2208/3318 [09:30<05:32,  3.34batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  67%|██████▋   | 2209/3318 [09:30<05:38,  3.27batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  67%|██████▋   | 2210/3318 [09:30<05:20,  3.46batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  67%|██████▋   | 2211/3318 [09:31<05:39,  3.26batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  67%|██████▋   | 2212/3318 [09:31<05:14,  3.51batch/s, batch_idx=1999, gpu=0, loss=0.139, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 2712/3318 [11:38<02:41,  3.75batch/s, batch_idx=2499, gpu=0, loss=0.188, v_num=0]\n",
      "Validating:   0%|          | 0/53 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2713/3318 [11:39<04:16,  2.36batch/s, batch_idx=2499, gpu=0, loss=0.188, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 2715/3318 [11:40<03:48,  2.63batch/s, batch_idx=2499, gpu=0, loss=0.188, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 2717/3318 [11:40<03:26,  2.91batch/s, batch_idx=2499, gpu=0, loss=0.188, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 2719/3318 [11:41<03:13,  3.10batch/s, batch_idx=2499, gpu=0, loss=0.188, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 2720/3318 [11:41<02:34,  3.86batch/s, batch_idx=2499, gpu=0, loss=0.188, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 2721/3318 [11:41<03:07,  3.19batch/s, batch_idx=2499, gpu=0, loss=0.188, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 2722/3318 [11:41<02:32,  3.91batch/s, batch_idx=2499, gpu=0, loss=0.188, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 2723/3318 [11:42<03:17,  3.01batch/s, batch_idx=2499, gpu=0, loss=0.188, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 2725/3318 [11:43<03:13,  3.06batch/s, batch_idx=2499, gpu=0, loss=0.188, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 2727/3318 [11:43<03:08,  3.13batch/s, batch_idx=2499, gpu=0, loss=0.188, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 2729/3318 [11:44<03:03,  3.21batch/s, batch_idx=2499, gpu=0, loss=0.188, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 2731/3318 [11:44<02:57,  3.30batch/s, batch_idx=2499, gpu=0, loss=0.188, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 2733/3318 [11:45<02:55,  3.33batch/s, batch_idx=2499, gpu=0, loss=0.188, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 2735/3318 [11:45<02:53,  3.36batch/s, batch_idx=2499, gpu=0, loss=0.188, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 2737/3318 [11:46<02:55,  3.31batch/s, batch_idx=2499, gpu=0, loss=0.188, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2739/3318 [11:47<02:52,  3.36batch/s, batch_idx=2499, gpu=0, loss=0.188, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2741/3318 [11:47<02:52,  3.35batch/s, batch_idx=2499, gpu=0, loss=0.188, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2743/3318 [11:48<02:47,  3.42batch/s, batch_idx=2499, gpu=0, loss=0.188, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2745/3318 [11:48<02:46,  3.44batch/s, batch_idx=2499, gpu=0, loss=0.188, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2747/3318 [11:49<02:45,  3.45batch/s, batch_idx=2499, gpu=0, loss=0.188, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2749/3318 [11:50<02:50,  3.34batch/s, batch_idx=2499, gpu=0, loss=0.188, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2751/3318 [11:50<02:48,  3.36batch/s, batch_idx=2499, gpu=0, loss=0.188, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2753/3318 [11:51<02:48,  3.35batch/s, batch_idx=2499, gpu=0, loss=0.188, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2755/3318 [11:51<02:41,  3.49batch/s, batch_idx=2499, gpu=0, loss=0.188, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2757/3318 [11:52<02:46,  3.37batch/s, batch_idx=2499, gpu=0, loss=0.188, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2759/3318 [11:53<02:43,  3.42batch/s, batch_idx=2499, gpu=0, loss=0.188, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2761/3318 [11:53<02:44,  3.38batch/s, batch_idx=2499, gpu=0, loss=0.188, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2763/3318 [11:54<02:42,  3.41batch/s, batch_idx=2499, gpu=0, loss=0.188, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2765/3318 [11:54<02:37,  3.50batch/s, batch_idx=2499, gpu=0, loss=0.188, v_num=0]\n",
      "Epoch 1:  98%|█████████▊| 3265/3318 [13:58<00:12,  4.08batch/s, batch_idx=2999, gpu=0, loss=0.128, v_num=0]\n",
      "Validating:   0%|          | 0/53 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 3266/3318 [13:59<00:21,  2.44batch/s, batch_idx=2999, gpu=0, loss=0.128, v_num=0]\n",
      "Epoch 1:  98%|█████████▊| 3268/3318 [14:00<00:18,  2.64batch/s, batch_idx=2999, gpu=0, loss=0.128, v_num=0]\n",
      "Epoch 1:  99%|█████████▊| 3270/3318 [14:00<00:16,  2.94batch/s, batch_idx=2999, gpu=0, loss=0.128, v_num=0]\n",
      "Epoch 1:  99%|█████████▊| 3272/3318 [14:01<00:14,  3.11batch/s, batch_idx=2999, gpu=0, loss=0.128, v_num=0]\n",
      "Epoch 1:  99%|█████████▊| 3274/3318 [14:01<00:13,  3.23batch/s, batch_idx=2999, gpu=0, loss=0.128, v_num=0]\n",
      "Epoch 1:  99%|█████████▊| 3276/3318 [14:02<00:12,  3.38batch/s, batch_idx=2999, gpu=0, loss=0.128, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3278/3318 [14:02<00:11,  3.41batch/s, batch_idx=2999, gpu=0, loss=0.128, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3280/3318 [14:03<00:11,  3.37batch/s, batch_idx=2999, gpu=0, loss=0.128, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3282/3318 [14:04<00:10,  3.38batch/s, batch_idx=2999, gpu=0, loss=0.128, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3284/3318 [14:04<00:09,  3.49batch/s, batch_idx=2999, gpu=0, loss=0.128, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3286/3318 [14:05<00:09,  3.39batch/s, batch_idx=2999, gpu=0, loss=0.128, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3288/3318 [14:05<00:08,  3.39batch/s, batch_idx=2999, gpu=0, loss=0.128, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3290/3318 [14:06<00:08,  3.41batch/s, batch_idx=2999, gpu=0, loss=0.128, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3292/3318 [14:06<00:07,  3.52batch/s, batch_idx=2999, gpu=0, loss=0.128, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3294/3318 [14:07<00:06,  3.48batch/s, batch_idx=2999, gpu=0, loss=0.128, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3296/3318 [14:08<00:06,  3.45batch/s, batch_idx=2999, gpu=0, loss=0.128, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3298/3318 [14:08<00:05,  3.54batch/s, batch_idx=2999, gpu=0, loss=0.128, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3300/3318 [14:09<00:05,  3.48batch/s, batch_idx=2999, gpu=0, loss=0.128, v_num=0]\n",
      "Epoch 1: 100%|█████████▉| 3302/3318 [14:09<00:04,  3.45batch/s, batch_idx=2999, gpu=0, loss=0.128, v_num=0]\n",
      "Epoch 1: 100%|█████████▉| 3304/3318 [14:10<00:04,  3.35batch/s, batch_idx=2999, gpu=0, loss=0.128, v_num=0]\n",
      "Epoch 1: 100%|█████████▉| 3306/3318 [14:10<00:03,  3.44batch/s, batch_idx=2999, gpu=0, loss=0.128, v_num=0]\n",
      "Epoch 1: 100%|█████████▉| 3308/3318 [14:11<00:02,  3.42batch/s, batch_idx=2999, gpu=0, loss=0.128, v_num=0]\n",
      "Epoch 1: 100%|█████████▉| 3310/3318 [14:12<00:02,  3.42batch/s, batch_idx=2999, gpu=0, loss=0.128, v_num=0]\n",
      "Epoch 1: 100%|█████████▉| 3312/3318 [14:12<00:01,  3.45batch/s, batch_idx=2999, gpu=0, loss=0.128, v_num=0]\n",
      "Epoch 1: 100%|█████████▉| 3314/3318 [14:13<00:01,  3.45batch/s, batch_idx=2999, gpu=0, loss=0.128, v_num=0]\n",
      "Epoch 1: 100%|█████████▉| 3316/3318 [14:13<00:00,  3.53batch/s, batch_idx=2999, gpu=0, loss=0.128, v_num=0]\n",
      "Epoch 1: 100%|██████████| 3318/3318 [14:14<00:00,  3.47batch/s, batch_idx=2999, gpu=0, loss=0.128, v_num=0]\n",
      "Epoch 1: 100%|██████████| 3318/3318 [14:14<00:00,  3.88batch/s, batch_idx=2999, gpu=0, loss=0.128, v_num=0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:gpu available: True, used: True\n",
      "INFO:root:VISIBLE GPUS: 0\n",
      "INFO:root:\n",
      "              Name               Type Params\n",
      "0            model             ResNet   24 M\n",
      "1      model.conv1             Conv2d    9 K\n",
      "2        model.bn1        BatchNorm2d  128  \n",
      "3       model.relu               ReLU    0  \n",
      "4    model.maxpool          MaxPool2d    0  \n",
      "..             ...                ...    ...\n",
      "150       model.fc         Sequential    1 M\n",
      "151     model.fc.0             Linear    1 M\n",
      "152     model.fc.1        BatchNorm1d    1 K\n",
      "153     model.fc.2             Linear  513  \n",
      "154           loss  BCEWithLogitsLoss    0  \n",
      "\n",
      "[155 rows x 3 columns]\n",
      "Validation sanity check:   0%|          | 0/5 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/catinous/cat_data/ catsinom_lr_dataset.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/3288 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  15%|█▌        | 500/3288 [02:04<11:28,  4.05batch/s, batch_idx=499, gpu=0, loss=0.285, v_num=0]\n",
      "Validating:   0%|          | 0/48 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 501/3288 [02:05<19:39,  2.36batch/s, batch_idx=499, gpu=0, loss=0.285, v_num=0]\n",
      "Epoch 1:  15%|█▌        | 503/3288 [02:05<18:07,  2.56batch/s, batch_idx=499, gpu=0, loss=0.285, v_num=0]\n",
      "Epoch 1:  15%|█▌        | 505/3288 [02:06<18:49,  2.46batch/s, batch_idx=499, gpu=0, loss=0.285, v_num=0]\n",
      "Epoch 1:  15%|█▌        | 507/3288 [02:07<17:54,  2.59batch/s, batch_idx=499, gpu=0, loss=0.285, v_num=0]\n",
      "Epoch 1:  15%|█▌        | 509/3288 [02:08<16:36,  2.79batch/s, batch_idx=499, gpu=0, loss=0.285, v_num=0]\n",
      "Epoch 1:  16%|█▌        | 511/3288 [02:08<16:27,  2.81batch/s, batch_idx=499, gpu=0, loss=0.285, v_num=0]\n",
      "Epoch 1:  16%|█▌        | 513/3288 [02:09<15:17,  3.02batch/s, batch_idx=499, gpu=0, loss=0.285, v_num=0]\n",
      "Epoch 1:  16%|█▌        | 515/3288 [02:09<14:51,  3.11batch/s, batch_idx=499, gpu=0, loss=0.285, v_num=0]\n",
      "Epoch 1:  16%|█▌        | 517/3288 [02:10<15:29,  2.98batch/s, batch_idx=499, gpu=0, loss=0.285, v_num=0]\n",
      "Epoch 1:  16%|█▌        | 519/3288 [02:11<15:32,  2.97batch/s, batch_idx=499, gpu=0, loss=0.285, v_num=0]\n",
      "Epoch 1:  16%|█▌        | 521/3288 [02:11<15:31,  2.97batch/s, batch_idx=499, gpu=0, loss=0.285, v_num=0]\n",
      "Epoch 1:  16%|█▌        | 523/3288 [02:12<15:02,  3.07batch/s, batch_idx=499, gpu=0, loss=0.285, v_num=0]\n",
      "Epoch 1:  16%|█▌        | 525/3288 [02:13<15:09,  3.04batch/s, batch_idx=499, gpu=0, loss=0.285, v_num=0]\n",
      "Epoch 1:  16%|█▌        | 527/3288 [02:13<14:05,  3.26batch/s, batch_idx=499, gpu=0, loss=0.285, v_num=0]\n",
      "Epoch 1:  16%|█▌        | 529/3288 [02:14<14:51,  3.10batch/s, batch_idx=499, gpu=0, loss=0.285, v_num=0]\n",
      "Epoch 1:  16%|█▌        | 531/3288 [02:15<14:17,  3.22batch/s, batch_idx=499, gpu=0, loss=0.285, v_num=0]\n",
      "Epoch 1:  16%|█▌        | 533/3288 [02:15<14:29,  3.17batch/s, batch_idx=499, gpu=0, loss=0.285, v_num=0]\n",
      "Epoch 1:  16%|█▋        | 535/3288 [02:16<14:59,  3.06batch/s, batch_idx=499, gpu=0, loss=0.285, v_num=0]\n",
      "Epoch 1:  16%|█▋        | 537/3288 [02:17<14:44,  3.11batch/s, batch_idx=499, gpu=0, loss=0.285, v_num=0]\n",
      "Epoch 1:  16%|█▋        | 539/3288 [02:17<14:14,  3.22batch/s, batch_idx=499, gpu=0, loss=0.285, v_num=0]\n",
      "Epoch 1:  16%|█▋        | 541/3288 [02:18<14:37,  3.13batch/s, batch_idx=499, gpu=0, loss=0.285, v_num=0]\n",
      "Epoch 1:  17%|█▋        | 543/3288 [02:18<14:23,  3.18batch/s, batch_idx=499, gpu=0, loss=0.285, v_num=0]\n",
      "Epoch 1:  17%|█▋        | 545/3288 [02:19<14:10,  3.23batch/s, batch_idx=499, gpu=0, loss=0.285, v_num=0]\n",
      "Epoch 1:  17%|█▋        | 548/3288 [02:20<13:56,  3.28batch/s, batch_idx=499, gpu=0, loss=0.285, v_num=0]\n",
      "Epoch 1:  32%|███▏      | 1048/3288 [04:23<09:12,  4.06batch/s, batch_idx=999, gpu=0, loss=0.176, v_num=0]\n",
      "Validating:   0%|          | 0/48 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 1049/3288 [04:24<14:15,  2.62batch/s, batch_idx=999, gpu=0, loss=0.176, v_num=0]\n",
      "Epoch 1:  32%|███▏      | 1051/3288 [04:25<12:33,  2.97batch/s, batch_idx=999, gpu=0, loss=0.176, v_num=0]\n",
      "Epoch 1:  32%|███▏      | 1053/3288 [04:25<11:30,  3.24batch/s, batch_idx=999, gpu=0, loss=0.176, v_num=0]\n",
      "Epoch 1:  32%|███▏      | 1055/3288 [04:26<11:07,  3.35batch/s, batch_idx=999, gpu=0, loss=0.176, v_num=0]\n",
      "Epoch 1:  32%|███▏      | 1057/3288 [04:26<10:13,  3.63batch/s, batch_idx=999, gpu=0, loss=0.176, v_num=0]\n",
      "Epoch 1:  32%|███▏      | 1059/3288 [04:26<09:37,  3.86batch/s, batch_idx=999, gpu=0, loss=0.176, v_num=0]\n",
      "Epoch 1:  32%|███▏      | 1061/3288 [04:27<09:40,  3.84batch/s, batch_idx=999, gpu=0, loss=0.176, v_num=0]\n",
      "Epoch 1:  32%|███▏      | 1063/3288 [04:27<09:06,  4.07batch/s, batch_idx=999, gpu=0, loss=0.176, v_num=0]\n",
      "Epoch 1:  32%|███▏      | 1065/3288 [04:28<08:55,  4.15batch/s, batch_idx=999, gpu=0, loss=0.176, v_num=0]\n",
      "Epoch 1:  32%|███▏      | 1067/3288 [04:28<09:09,  4.04batch/s, batch_idx=999, gpu=0, loss=0.176, v_num=0]\n",
      "Validating:  42%|████▏     | 20/48 [00:05<00:05,  4.74batch/s]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 1069/3288 [04:29<09:30,  3.89batch/s, batch_idx=999, gpu=0, loss=0.176, v_num=0]\n",
      "Epoch 1:  33%|███▎      | 1071/3288 [04:30<09:31,  3.88batch/s, batch_idx=999, gpu=0, loss=0.176, v_num=0]\n",
      "Epoch 1:  33%|███▎      | 1073/3288 [04:30<09:59,  3.70batch/s, batch_idx=999, gpu=0, loss=0.176, v_num=0]\n",
      "Epoch 1:  33%|███▎      | 1075/3288 [04:31<09:27,  3.90batch/s, batch_idx=999, gpu=0, loss=0.176, v_num=0]\n",
      "Epoch 1:  33%|███▎      | 1077/3288 [04:31<09:11,  4.01batch/s, batch_idx=999, gpu=0, loss=0.176, v_num=0]\n",
      "Epoch 1:  33%|███▎      | 1079/3288 [04:32<09:06,  4.04batch/s, batch_idx=999, gpu=0, loss=0.176, v_num=0]\n",
      "Epoch 1:  33%|███▎      | 1081/3288 [04:32<08:43,  4.22batch/s, batch_idx=999, gpu=0, loss=0.176, v_num=0]\n",
      "Epoch 1:  33%|███▎      | 1083/3288 [04:32<08:52,  4.14batch/s, batch_idx=999, gpu=0, loss=0.176, v_num=0]\n",
      "Epoch 1:  33%|███▎      | 1085/3288 [04:33<08:33,  4.29batch/s, batch_idx=999, gpu=0, loss=0.176, v_num=0]\n",
      "Epoch 1:  33%|███▎      | 1087/3288 [04:33<08:36,  4.26batch/s, batch_idx=999, gpu=0, loss=0.176, v_num=0]\n",
      "Epoch 1:  33%|███▎      | 1089/3288 [04:34<08:46,  4.18batch/s, batch_idx=999, gpu=0, loss=0.176, v_num=0]\n",
      "Epoch 1:  33%|███▎      | 1091/3288 [04:34<08:26,  4.34batch/s, batch_idx=999, gpu=0, loss=0.176, v_num=0]\n",
      "Epoch 1:  33%|███▎      | 1093/3288 [04:35<08:19,  4.40batch/s, batch_idx=999, gpu=0, loss=0.176, v_num=0]\n",
      "Epoch 1:  33%|███▎      | 1096/3288 [04:35<08:24,  4.35batch/s, batch_idx=999, gpu=0, loss=0.176, v_num=0]\n",
      "Epoch 1:  49%|████▊     | 1596/3288 [06:39<06:54,  4.08batch/s, batch_idx=1499, gpu=0, loss=0.080, v_num=0]\n",
      "Validating:   0%|          | 0/48 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 1597/3288 [06:40<11:21,  2.48batch/s, batch_idx=1499, gpu=0, loss=0.080, v_num=0]\n",
      "Epoch 1:  49%|████▊     | 1599/3288 [06:40<09:59,  2.82batch/s, batch_idx=1499, gpu=0, loss=0.080, v_num=0]\n",
      "Epoch 1:  49%|████▊     | 1601/3288 [06:41<08:48,  3.19batch/s, batch_idx=1499, gpu=0, loss=0.080, v_num=0]\n",
      "Epoch 1:  49%|████▉     | 1603/3288 [06:41<07:55,  3.55batch/s, batch_idx=1499, gpu=0, loss=0.080, v_num=0]\n",
      "Epoch 1:  49%|████▉     | 1605/3288 [06:42<07:31,  3.73batch/s, batch_idx=1499, gpu=0, loss=0.080, v_num=0]\n",
      "Epoch 1:  49%|████▉     | 1607/3288 [06:42<07:04,  3.96batch/s, batch_idx=1499, gpu=0, loss=0.080, v_num=0]\n",
      "Epoch 1:  49%|████▉     | 1609/3288 [06:43<06:45,  4.14batch/s, batch_idx=1499, gpu=0, loss=0.080, v_num=0]\n",
      "Epoch 1:  49%|████▉     | 1611/3288 [06:43<06:30,  4.30batch/s, batch_idx=1499, gpu=0, loss=0.080, v_num=0]\n",
      "Epoch 1:  49%|████▉     | 1613/3288 [06:43<06:33,  4.25batch/s, batch_idx=1499, gpu=0, loss=0.080, v_num=0]\n",
      "Epoch 1:  49%|████▉     | 1615/3288 [06:44<06:27,  4.32batch/s, batch_idx=1499, gpu=0, loss=0.080, v_num=0]\n",
      "Epoch 1:  49%|████▉     | 1617/3288 [06:44<06:20,  4.39batch/s, batch_idx=1499, gpu=0, loss=0.080, v_num=0]\n",
      "Epoch 1:  49%|████▉     | 1619/3288 [06:45<06:28,  4.30batch/s, batch_idx=1499, gpu=0, loss=0.080, v_num=0]\n",
      "Epoch 1:  49%|████▉     | 1621/3288 [06:45<06:36,  4.20batch/s, batch_idx=1499, gpu=0, loss=0.080, v_num=0]\n",
      "Epoch 1:  49%|████▉     | 1623/3288 [06:46<06:25,  4.32batch/s, batch_idx=1499, gpu=0, loss=0.080, v_num=0]\n",
      "Epoch 1:  49%|████▉     | 1625/3288 [06:46<06:18,  4.39batch/s, batch_idx=1499, gpu=0, loss=0.080, v_num=0]\n",
      "Epoch 1:  49%|████▉     | 1627/3288 [06:47<06:15,  4.42batch/s, batch_idx=1499, gpu=0, loss=0.080, v_num=0]\n",
      "Epoch 1:  50%|████▉     | 1629/3288 [06:47<06:08,  4.50batch/s, batch_idx=1499, gpu=0, loss=0.080, v_num=0]\n",
      "Epoch 1:  50%|████▉     | 1631/3288 [06:48<06:24,  4.31batch/s, batch_idx=1499, gpu=0, loss=0.080, v_num=0]\n",
      "Epoch 1:  50%|████▉     | 1633/3288 [06:48<06:15,  4.41batch/s, batch_idx=1499, gpu=0, loss=0.080, v_num=0]\n",
      "Epoch 1:  50%|████▉     | 1635/3288 [06:48<06:13,  4.43batch/s, batch_idx=1499, gpu=0, loss=0.080, v_num=0]\n",
      "Epoch 1:  50%|████▉     | 1637/3288 [06:49<06:03,  4.54batch/s, batch_idx=1499, gpu=0, loss=0.080, v_num=0]\n",
      "Epoch 1:  50%|████▉     | 1639/3288 [06:49<06:11,  4.43batch/s, batch_idx=1499, gpu=0, loss=0.080, v_num=0]\n",
      "Epoch 1:  50%|████▉     | 1641/3288 [06:50<06:17,  4.37batch/s, batch_idx=1499, gpu=0, loss=0.080, v_num=0]\n",
      "Epoch 1:  50%|█████     | 1644/3288 [06:50<06:13,  4.40batch/s, batch_idx=1499, gpu=0, loss=0.080, v_num=0]\n",
      "Epoch 1:  65%|██████▌   | 2144/3288 [08:54<04:44,  4.02batch/s, batch_idx=1999, gpu=0, loss=0.101, v_num=0]\n",
      "Validating:   0%|          | 0/48 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 2145/3288 [08:55<07:18,  2.61batch/s, batch_idx=1999, gpu=0, loss=0.101, v_num=0]\n",
      "Epoch 1:  65%|██████▌   | 2147/3288 [08:56<06:16,  3.03batch/s, batch_idx=1999, gpu=0, loss=0.101, v_num=0]\n",
      "Epoch 1:  65%|██████▌   | 2149/3288 [08:56<05:42,  3.32batch/s, batch_idx=1999, gpu=0, loss=0.101, v_num=0]\n",
      "Epoch 1:  65%|██████▌   | 2151/3288 [08:56<05:14,  3.62batch/s, batch_idx=1999, gpu=0, loss=0.101, v_num=0]\n",
      "Epoch 1:  65%|██████▌   | 2153/3288 [08:57<04:59,  3.78batch/s, batch_idx=1999, gpu=0, loss=0.101, v_num=0]\n",
      "Epoch 1:  66%|██████▌   | 2155/3288 [08:57<04:40,  4.04batch/s, batch_idx=1999, gpu=0, loss=0.101, v_num=0]\n",
      "Epoch 1:  66%|██████▌   | 2157/3288 [08:58<04:31,  4.16batch/s, batch_idx=1999, gpu=0, loss=0.101, v_num=0]\n",
      "Epoch 1:  66%|██████▌   | 2159/3288 [08:58<04:21,  4.31batch/s, batch_idx=1999, gpu=0, loss=0.101, v_num=0]\n",
      "Epoch 1:  66%|██████▌   | 2161/3288 [08:59<04:19,  4.34batch/s, batch_idx=1999, gpu=0, loss=0.101, v_num=0]\n",
      "Epoch 1:  66%|██████▌   | 2163/3288 [08:59<04:23,  4.28batch/s, batch_idx=1999, gpu=0, loss=0.101, v_num=0]\n",
      "Epoch 1:  66%|██████▌   | 2165/3288 [09:00<04:16,  4.37batch/s, batch_idx=1999, gpu=0, loss=0.101, v_num=0]\n",
      "Epoch 1:  66%|██████▌   | 2167/3288 [09:00<04:13,  4.42batch/s, batch_idx=1999, gpu=0, loss=0.101, v_num=0]\n",
      "Epoch 1:  66%|██████▌   | 2169/3288 [09:00<04:12,  4.43batch/s, batch_idx=1999, gpu=0, loss=0.101, v_num=0]\n",
      "Epoch 1:  66%|██████▌   | 2171/3288 [09:01<04:06,  4.53batch/s, batch_idx=1999, gpu=0, loss=0.101, v_num=0]\n",
      "Epoch 1:  66%|██████▌   | 2173/3288 [09:01<04:05,  4.55batch/s, batch_idx=1999, gpu=0, loss=0.101, v_num=0]\n",
      "Epoch 1:  66%|██████▌   | 2175/3288 [09:02<04:09,  4.46batch/s, batch_idx=1999, gpu=0, loss=0.101, v_num=0]\n",
      "Epoch 1:  66%|██████▌   | 2177/3288 [09:02<04:07,  4.48batch/s, batch_idx=1999, gpu=0, loss=0.101, v_num=0]\n",
      "Epoch 1:  66%|██████▋   | 2179/3288 [09:03<04:10,  4.43batch/s, batch_idx=1999, gpu=0, loss=0.101, v_num=0]\n",
      "Epoch 1:  66%|██████▋   | 2181/3288 [09:03<04:10,  4.42batch/s, batch_idx=1999, gpu=0, loss=0.101, v_num=0]\n",
      "Epoch 1:  66%|██████▋   | 2183/3288 [09:04<04:05,  4.51batch/s, batch_idx=1999, gpu=0, loss=0.101, v_num=0]\n",
      "Epoch 1:  66%|██████▋   | 2185/3288 [09:04<03:59,  4.60batch/s, batch_idx=1999, gpu=0, loss=0.101, v_num=0]\n",
      "Epoch 1:  67%|██████▋   | 2187/3288 [09:04<04:05,  4.48batch/s, batch_idx=1999, gpu=0, loss=0.101, v_num=0]\n",
      "Epoch 1:  67%|██████▋   | 2189/3288 [09:05<04:01,  4.55batch/s, batch_idx=1999, gpu=0, loss=0.101, v_num=0]\n",
      "Epoch 1:  67%|██████▋   | 2192/3288 [09:05<04:02,  4.52batch/s, batch_idx=1999, gpu=0, loss=0.101, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 2692/3288 [11:10<02:28,  4.02batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Validating:   0%|          | 0/48 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 2693/3288 [11:10<03:41,  2.69batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 2695/3288 [11:11<03:16,  3.02batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 2697/3288 [11:11<02:54,  3.39batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 2699/3288 [11:12<02:44,  3.59batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 2701/3288 [11:12<02:31,  3.87batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 2703/3288 [11:12<02:24,  4.04batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 2705/3288 [11:13<02:20,  4.14batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 2707/3288 [11:13<02:18,  4.21batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 2709/3288 [11:14<02:15,  4.29batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  82%|████████▏ | 2711/3288 [11:14<02:13,  4.31batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2713/3288 [11:15<02:07,  4.50batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2714/3288 [11:15<01:56,  4.91batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2715/3288 [11:15<02:09,  4.44batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2716/3288 [11:15<01:58,  4.84batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2717/3288 [11:16<02:13,  4.27batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2718/3288 [11:16<02:04,  4.59batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2719/3288 [11:16<02:21,  4.03batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2720/3288 [11:16<02:05,  4.53batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2721/3288 [11:16<02:19,  4.06batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2722/3288 [11:17<01:59,  4.73batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2723/3288 [11:17<02:18,  4.07batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2725/3288 [11:17<02:13,  4.21batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2726/3288 [11:18<01:54,  4.92batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2727/3288 [11:18<02:14,  4.19batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2729/3288 [11:18<02:12,  4.23batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2731/3288 [11:19<02:09,  4.29batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2732/3288 [11:19<01:51,  4.98batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2733/3288 [11:19<02:11,  4.23batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2734/3288 [11:19<01:52,  4.92batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2735/3288 [11:20<02:16,  4.05batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2737/3288 [11:20<02:09,  4.26batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2738/3288 [11:20<01:49,  5.00batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  83%|████████▎ | 2740/3288 [11:21<02:17,  3.99batch/s, batch_idx=2499, gpu=0, loss=0.125, v_num=0]\n",
      "Epoch 1:  99%|█████████▊| 3240/3288 [13:28<00:11,  4.05batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n",
      "Validating:   0%|          | 0/48 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 3241/3288 [13:29<00:18,  2.57batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n",
      "Epoch 1:  99%|█████████▊| 3243/3288 [13:29<00:15,  2.92batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n",
      "Epoch 1:  99%|█████████▊| 3245/3288 [13:30<00:13,  3.20batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3247/3288 [13:30<00:11,  3.49batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3249/3288 [13:31<00:10,  3.80batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3251/3288 [13:31<00:09,  3.91batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3253/3288 [13:32<00:08,  3.97batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3255/3288 [13:32<00:08,  3.98batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3257/3288 [13:33<00:07,  4.13batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3259/3288 [13:33<00:06,  4.21batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3261/3288 [13:34<00:06,  4.24batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3263/3288 [13:34<00:05,  4.31batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3265/3288 [13:34<00:05,  4.48batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3267/3288 [13:35<00:04,  4.34batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3268/3288 [13:35<00:04,  4.61batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3269/3288 [13:35<00:04,  3.87batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3270/3288 [13:36<00:03,  4.68batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n",
      "Epoch 1:  99%|█████████▉| 3271/3288 [13:36<00:04,  3.88batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n",
      "Epoch 1: 100%|█████████▉| 3273/3288 [13:36<00:03,  3.91batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n",
      "Epoch 1: 100%|█████████▉| 3275/3288 [13:37<00:03,  3.98batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n",
      "Epoch 1: 100%|█████████▉| 3277/3288 [13:37<00:02,  4.10batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n",
      "Epoch 1: 100%|█████████▉| 3278/3288 [13:37<00:02,  4.95batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n",
      "Epoch 1: 100%|█████████▉| 3279/3288 [13:38<00:02,  4.35batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n",
      "Epoch 1: 100%|█████████▉| 3280/3288 [13:38<00:01,  4.57batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n",
      "Epoch 1: 100%|█████████▉| 3281/3288 [13:38<00:01,  4.34batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n",
      "Epoch 1: 100%|█████████▉| 3282/3288 [13:38<00:01,  4.72batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n",
      "Epoch 1: 100%|█████████▉| 3283/3288 [13:39<00:01,  4.38batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n",
      "Epoch 1: 100%|█████████▉| 3284/3288 [13:39<00:00,  4.06batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n",
      "Epoch 1: 100%|█████████▉| 3285/3288 [13:39<00:00,  4.36batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n",
      "Epoch 1: 100%|█████████▉| 3286/3288 [13:39<00:00,  4.00batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n",
      "Epoch 1: 100%|██████████| 3288/3288 [13:40<00:00,  4.25batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n",
      "Epoch 1: 100%|██████████| 3288/3288 [13:40<00:00,  4.01batch/s, batch_idx=2999, gpu=0, loss=0.082, v_num=0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/project/catinous/trained_models/lrbase_iterations.pt'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_full_dataset('hr')\n",
    "trained_full_dataset('lr')\n",
    "trained_full_dataset('combined')\n",
    "trained_full_dataset('hr', base_only=True)\n",
    "trained_full_dataset('lr', base_only=True)\n",
    "trained_full_dataset('hr', continue_from='lr')\n",
    "trained_full_dataset('lr', continue_from='hr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/project/catinous/trained_models/hr_iterations.pt'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_full_dataset('hr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MLFlowLogger', 'TensorBoardLogger']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pllogging.__all__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pytorch_lightning.logging' from '/home/jhofmanninger/anaconda3/envs/candid/lib/python3.6/site-packages/pytorch_lightning/logging/__init__.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pllogging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 2 1 3 5 6]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(9375)\n",
    "perm = np.random.permutation([1,2,3,4,5,6])\n",
    "print(perm)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
